2024-08-18 00:13:16.748 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d98380d0ae73242b, traceId=66c13c9cb41226b4d98380d0ae73242b} - {"traceId":"66c13c9cb41226b4d98380d0ae73242b","id":"d98380d0ae73242b","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723939996710812,"duration":36682,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"8","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 00:13:16.975 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723939396892, flow.id=6949dfab-22d5-47ee-9462-950bfc2de505, spanId=d25560b526d7d30e, traceId=66c13c9c420c2aa77a658dd11ea2adee, vnode.id=E6376372B510} - Flow [6949dfab-22d5-47ee-9462-950bfc2de505] started
2024-08-18 00:13:17.010 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 149 ms
2024-08-18 00:13:17.118 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723939396892, corda.external.event.id=6949dfab-22d5-47ee-9462-950bfc2de505-Nfk17lYbgSXqX+7PPyG8tkBGy4T0CBhpR1DLHflMOqA=-1, flow.id=6949dfab-22d5-47ee-9462-950bfc2de505, spanId=788564b738f246de, traceId=66c13c9c420c2aa77a658dd11ea2adee, vnode.id=E6376372B510} - Flow [6949dfab-22d5-47ee-9462-950bfc2de505] completed successfully
2024-08-18 00:13:17.119 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723939396894, flow.id=4f8b86d7-c984-4b8e-a791-c57a58f01650, spanId=56889506ec6f3691, traceId=66c13c9c8de9e1115d1d442031669ee0, vnode.id=70D646C43105} - Flow [4f8b86d7-c984-4b8e-a791-c57a58f01650] started
2024-08-18 00:13:17.129 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723939396894, corda.external.event.id=4f8b86d7-c984-4b8e-a791-c57a58f01650-zM1Kh9QsrOFH8bKzd1fIf3AvPdGNX8KJTFOQbRufWxY=-1, flow.id=4f8b86d7-c984-4b8e-a791-c57a58f01650, spanId=897c08f320392e90, traceId=66c13c9c8de9e1115d1d442031669ee0, vnode.id=70D646C43105} - Flow [4f8b86d7-c984-4b8e-a791-c57a58f01650] completed successfully
2024-08-18 00:13:17.129 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723939396894, flow.id=02ccba44-2c6c-4d2b-861d-7448a65eab7e, spanId=c7001b575a819ab8, traceId=66c13c9cdac68cdb5ad391bea81641f4, vnode.id=2F24A5C4BB8B} - Flow [02ccba44-2c6c-4d2b-861d-7448a65eab7e] started
2024-08-18 00:13:17.141 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723939396894, corda.external.event.id=02ccba44-2c6c-4d2b-861d-7448a65eab7e-zM1Kh9QsrOFH8bKzd1fIf3AvPdGNX8KJTFOQbRufWxY=-1, flow.id=02ccba44-2c6c-4d2b-861d-7448a65eab7e, spanId=585f3a04cec98a27, traceId=66c13c9cdac68cdb5ad391bea81641f4, vnode.id=2F24A5C4BB8B} - Flow [02ccba44-2c6c-4d2b-861d-7448a65eab7e] completed successfully
2024-08-18 00:13:17.142 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723939396894, flow.id=466fe44c-b7d8-439d-9a04-d306b8de9bd2, spanId=649d94c7c7953688, traceId=66c13c9cef97bc7689d4b656734218d0, vnode.id=F87FD80A917B} - Flow [466fe44c-b7d8-439d-9a04-d306b8de9bd2] started
2024-08-18 00:13:17.154 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723939396894, corda.external.event.id=466fe44c-b7d8-439d-9a04-d306b8de9bd2-zM1Kh9QsrOFH8bKzd1fIf3AvPdGNX8KJTFOQbRufWxY=-1, flow.id=466fe44c-b7d8-439d-9a04-d306b8de9bd2, spanId=6dcb67591922eefb, traceId=66c13c9cef97bc7689d4b656734218d0, vnode.id=F87FD80A917B} - Flow [466fe44c-b7d8-439d-9a04-d306b8de9bd2] completed successfully
2024-08-18 00:13:17.155 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723939396894, flow.id=eeda592c-6c80-49bb-bdd2-f105548c38f6, spanId=ce79243f5802b45f, traceId=66c13c9ca0255b699a7ec52b9b736c5f, vnode.id=E23A18A57E27} - Flow [eeda592c-6c80-49bb-bdd2-f105548c38f6] started
2024-08-18 00:13:17.174 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723939396894, corda.external.event.id=eeda592c-6c80-49bb-bdd2-f105548c38f6-zM1Kh9QsrOFH8bKzd1fIf3AvPdGNX8KJTFOQbRufWxY=-1, flow.id=eeda592c-6c80-49bb-bdd2-f105548c38f6, spanId=adfd0348e681afd9, traceId=66c13c9ca0255b699a7ec52b9b736c5f, vnode.id=E23A18A57E27} - Flow [eeda592c-6c80-49bb-bdd2-f105548c38f6] completed successfully
2024-08-18 00:13:19.112 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=388ad945e1c225e8, traceId=66c13c9fdfc33aa7388ad945e1c225e8} - {"traceId":"66c13c9fdfc33aa7388ad945e1c225e8","id":"388ad945e1c225e8","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723939999098180,"duration":13596,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"46","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 00:25:48.402 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:25:48.406 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 00:25:48.911 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 00:25:48.913 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 00:25:49.365 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 00:25:49.366 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 00:25:49.367 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 00:25:49.368 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 00:25:49.368 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 00:25:56.986 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2cb01acb7ae5bf86, traceId=66c13f948df1fd4f2cb01acb7ae5bf86} - {"traceId":"66c13f948df1fd4f2cb01acb7ae5bf86","id":"2cb01acb7ae5bf86","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723940756962543,"duration":21189,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"48","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 00:48:04.104 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:48:04.104 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:48:04.108 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:48:04.107 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:48:04.108 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 00:48:04.108 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 00:48:04.116 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:48:04.120 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 00:48:04.121 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 00:48:04.121 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 00:48:04.110 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 00:48:04.110 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 00:48:04.162 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 00:48:04.162 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 00:48:04.169 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 00:48:04.169 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 00:48:04.174 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 00:48:04.174 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 00:48:04.174 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 00:48:04.174 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 00:48:12.752 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a013eb4f18bbd21f, traceId=66c144ccbe7832f0a013eb4f18bbd21f} - {"traceId":"66c144ccbe7832f0a013eb4f18bbd21f","id":"a013eb4f18bbd21f","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723942092715653,"duration":35319,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"50","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 00:48:24.187 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 00:48:24.194 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 00:48:24.207 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 00:48:24.209 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 00:48:24.402 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 00:48:24.407 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 00:48:24.406 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 00:48:24.406 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 00:48:24.406 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 00:48:24.402 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 00:48:24.405 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 00:48:24.409 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 00:48:24.410 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 00:48:24.415 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 00:58:21.273 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=5f847cc200c71fd8, traceId=66c1472d3caa14645f847cc200c71fd8} - {"traceId":"66c1472d3caa14645f847cc200c71fd8","id":"5f847cc200c71fd8","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723942701225136,"duration":45052,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"52","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 01:38:56.280 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=286890c24b403e27, traceId=66c150b025826e2a286890c24b403e27} - {"traceId":"66c150b025826e2a286890c24b403e27","id":"286890c24b403e27","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723945136254850,"duration":24673,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"10","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 01:38:57.318 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723944536314, flow.id=496bf217-d988-49df-bff7-83ecd07ffb4e, spanId=3bb97bdbf0e6a34e, traceId=66c150b0414571098e784b4e6f871d7a, vnode.id=E6376372B510} - Flow [496bf217-d988-49df-bff7-83ecd07ffb4e] started
2024-08-18 01:38:57.438 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723944536314, corda.external.event.id=496bf217-d988-49df-bff7-83ecd07ffb4e-w7qvUCFWovZIgJq8bJ0EPGFzip9SAwctU1DrIj8AzQs=-1, flow.id=496bf217-d988-49df-bff7-83ecd07ffb4e, spanId=124d74d7020bafcd, traceId=66c150b0414571098e784b4e6f871d7a, vnode.id=E6376372B510} - Flow [496bf217-d988-49df-bff7-83ecd07ffb4e] completed successfully
2024-08-18 01:38:57.439 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723944536317, flow.id=a4063c44-8cad-4a28-ad07-29217a2e669a, spanId=0da0392dbcd6ad25, traceId=66c150b0f37264d246c832f9ea690047, vnode.id=70D646C43105} - Flow [a4063c44-8cad-4a28-ad07-29217a2e669a] started
2024-08-18 01:38:57.466 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 1164 ms
2024-08-18 01:38:57.471 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723944536317, corda.external.event.id=a4063c44-8cad-4a28-ad07-29217a2e669a-/oeqjgv1ecSikO7YCokVfLMvq6VGa7FS7kwsMnCXPmI=-1, flow.id=a4063c44-8cad-4a28-ad07-29217a2e669a, spanId=d05ea7c4c2b21758, traceId=66c150b0f37264d246c832f9ea690047, vnode.id=70D646C43105} - Flow [a4063c44-8cad-4a28-ad07-29217a2e669a] completed successfully
2024-08-18 01:38:57.473 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723944536317, flow.id=e9ad4701-9ae0-41fa-8a32-c284fa6aef10, spanId=383a7c9aae624788, traceId=66c150b0699fc5062a3bf7dc9f5e038e, vnode.id=2F24A5C4BB8B} - Flow [e9ad4701-9ae0-41fa-8a32-c284fa6aef10] started
2024-08-18 01:38:57.508 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723944536317, corda.external.event.id=e9ad4701-9ae0-41fa-8a32-c284fa6aef10-/oeqjgv1ecSikO7YCokVfLMvq6VGa7FS7kwsMnCXPmI=-1, flow.id=e9ad4701-9ae0-41fa-8a32-c284fa6aef10, spanId=2ec832127a6d0aaf, traceId=66c150b0699fc5062a3bf7dc9f5e038e, vnode.id=2F24A5C4BB8B} - Flow [e9ad4701-9ae0-41fa-8a32-c284fa6aef10] completed successfully
2024-08-18 01:38:57.518 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723944536317, flow.id=abda9df2-9e54-4f63-931b-e7661b28757f, spanId=e0e5836d0957029f, traceId=66c150b0c6294a26f48f46198de2b72f, vnode.id=F87FD80A917B} - Flow [abda9df2-9e54-4f63-931b-e7661b28757f] started
2024-08-18 01:38:57.552 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723944536317, corda.external.event.id=abda9df2-9e54-4f63-931b-e7661b28757f-/oeqjgv1ecSikO7YCokVfLMvq6VGa7FS7kwsMnCXPmI=-1, flow.id=abda9df2-9e54-4f63-931b-e7661b28757f, spanId=b85aac3955231657, traceId=66c150b0c6294a26f48f46198de2b72f, vnode.id=F87FD80A917B} - Flow [abda9df2-9e54-4f63-931b-e7661b28757f] completed successfully
2024-08-18 01:38:57.552 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723944536317, flow.id=1421a297-a237-43f3-8349-53dc1fa7f520, spanId=4787d090bd46df78, traceId=66c150b083085a48062351e371189c50, vnode.id=E23A18A57E27} - Flow [1421a297-a237-43f3-8349-53dc1fa7f520] started
2024-08-18 01:38:57.572 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723944536317, corda.external.event.id=1421a297-a237-43f3-8349-53dc1fa7f520-/oeqjgv1ecSikO7YCokVfLMvq6VGa7FS7kwsMnCXPmI=-1, flow.id=1421a297-a237-43f3-8349-53dc1fa7f520, spanId=2f917b692ef9fbf0, traceId=66c150b083085a48062351e371189c50, vnode.id=E23A18A57E27} - Flow [1421a297-a237-43f3-8349-53dc1fa7f520] completed successfully
2024-08-18 01:38:58.987 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=897fc01355e86fed, traceId=66c150b280fae239897fc01355e86fed} - {"traceId":"66c150b280fae239897fc01355e86fed","id":"897fc01355e86fed","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723945138963271,"duration":22471,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"54","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 03:01:16.203 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 03:01:16.203 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 03:01:16.206 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 03:01:16.206 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 03:01:16.254 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 03:01:16.256 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 03:01:16.311 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 03:01:16.314 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 03:01:16.357 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 03:01:16.358 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 03:01:16.759 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 03:01:16.759 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 03:01:16.762 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 03:01:16.762 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 03:01:16.762 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 03:01:25.255 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=8b094d3f4699f727, traceId=66c164053018de6c8b094d3f4699f727} - {"traceId":"66c164053018de6c8b094d3f4699f727","id":"8b094d3f4699f727","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723950085232654,"duration":21249,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"56","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 03:01:36.238 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 03:01:36.238 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 03:01:36.238 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 03:50:08.531 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 03:50:08.538 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 03:50:08.538 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 03:50:08.540 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 03:50:08.540 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 03:50:08.540 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 03:50:08.539 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 03:50:08.543 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 03:50:09.547 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 03:50:09.547 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 03:50:09.548 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 03:50:09.549 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 03:50:09.548 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 03:50:09.549 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 03:50:09.550 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 03:50:09.550 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 03:50:09.551 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 03:50:09.551 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 03:50:17.685 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=17f5e03083fd997a, traceId=66c16f79d5315e9617f5e03083fd997a} - {"traceId":"66c16f79d5315e9617f5e03083fd997a","id":"17f5e03083fd997a","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723953017589764,"duration":94187,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"58","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 04:41:12.104 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 04:41:12.104 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 04:41:12.104 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 04:41:12.104 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 04:41:12.104 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 04:41:12.107 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 04:41:12.107 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 04:41:12.107 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 04:41:12.107 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 04:41:12.108 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 04:41:13.072 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 04:41:13.073 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 04:41:13.073 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 04:41:13.073 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 04:41:13.083 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 04:41:15.152 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 04:41:15.152 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 04:41:15.152 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 04:41:21.381 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=25274748fce5f26b, traceId=66c17b711f600c5425274748fce5f26b} - {"traceId":"66c17b711f600c5425274748fce5f26b","id":"25274748fce5f26b","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723956081351896,"duration":27852,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"60","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 05:28:01.107 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 05:28:01.110 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 05:28:01.124 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 05:28:01.124 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 05:28:01.129 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 05:28:01.130 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 05:28:01.623 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 05:28:01.624 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 05:28:02.079 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 05:28:02.080 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 05:28:02.081 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 05:28:02.081 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 05:28:02.082 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 05:28:07.455 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=68dba45e59a1a374, traceId=66c18667cfddf73468dba45e59a1a374} - {"traceId":"66c18667cfddf73468dba45e59a1a374","id":"68dba45e59a1a374","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723958887405779,"duration":45260,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"12","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 05:28:07.739 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 257 ms
2024-08-18 05:28:10.414 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=301fb3096f9aca0e, traceId=66c1866a16924f0f301fb3096f9aca0e} - {"traceId":"66c1866a16924f0f301fb3096f9aca0e","id":"301fb3096f9aca0e","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723958890394976,"duration":19022,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"62","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 05:28:21.151 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 05:28:21.151 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 05:28:21.151 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 05:28:21.194 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723958287506, flow.id=6a562b2c-badf-4eb2-8336-78be4df9c334, spanId=e3c960ce457426d0, traceId=66c1866765a71b4e7e2cdf9c102bd83b, vnode.id=E6376372B510} - Flow [6a562b2c-badf-4eb2-8336-78be4df9c334] started
2024-08-18 05:28:21.342 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723958287506, corda.external.event.id=6a562b2c-badf-4eb2-8336-78be4df9c334-fnE1n1305/DP10DLKLDWiy67uyN65YDrTl7OvFmwP3I=-1, flow.id=6a562b2c-badf-4eb2-8336-78be4df9c334, spanId=9d553ec319bf0a67, traceId=66c1866765a71b4e7e2cdf9c102bd83b, vnode.id=E6376372B510} - Flow [6a562b2c-badf-4eb2-8336-78be4df9c334] completed successfully
2024-08-18 05:28:21.355 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723958287510, flow.id=6839016b-e30c-4042-bab0-81c1c32ef4fb, spanId=f443313f40606514, traceId=66c186670f77412c9b4ef8271221c9a2, vnode.id=70D646C43105} - Flow [6839016b-e30c-4042-bab0-81c1c32ef4fb] started
2024-08-18 05:28:21.378 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723958287510, corda.external.event.id=6839016b-e30c-4042-bab0-81c1c32ef4fb-fXQPSvvqQd1jCtqauOvn5cQaI9IuSoa0T/tMiW0UngQ=-1, flow.id=6839016b-e30c-4042-bab0-81c1c32ef4fb, spanId=761a1451757e152f, traceId=66c186670f77412c9b4ef8271221c9a2, vnode.id=70D646C43105} - Flow [6839016b-e30c-4042-bab0-81c1c32ef4fb] completed successfully
2024-08-18 05:28:21.379 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723958287510, flow.id=706c870e-043c-4127-aac5-5c67e24ff926, spanId=410f2374717cc74a, traceId=66c18667c89fe7c1b65c53687ab10f6e, vnode.id=2F24A5C4BB8B} - Flow [706c870e-043c-4127-aac5-5c67e24ff926] started
2024-08-18 05:28:21.411 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723958287510, corda.external.event.id=706c870e-043c-4127-aac5-5c67e24ff926-fXQPSvvqQd1jCtqauOvn5cQaI9IuSoa0T/tMiW0UngQ=-1, flow.id=706c870e-043c-4127-aac5-5c67e24ff926, spanId=84452c7adc025d0a, traceId=66c18667c89fe7c1b65c53687ab10f6e, vnode.id=2F24A5C4BB8B} - Flow [706c870e-043c-4127-aac5-5c67e24ff926] completed successfully
2024-08-18 05:28:21.412 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723958287510, flow.id=6b25443d-634e-4dcc-9111-090ca5cf1d66, spanId=c8a2e4ec424a95d9, traceId=66c18667a12315728c3ba75baa9f96cb, vnode.id=F87FD80A917B} - Flow [6b25443d-634e-4dcc-9111-090ca5cf1d66] started
2024-08-18 05:28:21.433 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723958287510, corda.external.event.id=6b25443d-634e-4dcc-9111-090ca5cf1d66-fXQPSvvqQd1jCtqauOvn5cQaI9IuSoa0T/tMiW0UngQ=-1, flow.id=6b25443d-634e-4dcc-9111-090ca5cf1d66, spanId=d98dfcd6946364fd, traceId=66c18667a12315728c3ba75baa9f96cb, vnode.id=F87FD80A917B} - Flow [6b25443d-634e-4dcc-9111-090ca5cf1d66] completed successfully
2024-08-18 05:28:21.434 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723958287511, flow.id=0332ba4a-997d-4799-96c0-862362423ff1, spanId=1350cf0c937bff84, traceId=66c18667654af0c7e1e5040d36fc303c, vnode.id=E23A18A57E27} - Flow [0332ba4a-997d-4799-96c0-862362423ff1] started
2024-08-18 05:28:21.460 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723958287511, corda.external.event.id=0332ba4a-997d-4799-96c0-862362423ff1-PQ8BQwR54/aGv69gzLy+BwHt7/0NvxE0NTtgpmUrIOg=-1, flow.id=0332ba4a-997d-4799-96c0-862362423ff1, spanId=d9699e7e23ecccaf, traceId=66c18667654af0c7e1e5040d36fc303c, vnode.id=E23A18A57E27} - Flow [0332ba4a-997d-4799-96c0-862362423ff1] completed successfully
2024-08-18 05:31:34.524 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=198a3fbc4a6916b9, traceId=66c18736a1e34344198a3fbc4a6916b9} - {"traceId":"66c18736a1e34344198a3fbc4a6916b9","id":"198a3fbc4a6916b9","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723959094438961,"duration":76999,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"64","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 05:32:34.618 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b1088b492ef1bb24, traceId=66c18772fde6d757b1088b492ef1bb24} - {"traceId":"66c18772fde6d757b1088b492ef1bb24","id":"b1088b492ef1bb24","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959154578224,"duration":36380,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"66","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:34:07.218 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=bc521b523e2d1c2e, traceId=66c187cfcec877e9bc521b523e2d1c2e} - {"traceId":"66c187cfcec877e9bc521b523e2d1c2e","id":"bc521b523e2d1c2e","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723959247178522,"duration":28621,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"68","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 05:35:07.331 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=004b87fb34dc7e00, traceId=66c1880b27df1f3e004b87fb34dc7e00} - {"traceId":"66c1880b27df1f3e004b87fb34dc7e00","id":"004b87fb34dc7e00","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959307306958,"duration":23145,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"70","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:36:07.459 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4a02e4a696308773, traceId=66c18847f18639af4a02e4a696308773} - {"traceId":"66c18847f18639af4a02e4a696308773","id":"4a02e4a696308773","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723959367437937,"duration":20024,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"72","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 05:37:56.474 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=481e2cc6d13b2c2a, traceId=66c188b44b45836c481e2cc6d13b2c2a} - {"traceId":"66c188b44b45836c481e2cc6d13b2c2a","id":"481e2cc6d13b2c2a","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959476442865,"duration":29997,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"74","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:38:22.811 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9c549b6d3aadc9d7, traceId=66c188ce07a61f859c549b6d3aadc9d7} - {"traceId":"66c188ce07a61f859c549b6d3aadc9d7","id":"9c549b6d3aadc9d7","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723959502752774,"duration":56727,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"14","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 05:38:22.982 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723958902835, flow.id=06d37386-0381-41ae-93d1-b1f915f16e58, spanId=a5657b3c6259c19b, traceId=66c188ceedff8d6839d5f3138f3330fa, vnode.id=E6376372B510} - Flow [06d37386-0381-41ae-93d1-b1f915f16e58] started
2024-08-18 05:38:23.058 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 212 ms
2024-08-18 05:38:23.141 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723958902835, corda.external.event.id=06d37386-0381-41ae-93d1-b1f915f16e58-AwlVTRRDPxMfQHnnORprIzw8CMXZuymq1g9VyNnqtik=-1, flow.id=06d37386-0381-41ae-93d1-b1f915f16e58, spanId=2d704bf54d2c7530, traceId=66c188ceedff8d6839d5f3138f3330fa, vnode.id=E6376372B510} - Flow [06d37386-0381-41ae-93d1-b1f915f16e58] completed successfully
2024-08-18 05:38:23.143 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723958902842, flow.id=88c8d672-5b3f-48a2-b803-b640f64bd05e, spanId=7533cd77e822cb69, traceId=66c188ce344632b1cfce1e45ae759b9b, vnode.id=70D646C43105} - Flow [88c8d672-5b3f-48a2-b803-b640f64bd05e] started
2024-08-18 05:38:23.180 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723958902842, corda.external.event.id=88c8d672-5b3f-48a2-b803-b640f64bd05e-QlwRUnmWag7O5j6366kwkae0mwrgBW6Xhqm50MvIVUc=-1, flow.id=88c8d672-5b3f-48a2-b803-b640f64bd05e, spanId=08c1312a56b7b1a6, traceId=66c188ce344632b1cfce1e45ae759b9b, vnode.id=70D646C43105} - Flow [88c8d672-5b3f-48a2-b803-b640f64bd05e] completed successfully
2024-08-18 05:38:23.181 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723958902842, flow.id=402248c9-8452-4ca9-a135-479ca8f43119, spanId=3293e9b9f21de7ca, traceId=66c188ce174f72a0e8a8d49aa4b29928, vnode.id=2F24A5C4BB8B} - Flow [402248c9-8452-4ca9-a135-479ca8f43119] started
2024-08-18 05:38:23.205 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723958902842, corda.external.event.id=402248c9-8452-4ca9-a135-479ca8f43119-QlwRUnmWag7O5j6366kwkae0mwrgBW6Xhqm50MvIVUc=-1, flow.id=402248c9-8452-4ca9-a135-479ca8f43119, spanId=60afbe5f8df9893c, traceId=66c188ce174f72a0e8a8d49aa4b29928, vnode.id=2F24A5C4BB8B} - Flow [402248c9-8452-4ca9-a135-479ca8f43119] completed successfully
2024-08-18 05:38:23.206 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723958902842, flow.id=013bf4d2-61f7-4a5f-acf2-deeefb8235c4, spanId=aff097d22ebee49a, traceId=66c188ce177cc5d9647758e40237a674, vnode.id=F87FD80A917B} - Flow [013bf4d2-61f7-4a5f-acf2-deeefb8235c4] started
2024-08-18 05:38:23.229 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723958902842, corda.external.event.id=013bf4d2-61f7-4a5f-acf2-deeefb8235c4-QlwRUnmWag7O5j6366kwkae0mwrgBW6Xhqm50MvIVUc=-1, flow.id=013bf4d2-61f7-4a5f-acf2-deeefb8235c4, spanId=5566c2acc3d6cb69, traceId=66c188ce177cc5d9647758e40237a674, vnode.id=F87FD80A917B} - Flow [013bf4d2-61f7-4a5f-acf2-deeefb8235c4] completed successfully
2024-08-18 05:38:23.230 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723958902842, flow.id=caad5013-a27d-4783-ba93-bb632711f5d4, spanId=ae643078774dfbf3, traceId=66c188ce88d213caf2c3283ad272386a, vnode.id=E23A18A57E27} - Flow [caad5013-a27d-4783-ba93-bb632711f5d4] started
2024-08-18 05:38:23.264 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723958902842, corda.external.event.id=caad5013-a27d-4783-ba93-bb632711f5d4-QlwRUnmWag7O5j6366kwkae0mwrgBW6Xhqm50MvIVUc=-1, flow.id=caad5013-a27d-4783-ba93-bb632711f5d4, spanId=8650266a47111ca4, traceId=66c188ce88d213caf2c3283ad272386a, vnode.id=E23A18A57E27} - Flow [caad5013-a27d-4783-ba93-bb632711f5d4] completed successfully
2024-08-18 05:38:56.512 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=17905a073a614245, traceId=66c188f0b229016617905a073a614245} - {"traceId":"66c188f0b229016617905a073a614245","id":"17905a073a614245","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959536495260,"duration":15988,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"76","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:39:56.566 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=08961751214f27cc, traceId=66c1892ce669ad1b08961751214f27cc} - {"traceId":"66c1892ce669ad1b08961751214f27cc","id":"08961751214f27cc","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959596533635,"duration":31146,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"78","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:40:56.622 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=83e6c3600187df81, traceId=66c189681033e92b83e6c3600187df81} - {"traceId":"66c189681033e92b83e6c3600187df81","id":"83e6c3600187df81","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959656601092,"duration":20541,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"80","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:41:56.696 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=44b2bfc78d456ea2, traceId=66c189a4fbc0778244b2bfc78d456ea2} - {"traceId":"66c189a4fbc0778244b2bfc78d456ea2","id":"44b2bfc78d456ea2","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959716667345,"duration":27612,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"82","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:42:56.762 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=adf7a80ceb220341, traceId=66c189e0b354b8cfadf7a80ceb220341} - {"traceId":"66c189e0b354b8cfadf7a80ceb220341","id":"adf7a80ceb220341","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723959776743608,"duration":14769,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"84","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 05:55:10.526 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 05:55:10.532 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 05:55:11.035 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 05:55:11.038 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 05:55:11.490 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 05:55:11.491 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 05:55:11.493 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 05:55:11.495 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 05:55:11.496 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 05:55:20.821 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a43a4a89ab3ed2e1, traceId=66c18cc85e72c7a2a43a4a89ab3ed2e1} - {"traceId":"66c18cc85e72c7a2a43a4a89ab3ed2e1","id":"a43a4a89ab3ed2e1","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723960520791700,"duration":28174,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"86","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 06:26:47.011 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 06:26:47.015 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 06:26:47.564 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 06:26:47.565 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 06:26:48.026 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 06:26:48.034 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 06:26:48.033 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 06:26:48.044 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 06:26:48.038 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 06:26:53.311 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=0945384301af11f7, traceId=66c1942d6febfff00945384301af11f7} - {"traceId":"66c1942d6febfff00945384301af11f7","id":"0945384301af11f7","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723962413270402,"duration":39763,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"16","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 06:26:53.442 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723961813328, flow.id=c5f3076c-6d73-4b32-bf91-e7e158137932, spanId=df7578f93e77b459, traceId=66c1942d7a3599ca41032ca2db1ee198, vnode.id=E6376372B510} - Flow [c5f3076c-6d73-4b32-bf91-e7e158137932] started
2024-08-18 06:26:53.513 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 173 ms
2024-08-18 06:26:53.539 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723961813328, corda.external.event.id=c5f3076c-6d73-4b32-bf91-e7e158137932-s7rERVe44suIYm1goCTlvMY10WDK7VYPBbhx3MTxsQw=-1, flow.id=c5f3076c-6d73-4b32-bf91-e7e158137932, spanId=9f3b18556efd0f95, traceId=66c1942d7a3599ca41032ca2db1ee198, vnode.id=E6376372B510} - Flow [c5f3076c-6d73-4b32-bf91-e7e158137932] completed successfully
2024-08-18 06:26:53.540 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723961813331, flow.id=71badb8b-0aef-4f45-8a32-603dc11f94a1, spanId=ecaa3ecf6c5ae084, traceId=66c1942dee52d10325acbc1d09cd9b4a, vnode.id=70D646C43105} - Flow [71badb8b-0aef-4f45-8a32-603dc11f94a1] started
2024-08-18 06:26:53.570 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723961813331, corda.external.event.id=71badb8b-0aef-4f45-8a32-603dc11f94a1-Oc5hRy8uFQYFjJbvaVS+040yzqlNWP5uGH1ce9mbIdY=-1, flow.id=71badb8b-0aef-4f45-8a32-603dc11f94a1, spanId=0bf8b7896542f793, traceId=66c1942dee52d10325acbc1d09cd9b4a, vnode.id=70D646C43105} - Flow [71badb8b-0aef-4f45-8a32-603dc11f94a1] completed successfully
2024-08-18 06:26:53.573 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723961813331, flow.id=6eecdfc7-ec9b-416c-8222-8db36bd7b644, spanId=4793d74a818d5f14, traceId=66c1942dd69b6b85d07056f92fe7895f, vnode.id=2F24A5C4BB8B} - Flow [6eecdfc7-ec9b-416c-8222-8db36bd7b644] started
2024-08-18 06:26:53.598 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723961813331, corda.external.event.id=6eecdfc7-ec9b-416c-8222-8db36bd7b644-Oc5hRy8uFQYFjJbvaVS+040yzqlNWP5uGH1ce9mbIdY=-1, flow.id=6eecdfc7-ec9b-416c-8222-8db36bd7b644, spanId=8ba99563f88f6594, traceId=66c1942dd69b6b85d07056f92fe7895f, vnode.id=2F24A5C4BB8B} - Flow [6eecdfc7-ec9b-416c-8222-8db36bd7b644] completed successfully
2024-08-18 06:26:53.600 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723961813331, flow.id=523f839e-c024-41ec-809d-63c34bf41ff7, spanId=2336cc7d2369a0a3, traceId=66c1942d8d27428ec785cc419a1903dc, vnode.id=F87FD80A917B} - Flow [523f839e-c024-41ec-809d-63c34bf41ff7] started
2024-08-18 06:26:53.643 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723961813331, corda.external.event.id=523f839e-c024-41ec-809d-63c34bf41ff7-Oc5hRy8uFQYFjJbvaVS+040yzqlNWP5uGH1ce9mbIdY=-1, flow.id=523f839e-c024-41ec-809d-63c34bf41ff7, spanId=37a866b6841a36b5, traceId=66c1942d8d27428ec785cc419a1903dc, vnode.id=F87FD80A917B} - Flow [523f839e-c024-41ec-809d-63c34bf41ff7] completed successfully
2024-08-18 06:26:53.645 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723961813331, flow.id=fd37ff75-2609-436f-bc7c-7a8e5c3decf7, spanId=6fcaca3b1eae04e0, traceId=66c1942d2d86085a0134a164e50a8386, vnode.id=E23A18A57E27} - Flow [fd37ff75-2609-436f-bc7c-7a8e5c3decf7] started
2024-08-18 06:26:54.139 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723961813331, corda.external.event.id=fd37ff75-2609-436f-bc7c-7a8e5c3decf7-Oc5hRy8uFQYFjJbvaVS+040yzqlNWP5uGH1ce9mbIdY=-1, flow.id=fd37ff75-2609-436f-bc7c-7a8e5c3decf7, spanId=4daee2181985d0b2, traceId=66c1942d2d86085a0134a164e50a8386, vnode.id=E23A18A57E27} - Flow [fd37ff75-2609-436f-bc7c-7a8e5c3decf7] completed successfully
2024-08-18 06:26:57.370 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=8711332a9d4f67a1, traceId=66c194313b999d2f8711332a9d4f67a1} - {"traceId":"66c194313b999d2f8711332a9d4f67a1","id":"8711332a9d4f67a1","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723962417337555,"duration":31631,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"88","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 06:31:45.007 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=96ffabf6f70eb490, traceId=66c195507e5c0fa596ffabf6f70eb490} - {"traceId":"66c195507e5c0fa596ffabf6f70eb490","id":"96ffabf6f70eb490","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723962704945125,"duration":61172,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"90","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 07:11:25.393 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 07:11:25.396 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 07:11:35.924 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=03c8c9835bec6399, traceId=66c19ea7ae948d9703c8c9835bec6399} - {"traceId":"66c19ea7ae948d9703c8c9835bec6399","id":"03c8c9835bec6399","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723965095879942,"duration":42710,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"92","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 07:11:45.419 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 07:11:45.422 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 07:11:45.515 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 07:11:45.516 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 07:11:45.526 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 07:11:45.528 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 07:11:45.528 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 07:56:07.280 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 07:56:07.283 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 07:56:07.291 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 07:56:07.291 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 07:56:07.314 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 07:56:07.318 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 07:56:07.779 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 07:56:07.780 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 07:56:07.793 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 07:56:07.793 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 07:56:08.218 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 07:56:08.263 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 07:56:08.268 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 07:56:08.268 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 07:56:08.268 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 07:56:17.751 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=bb1e99e392cf6e93, traceId=66c1a921e1356f39bb1e99e392cf6e93} - {"traceId":"66c1a921e1356f39bb1e99e392cf6e93","id":"bb1e99e392cf6e93","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723967777732582,"duration":17944,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"94","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 07:56:27.269 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 07:56:27.274 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 07:56:27.280 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 07:56:27.280 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 07:56:27.280 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 08:09:45.420 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:09:45.420 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:09:45.422 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:09:45.422 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:09:45.423 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 08:09:45.423 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 08:09:45.423 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 08:09:45.423 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 08:09:45.426 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:09:45.428 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 08:09:45.444 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 08:09:45.444 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 08:09:45.444 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 08:09:51.690 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b5a14e193e42d546, traceId=66c1ac4f9c8c62d7b5a14e193e42d546} - {"traceId":"66c1ac4f9c8c62d7b5a14e193e42d546","id":"b5a14e193e42d546","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723968591648547,"duration":39418,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"18","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 08:09:51.910 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 132 ms
2024-08-18 08:09:55.971 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d679affabd78b163, traceId=66c1ac5329d39424d679affabd78b163} - {"traceId":"66c1ac5329d39424d679affabd78b163","id":"d679affabd78b163","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723968595941129,"duration":28705,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"96","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 08:10:05.924 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:10:05.927 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:10:05.927 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:10:05.928 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:10:05.930 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 08:10:05.985 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723967991704, flow.id=58cb3a19-db77-45db-aa43-c0d89ba46700, spanId=b52713ad0fbf609c, traceId=66c1ac4ff15ff5ca062f5c2b21030add, vnode.id=E6376372B510} - Flow [58cb3a19-db77-45db-aa43-c0d89ba46700] started
2024-08-18 08:10:06.123 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723967991704, corda.external.event.id=58cb3a19-db77-45db-aa43-c0d89ba46700-1lS6jDE1Oyry7B9V0PZb5gkdBmZ8fbWvLCjjc5x9YWc=-1, flow.id=58cb3a19-db77-45db-aa43-c0d89ba46700, spanId=b034af65f473107c, traceId=66c1ac4ff15ff5ca062f5c2b21030add, vnode.id=E6376372B510} - Flow [58cb3a19-db77-45db-aa43-c0d89ba46700] completed successfully
2024-08-18 08:10:06.125 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723967991706, flow.id=861d2d81-f304-4b95-a1cc-e70a4c3c768f, spanId=c031ffe3877d9831, traceId=66c1ac4f79085f2fd9ee8ecd614acfdf, vnode.id=70D646C43105} - Flow [861d2d81-f304-4b95-a1cc-e70a4c3c768f] started
2024-08-18 08:10:06.160 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723967991706, corda.external.event.id=861d2d81-f304-4b95-a1cc-e70a4c3c768f-GyOiyk8lsK2kVYVk9wRYcZ/TxpAQ/cWj6S0jtdWNS7g=-1, flow.id=861d2d81-f304-4b95-a1cc-e70a4c3c768f, spanId=4914f73d9672702b, traceId=66c1ac4f79085f2fd9ee8ecd614acfdf, vnode.id=70D646C43105} - Flow [861d2d81-f304-4b95-a1cc-e70a4c3c768f] completed successfully
2024-08-18 08:10:06.160 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723967991706, flow.id=d85f267f-9399-4787-858a-8d7853c4ad5e, spanId=d897f13faa97fce1, traceId=66c1ac4fbac4c93870811ef578b4d568, vnode.id=2F24A5C4BB8B} - Flow [d85f267f-9399-4787-858a-8d7853c4ad5e] started
2024-08-18 08:10:06.185 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723967991706, corda.external.event.id=d85f267f-9399-4787-858a-8d7853c4ad5e-GyOiyk8lsK2kVYVk9wRYcZ/TxpAQ/cWj6S0jtdWNS7g=-1, flow.id=d85f267f-9399-4787-858a-8d7853c4ad5e, spanId=863490b2e30fe1f4, traceId=66c1ac4fbac4c93870811ef578b4d568, vnode.id=2F24A5C4BB8B} - Flow [d85f267f-9399-4787-858a-8d7853c4ad5e] completed successfully
2024-08-18 08:10:06.186 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723967991706, flow.id=a7f8a37a-19cb-42f0-83bb-65fa74b5c1d6, spanId=4483b16b1f16aeb5, traceId=66c1ac4f4e88e4eae22e4f31ebc36e3a, vnode.id=F87FD80A917B} - Flow [a7f8a37a-19cb-42f0-83bb-65fa74b5c1d6] started
2024-08-18 08:10:06.216 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723967991706, corda.external.event.id=a7f8a37a-19cb-42f0-83bb-65fa74b5c1d6-GyOiyk8lsK2kVYVk9wRYcZ/TxpAQ/cWj6S0jtdWNS7g=-1, flow.id=a7f8a37a-19cb-42f0-83bb-65fa74b5c1d6, spanId=e5d1447dc373074b, traceId=66c1ac4f4e88e4eae22e4f31ebc36e3a, vnode.id=F87FD80A917B} - Flow [a7f8a37a-19cb-42f0-83bb-65fa74b5c1d6] completed successfully
2024-08-18 08:10:06.216 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723967991706, flow.id=a043db09-5661-4e48-b495-834fb13df6ad, spanId=80ba8a0c7e67d457, traceId=66c1ac4f5b0a85533250149dd93375a1, vnode.id=E23A18A57E27} - Flow [a043db09-5661-4e48-b495-834fb13df6ad] started
2024-08-18 08:10:06.236 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723967991706, corda.external.event.id=a043db09-5661-4e48-b495-834fb13df6ad-GyOiyk8lsK2kVYVk9wRYcZ/TxpAQ/cWj6S0jtdWNS7g=-1, flow.id=a043db09-5661-4e48-b495-834fb13df6ad, spanId=afb6b002054cb7f4, traceId=66c1ac4f5b0a85533250149dd93375a1, vnode.id=E23A18A57E27} - Flow [a043db09-5661-4e48-b495-834fb13df6ad] completed successfully
2024-08-18 08:16:49.212 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:16:49.214 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 08:16:49.680 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:16:49.681 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:16:50.134 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:16:50.135 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:16:50.137 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 08:16:50.138 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 08:16:50.138 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 08:16:59.865 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b487e1fecb747706, traceId=66c1adfb829148a8b487e1fecb747706} - {"traceId":"66c1adfb829148a8b487e1fecb747706","id":"b487e1fecb747706","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723969019816853,"duration":47542,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"98","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 08:23:03.390 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:23:03.390 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:23:03.392 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:23:03.394 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 08:23:03.394 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 08:23:03.398 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:23:03.399 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 08:23:03.393 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 08:23:03.408 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 08:23:03.411 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 08:23:04.330 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:23:04.330 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:23:04.331 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:23:04.331 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:23:04.332 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 08:23:04.332 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 08:23:04.333 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 08:23:04.334 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:23:04.339 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 08:23:04.339 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:23:14.055 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=da19c52ebbcee53b, traceId=66c1af7294aebce4da19c52ebbcee53b} - {"traceId":"66c1af7294aebce4da19c52ebbcee53b","id":"da19c52ebbcee53b","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723969394034784,"duration":19035,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"100","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 08:31:56.710 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:31:56.712 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:31:56.711 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:31:56.714 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 08:31:56.714 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 08:31:56.714 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 08:31:56.720 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:31:56.728 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 08:31:57.692 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:31:57.692 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 08:31:57.700 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:31:57.700 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 08:31:57.700 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 08:31:57.700 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:31:57.701 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:31:57.701 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:31:57.703 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 08:31:57.703 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 08:32:07.400 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=fa489e5f128466b8, traceId=66c1b1876104d946fa489e5f128466b8} - {"traceId":"66c1b1876104d946fa489e5f128466b8","id":"fa489e5f128466b8","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723969927376272,"duration":23062,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"102","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 08:42:08.320 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:42:08.320 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:42:08.320 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:42:08.320 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:42:08.320 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:42:08.320 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:42:08.324 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 08:42:08.324 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 08:42:08.324 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 08:42:08.324 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 08:42:08.324 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 08:42:08.326 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 08:42:11.372 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 08:42:11.372 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 08:42:11.372 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 08:42:11.380 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:42:11.380 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:42:11.380 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:42:14.823 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=dc8e922f98bc1d4b, traceId=66c1b3e6fb75a82bdc8e922f98bc1d4b} - {"traceId":"66c1b3e6fb75a82bdc8e922f98bc1d4b","id":"dc8e922f98bc1d4b","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723970534800996,"duration":21543,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"20","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 08:42:14.973 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723969934862, flow.id=3293d8c1-6933-4af8-8a38-3e04ded1aa28, spanId=76e746a7744eacd7, traceId=66c1b3e6148e761a05484435cb4ef780, vnode.id=E6376372B510} - Flow [3293d8c1-6933-4af8-8a38-3e04ded1aa28] started
2024-08-18 08:42:15.086 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723969934862, corda.external.event.id=3293d8c1-6933-4af8-8a38-3e04ded1aa28-aJBFuXdzZSP9GC043OX/vOhBLa5N89WvmkErlD3ZwJI=-1, flow.id=3293d8c1-6933-4af8-8a38-3e04ded1aa28, spanId=f4a009b77d723383, traceId=66c1b3e6148e761a05484435cb4ef780, vnode.id=E6376372B510} - Flow [3293d8c1-6933-4af8-8a38-3e04ded1aa28] completed successfully
2024-08-18 08:42:15.089 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723969934864, flow.id=ac0ec149-6cd2-44cf-9369-a277d715ab90, spanId=62e1634abff561e0, traceId=66c1b3e6729c8def5b5b8b6117032303, vnode.id=70D646C43105} - Flow [ac0ec149-6cd2-44cf-9369-a277d715ab90] started
2024-08-18 08:42:15.112 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723969934864, corda.external.event.id=ac0ec149-6cd2-44cf-9369-a277d715ab90-YY5xfyYb/4NXGtmFGCnLAK/P7yZ8gQnQVH4cqn0czTw=-1, flow.id=ac0ec149-6cd2-44cf-9369-a277d715ab90, spanId=f0f02c371a0a3b53, traceId=66c1b3e6729c8def5b5b8b6117032303, vnode.id=70D646C43105} - Flow [ac0ec149-6cd2-44cf-9369-a277d715ab90] completed successfully
2024-08-18 08:42:15.114 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723969934864, flow.id=138dfbc2-99f1-43b9-b508-9e989f8f9a95, spanId=2ab3e4895bdef831, traceId=66c1b3e6fa931df0ffd79ef0e16cd9a8, vnode.id=2F24A5C4BB8B} - Flow [138dfbc2-99f1-43b9-b508-9e989f8f9a95] started
2024-08-18 08:42:15.121 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 273 ms
2024-08-18 08:42:15.133 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723969934864, corda.external.event.id=138dfbc2-99f1-43b9-b508-9e989f8f9a95-YY5xfyYb/4NXGtmFGCnLAK/P7yZ8gQnQVH4cqn0czTw=-1, flow.id=138dfbc2-99f1-43b9-b508-9e989f8f9a95, spanId=33ee13b34ec48347, traceId=66c1b3e6fa931df0ffd79ef0e16cd9a8, vnode.id=2F24A5C4BB8B} - Flow [138dfbc2-99f1-43b9-b508-9e989f8f9a95] completed successfully
2024-08-18 08:42:15.135 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723969934864, flow.id=d15b440b-ceb6-476e-8103-231e14d9ecf6, spanId=bae46496aff94404, traceId=66c1b3e6f667fcfdb54ad8df4e27b300, vnode.id=F87FD80A917B} - Flow [d15b440b-ceb6-476e-8103-231e14d9ecf6] started
2024-08-18 08:42:15.150 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723969934864, corda.external.event.id=d15b440b-ceb6-476e-8103-231e14d9ecf6-YY5xfyYb/4NXGtmFGCnLAK/P7yZ8gQnQVH4cqn0czTw=-1, flow.id=d15b440b-ceb6-476e-8103-231e14d9ecf6, spanId=ab0b7244b1b52b12, traceId=66c1b3e6f667fcfdb54ad8df4e27b300, vnode.id=F87FD80A917B} - Flow [d15b440b-ceb6-476e-8103-231e14d9ecf6] completed successfully
2024-08-18 08:42:15.151 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723969934864, flow.id=3f1b8dde-4a34-4014-b889-f82661b415b5, spanId=7b048f34169d1ed0, traceId=66c1b3e688ae88ca7e6613d68e4bbc1b, vnode.id=E23A18A57E27} - Flow [3f1b8dde-4a34-4014-b889-f82661b415b5] started
2024-08-18 08:42:15.160 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723969934864, corda.external.event.id=3f1b8dde-4a34-4014-b889-f82661b415b5-YY5xfyYb/4NXGtmFGCnLAK/P7yZ8gQnQVH4cqn0czTw=-1, flow.id=3f1b8dde-4a34-4014-b889-f82661b415b5, spanId=3c530a10508ddf90, traceId=66c1b3e688ae88ca7e6613d68e4bbc1b, vnode.id=E23A18A57E27} - Flow [3f1b8dde-4a34-4014-b889-f82661b415b5] completed successfully
2024-08-18 08:42:19.038 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=bc54fe92ef179095, traceId=66c1b3eb717dafd3bc54fe92ef179095} - {"traceId":"66c1b3eb717dafd3bc54fe92ef179095","id":"bc54fe92ef179095","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723970539008419,"duration":30074,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"104","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 08:59:42.783 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before successfully committing offsets {flow.session-0=OffsetAndMetadata{offset=34, leaderEpoch=null, metadata=''}}
2024-08-18 08:59:42.785 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 08:59:42.906 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:59:42.910 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 08:59:42.925 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:59:42.926 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 08:59:42.937 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:59:42.938 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:59:42.938 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 08:59:42.938 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:59:42.938 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 08:59:42.938 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 08:59:42.940 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 08:59:42.939 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 08:59:42.947 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:59:42.947 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 08:59:42.961 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 08:59:42.961 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 08:59:42.961 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 08:59:53.684 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b99a99176670dfb7, traceId=66c1b8098655dbd1b99a99176670dfb7} - {"traceId":"66c1b8098655dbd1b99a99176670dfb7","id":"b99a99176670dfb7","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723971593636530,"duration":46252,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"106","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 09:00:02.991 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:00:03.000 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:00:03.055 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:00:03.055 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:00:03.076 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:00:03.076 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:00:03.079 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 09:00:03.079 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 09:00:03.079 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 09:08:29.363 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 09:08:29.366 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 09:08:40.201 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=54f471b974ee3eb7, traceId=66c1ba188a71e66754f471b974ee3eb7} - {"traceId":"66c1ba188a71e66754f471b974ee3eb7","id":"54f471b974ee3eb7","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723972120157487,"duration":42874,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"108","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 09:08:49.397 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:08:49.400 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:08:49.513 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:08:49.514 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:08:49.526 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 09:08:49.526 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 09:08:49.526 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 09:14:50.386 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 09:14:50.392 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 09:14:50.419 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 09:14:50.427 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 09:14:50.916 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:14:50.916 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:14:51.371 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:14:51.377 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:14:51.382 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 09:14:51.377 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 09:14:51.386 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 09:15:01.268 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=60d1b1df2ca50b95, traceId=66c1bb95f8d94eef60d1b1df2ca50b95} - {"traceId":"66c1bb95f8d94eef60d1b1df2ca50b95","id":"60d1b1df2ca50b95","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723972501216841,"duration":41137,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"110","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 09:31:26.871 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 09:31:26.871 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 09:31:26.871 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 09:31:26.875 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 09:31:26.875 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 09:31:26.875 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 09:31:27.345 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:31:27.352 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:31:27.798 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:31:27.810 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:31:27.806 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 09:31:27.812 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 09:31:27.799 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:31:27.814 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:31:27.813 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 09:31:27.814 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 09:31:27.814 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 09:31:27.815 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 09:31:33.351 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=3dad11e1b92db2cb, traceId=66c1bf75a58dfb923dad11e1b92db2cb} - {"traceId":"66c1bf75a58dfb923dad11e1b92db2cb","id":"3dad11e1b92db2cb","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723973493330903,"duration":18872,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"22","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 09:31:34.031 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723972893818, flow.id=294f018a-d6ea-46b4-92de-5d08847637f4, spanId=f858bc72571086e3, traceId=66c1bf7504cbfd5642156863214bfd63, vnode.id=E6376372B510} - Flow [294f018a-d6ea-46b4-92de-5d08847637f4] started
2024-08-18 09:31:34.153 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 452 ms
2024-08-18 09:31:34.158 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723972893818, corda.external.event.id=294f018a-d6ea-46b4-92de-5d08847637f4-922JaNLSLq75UPKeY+OHZiP6EuGei3Vni6PyeoTpvh4=-1, flow.id=294f018a-d6ea-46b4-92de-5d08847637f4, spanId=d772a1fc9c97081f, traceId=66c1bf7504cbfd5642156863214bfd63, vnode.id=E6376372B510} - Flow [294f018a-d6ea-46b4-92de-5d08847637f4] completed successfully
2024-08-18 09:31:34.162 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723972893821, flow.id=10ca4fa8-2839-43a1-a68f-4b463e8d9aa4, spanId=212b0fd2c4504254, traceId=66c1bf756a9585c9d0204bf9fbc2d660, vnode.id=70D646C43105} - Flow [10ca4fa8-2839-43a1-a68f-4b463e8d9aa4] started
2024-08-18 09:31:34.186 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723972893821, corda.external.event.id=10ca4fa8-2839-43a1-a68f-4b463e8d9aa4-xyn0yuUUSTLlnCttvNA3Iion66J1eOmSwTIakgG8aFQ=-1, flow.id=10ca4fa8-2839-43a1-a68f-4b463e8d9aa4, spanId=a3a94ca616e6fdde, traceId=66c1bf756a9585c9d0204bf9fbc2d660, vnode.id=70D646C43105} - Flow [10ca4fa8-2839-43a1-a68f-4b463e8d9aa4] completed successfully
2024-08-18 09:31:34.187 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723972893821, flow.id=3f25cc2c-b1b3-42e9-b27f-c10fcb198a5b, spanId=702088ccebba4957, traceId=66c1bf759aa29c5858de13d9672cdb98, vnode.id=2F24A5C4BB8B} - Flow [3f25cc2c-b1b3-42e9-b27f-c10fcb198a5b] started
2024-08-18 09:31:34.202 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723972893821, corda.external.event.id=3f25cc2c-b1b3-42e9-b27f-c10fcb198a5b-xyn0yuUUSTLlnCttvNA3Iion66J1eOmSwTIakgG8aFQ=-1, flow.id=3f25cc2c-b1b3-42e9-b27f-c10fcb198a5b, spanId=9098101138fd70a8, traceId=66c1bf759aa29c5858de13d9672cdb98, vnode.id=2F24A5C4BB8B} - Flow [3f25cc2c-b1b3-42e9-b27f-c10fcb198a5b] completed successfully
2024-08-18 09:31:34.203 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723972893821, flow.id=a90bf5c1-e2d6-47e0-aab7-927be698094d, spanId=a006d20cff15499f, traceId=66c1bf759efabb482705b9ae5da009dc, vnode.id=F87FD80A917B} - Flow [a90bf5c1-e2d6-47e0-aab7-927be698094d] started
2024-08-18 09:31:34.222 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723972893821, corda.external.event.id=a90bf5c1-e2d6-47e0-aab7-927be698094d-xyn0yuUUSTLlnCttvNA3Iion66J1eOmSwTIakgG8aFQ=-1, flow.id=a90bf5c1-e2d6-47e0-aab7-927be698094d, spanId=83394e42accb85bc, traceId=66c1bf759efabb482705b9ae5da009dc, vnode.id=F87FD80A917B} - Flow [a90bf5c1-e2d6-47e0-aab7-927be698094d] completed successfully
2024-08-18 09:31:34.224 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723972893821, flow.id=a6326891-18ed-4557-8b6e-7b88a31c6a3e, spanId=cfcca27682467add, traceId=66c1bf75f032d1d4180c98b49dfa3b89, vnode.id=E23A18A57E27} - Flow [a6326891-18ed-4557-8b6e-7b88a31c6a3e] started
2024-08-18 09:31:34.246 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723972893821, corda.external.event.id=a6326891-18ed-4557-8b6e-7b88a31c6a3e-xyn0yuUUSTLlnCttvNA3Iion66J1eOmSwTIakgG8aFQ=-1, flow.id=a6326891-18ed-4557-8b6e-7b88a31c6a3e, spanId=7960e6485d69bd0d, traceId=66c1bf75f032d1d4180c98b49dfa3b89, vnode.id=E23A18A57E27} - Flow [a6326891-18ed-4557-8b6e-7b88a31c6a3e] completed successfully
2024-08-18 09:31:37.759 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c74524a56c9d31f2, traceId=66c1bf79a38b5a9bc74524a56c9d31f2} - {"traceId":"66c1bf79a38b5a9bc74524a56c9d31f2","id":"c74524a56c9d31f2","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723973497733044,"duration":25625,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"112","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 09:50:42.522 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 09:50:42.555 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 09:50:43.064 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:50:43.066 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:50:43.543 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 09:50:43.548 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 09:50:43.552 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 09:50:43.548 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 09:50:43.556 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 09:50:53.271 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=81de7251d45a3c8c, traceId=66c1c3fd5d99711381de7251d45a3c8c} - {"traceId":"66c1c3fd5d99711381de7251d45a3c8c","id":"81de7251d45a3c8c","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723974653233941,"duration":23313,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"114","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 09:59:15.886 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=69e4ba82e277a06a, traceId=66c1c5f36f3794aa69e4ba82e277a06a} - {"traceId":"66c1c5f36f3794aa69e4ba82e277a06a","id":"69e4ba82e277a06a","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723975155836938,"duration":48364,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"116","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 10:00:43.017 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=67dc4c575409f140, traceId=66c1c64a6352a73e67dc4c575409f140} - {"traceId":"66c1c64a6352a73e67dc4c575409f140","id":"67dc4c575409f140","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723975242986097,"duration":28995,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"118","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 10:17:06.260 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=72328c70a3d23005, traceId=66c1ca2275cc929e72328c70a3d23005} - {"traceId":"66c1ca2275cc929e72328c70a3d23005","id":"72328c70a3d23005","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723976226234692,"duration":24495,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"24","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 10:17:06.470 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 187 ms
2024-08-18 10:17:06.745 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723975626675, flow.id=dd986b99-ff8b-45ab-8492-97c20f3b558d, spanId=e2993c878b65e56a, traceId=66c1ca2274540a3674a2785462a57e0f, vnode.id=E6376372B510} - Flow [dd986b99-ff8b-45ab-8492-97c20f3b558d] started
2024-08-18 10:17:06.806 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723975626675, corda.external.event.id=dd986b99-ff8b-45ab-8492-97c20f3b558d-9EZ9xB93fLc7qPwVZ+p5OCXva7T5nTOLwhtMpf/FGyY=-1, flow.id=dd986b99-ff8b-45ab-8492-97c20f3b558d, spanId=a97f2d1c6653ffab, traceId=66c1ca2274540a3674a2785462a57e0f, vnode.id=E6376372B510} - Flow [dd986b99-ff8b-45ab-8492-97c20f3b558d] completed successfully
2024-08-18 10:17:06.807 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723975626677, flow.id=406163db-e4ea-4594-8974-0115af7cbbcd, spanId=ee7ce76748889725, traceId=66c1ca22231ce28eff11c95fa3362dc9, vnode.id=70D646C43105} - Flow [406163db-e4ea-4594-8974-0115af7cbbcd] started
2024-08-18 10:17:06.826 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723975626677, corda.external.event.id=406163db-e4ea-4594-8974-0115af7cbbcd-jvYDbPDhIlzhqUKxVJ8tI51lAIlcANuuhAyUgc0Xnm4=-1, flow.id=406163db-e4ea-4594-8974-0115af7cbbcd, spanId=5b85c909ec9a4d83, traceId=66c1ca22231ce28eff11c95fa3362dc9, vnode.id=70D646C43105} - Flow [406163db-e4ea-4594-8974-0115af7cbbcd] completed successfully
2024-08-18 10:17:06.829 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723975626677, flow.id=c569d4a4-f2ee-4d2e-908a-654f637f923a, spanId=69d2230b95d31244, traceId=66c1ca221fe26be42a5f6052b4c42b3f, vnode.id=2F24A5C4BB8B} - Flow [c569d4a4-f2ee-4d2e-908a-654f637f923a] started
2024-08-18 10:17:06.865 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723975626677, corda.external.event.id=c569d4a4-f2ee-4d2e-908a-654f637f923a-jvYDbPDhIlzhqUKxVJ8tI51lAIlcANuuhAyUgc0Xnm4=-1, flow.id=c569d4a4-f2ee-4d2e-908a-654f637f923a, spanId=d6b5ace75c1807c2, traceId=66c1ca221fe26be42a5f6052b4c42b3f, vnode.id=2F24A5C4BB8B} - Flow [c569d4a4-f2ee-4d2e-908a-654f637f923a] completed successfully
2024-08-18 10:17:06.869 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723975626677, flow.id=f57f2bbb-331c-4ccc-b8dc-aacd5ca830b9, spanId=eae088da57b4cb16, traceId=66c1ca22929e21bfa7f46e885ee16fae, vnode.id=F87FD80A917B} - Flow [f57f2bbb-331c-4ccc-b8dc-aacd5ca830b9] started
2024-08-18 10:17:06.879 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723975626677, corda.external.event.id=f57f2bbb-331c-4ccc-b8dc-aacd5ca830b9-jvYDbPDhIlzhqUKxVJ8tI51lAIlcANuuhAyUgc0Xnm4=-1, flow.id=f57f2bbb-331c-4ccc-b8dc-aacd5ca830b9, spanId=c6cc9495175dc885, traceId=66c1ca22929e21bfa7f46e885ee16fae, vnode.id=F87FD80A917B} - Flow [f57f2bbb-331c-4ccc-b8dc-aacd5ca830b9] completed successfully
2024-08-18 10:17:06.880 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723975626677, flow.id=31a626ec-ec30-439c-90bd-60e5504f0ea8, spanId=7b5e6ccda2080755, traceId=66c1ca220791adfb90d6d3e640935b32, vnode.id=E23A18A57E27} - Flow [31a626ec-ec30-439c-90bd-60e5504f0ea8] started
2024-08-18 10:17:06.892 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723975626677, corda.external.event.id=31a626ec-ec30-439c-90bd-60e5504f0ea8-jvYDbPDhIlzhqUKxVJ8tI51lAIlcANuuhAyUgc0Xnm4=-1, flow.id=31a626ec-ec30-439c-90bd-60e5504f0ea8, spanId=bf219078e7e6cfce, traceId=66c1ca220791adfb90d6d3e640935b32, vnode.id=E23A18A57E27} - Flow [31a626ec-ec30-439c-90bd-60e5504f0ea8] completed successfully
2024-08-18 10:17:10.865 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d93f0ff32ff0eca4, traceId=66c1ca268570411cd93f0ff32ff0eca4} - {"traceId":"66c1ca268570411cd93f0ff32ff0eca4","id":"d93f0ff32ff0eca4","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723976230821747,"duration":42557,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"120","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 10:35:26.997 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:35:26.999 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 10:35:27.017 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:35:27.020 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 10:35:27.444 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 10:35:27.452 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 10:35:27.507 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 10:35:27.508 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 10:35:27.969 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 10:35:27.972 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 10:35:27.976 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 10:35:27.981 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 10:35:27.981 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 10:35:38.065 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=37aed8f6ed3ed5ef, traceId=66c1ce7ad1049e7437aed8f6ed3ed5ef} - {"traceId":"66c1ce7ad1049e7437aed8f6ed3ed5ef","id":"37aed8f6ed3ed5ef","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723977338021369,"duration":42886,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"122","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 10:35:47.073 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 10:35:47.079 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 10:35:47.204 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 10:35:47.207 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 10:35:47.212 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 10:35:47.212 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 10:35:47.212 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 10:43:05.331 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:43:05.331 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:43:05.331 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:43:05.331 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:43:05.332 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 10:43:05.334 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 10:43:05.334 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 10:43:05.334 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 10:43:05.334 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 10:43:05.334 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 10:43:06.304 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 10:43:06.306 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 10:43:06.307 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 10:43:06.308 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 10:43:06.310 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 10:43:08.347 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 10:43:08.347 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 10:43:08.353 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 10:43:16.478 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=aa3cff677312cfcc, traceId=66c1d0440c8eb63daa3cff677312cfcc} - {"traceId":"66c1d0440c8eb63daa3cff677312cfcc","id":"aa3cff677312cfcc","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723977796427436,"duration":49185,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"124","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 10:49:33.677 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b551034772a653cf, traceId=66c1d1bd54b5be02b551034772a653cf} - {"traceId":"66c1d1bd54b5be02b551034772a653cf","id":"b551034772a653cf","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723978173646978,"duration":27769,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"126","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 11:05:14.869 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=620ba395d241d6ba, traceId=66c1d56a68693517620ba395d241d6ba} - {"traceId":"66c1d56a68693517620ba395d241d6ba","id":"620ba395d241d6ba","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723979114813424,"duration":54377,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"26","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 11:05:15.166 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 285 ms
2024-08-18 11:05:15.258 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723978515206, flow.id=16df42ba-afa4-4c6c-a3bc-9a9a7c237ef9, spanId=5176645d83874300, traceId=66c1d56b7e1f3afcb6774a0506666403, vnode.id=E6376372B510} - Flow [16df42ba-afa4-4c6c-a3bc-9a9a7c237ef9] started
2024-08-18 11:05:15.312 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723978515206, corda.external.event.id=16df42ba-afa4-4c6c-a3bc-9a9a7c237ef9-h9n1qcoXR8dyerao1TFXp4tVQUZZrQ+OPds9wxngJ84=-1, flow.id=16df42ba-afa4-4c6c-a3bc-9a9a7c237ef9, spanId=32cf1536c57a40f7, traceId=66c1d56b7e1f3afcb6774a0506666403, vnode.id=E6376372B510} - Flow [16df42ba-afa4-4c6c-a3bc-9a9a7c237ef9] completed successfully
2024-08-18 11:05:15.313 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723978515207, flow.id=93249364-6306-42b6-b120-f4e5949fd859, spanId=97904e1d1a49b58b, traceId=66c1d56b0ea6aacb1770a59d0cd8798b, vnode.id=70D646C43105} - Flow [93249364-6306-42b6-b120-f4e5949fd859] started
2024-08-18 11:05:15.325 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723978515207, corda.external.event.id=93249364-6306-42b6-b120-f4e5949fd859-ftSRc30Y5h6w5TgrkvilYT3ZwbfAeWgAt1QN9SrleB4=-1, flow.id=93249364-6306-42b6-b120-f4e5949fd859, spanId=3b26d43fa2746c10, traceId=66c1d56b0ea6aacb1770a59d0cd8798b, vnode.id=70D646C43105} - Flow [93249364-6306-42b6-b120-f4e5949fd859] completed successfully
2024-08-18 11:05:15.325 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723978515207, flow.id=6216481f-5452-46f0-b93a-ff988cf933cb, spanId=29944b2108eaf96b, traceId=66c1d56bba0343506cc5ec42ed690009, vnode.id=2F24A5C4BB8B} - Flow [6216481f-5452-46f0-b93a-ff988cf933cb] started
2024-08-18 11:05:15.338 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723978515207, corda.external.event.id=6216481f-5452-46f0-b93a-ff988cf933cb-ftSRc30Y5h6w5TgrkvilYT3ZwbfAeWgAt1QN9SrleB4=-1, flow.id=6216481f-5452-46f0-b93a-ff988cf933cb, spanId=21e97c304422fd99, traceId=66c1d56bba0343506cc5ec42ed690009, vnode.id=2F24A5C4BB8B} - Flow [6216481f-5452-46f0-b93a-ff988cf933cb] completed successfully
2024-08-18 11:05:15.339 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723978515207, flow.id=28d8ea97-21f5-42d2-9345-66258917d51a, spanId=c9d94169e8a00f53, traceId=66c1d56bd23617ea2891fb0a84bd57f4, vnode.id=F87FD80A917B} - Flow [28d8ea97-21f5-42d2-9345-66258917d51a] started
2024-08-18 11:05:15.354 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723978515207, corda.external.event.id=28d8ea97-21f5-42d2-9345-66258917d51a-ftSRc30Y5h6w5TgrkvilYT3ZwbfAeWgAt1QN9SrleB4=-1, flow.id=28d8ea97-21f5-42d2-9345-66258917d51a, spanId=b2d6da3983758541, traceId=66c1d56bd23617ea2891fb0a84bd57f4, vnode.id=F87FD80A917B} - Flow [28d8ea97-21f5-42d2-9345-66258917d51a] completed successfully
2024-08-18 11:05:15.356 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723978515207, flow.id=6955936f-325f-42f5-a913-ddd6c635dcb7, spanId=ff11b3df4672e3a2, traceId=66c1d56bba009d7c7d29e49ade000397, vnode.id=E23A18A57E27} - Flow [6955936f-325f-42f5-a913-ddd6c635dcb7] started
2024-08-18 11:05:15.373 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723978515207, corda.external.event.id=6955936f-325f-42f5-a913-ddd6c635dcb7-ftSRc30Y5h6w5TgrkvilYT3ZwbfAeWgAt1QN9SrleB4=-1, flow.id=6955936f-325f-42f5-a913-ddd6c635dcb7, spanId=dd288fe2712ba77e, traceId=66c1d56bba009d7c7d29e49ade000397, vnode.id=E23A18A57E27} - Flow [6955936f-325f-42f5-a913-ddd6c635dcb7] completed successfully
2024-08-18 11:05:20.081 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=14a0dab64950bd84, traceId=66c1d5701434eaca14a0dab64950bd84} - {"traceId":"66c1d5701434eaca14a0dab64950bd84","id":"14a0dab64950bd84","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723979120017272,"duration":63253,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"128","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 11:14:16.936 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=20a850adf5cf6693, traceId=66c1d788557a9eed20a850adf5cf6693} - {"traceId":"66c1d788557a9eed20a850adf5cf6693","id":"20a850adf5cf6693","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723979656870912,"duration":64365,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"130","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 11:23:34.255 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 11:23:34.255 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 11:23:34.259 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 11:23:34.259 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 11:23:35.242 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 11:23:35.244 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 11:23:35.244 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 11:23:35.245 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 11:23:35.248 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 11:23:45.563 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4e9aa3d80a54f8c0, traceId=66c1d9c15519c46a4e9aa3d80a54f8c0} - {"traceId":"66c1d9c15519c46a4e9aa3d80a54f8c0","id":"4e9aa3d80a54f8c0","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723980225522326,"duration":39731,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"132","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 11:45:33.586 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1d598606c3a32124, traceId=66c1dedd8e9212e11d598606c3a32124} - {"traceId":"66c1dedd8e9212e11d598606c3a32124","id":"1d598606c3a32124","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723981533558566,"duration":27066,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"134","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 11:56:29.808 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 11:56:29.808 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 11:56:29.810 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 11:56:29.811 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 11:56:29.811 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 11:56:29.811 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 11:56:35.788 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=0f74bbb68d15069d, traceId=66c1e17328da01840f74bbb68d15069d} - {"traceId":"66c1e17328da01840f74bbb68d15069d","id":"0f74bbb68d15069d","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723982195740223,"duration":41245,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"28","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 11:56:35.921 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 119 ms
2024-08-18 11:56:41.233 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1c23bfa8d267f431, traceId=66c1e1797698312e1c23bfa8d267f431} - {"traceId":"66c1e1797698312e1c23bfa8d267f431","id":"1c23bfa8d267f431","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723982201223691,"duration":9668,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"136","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 11:56:49.839 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 11:56:49.845 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 11:56:49.834 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 11:56:49.850 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 11:56:49.850 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 11:56:49.851 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 11:56:49.851 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 11:56:49.852 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 11:56:49.851 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 11:56:49.854 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 11:56:49.855 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 11:56:49.854 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 11:56:49.906 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723981596050, flow.id=153c2e12-1dc9-48bb-8a9a-fee9b6219cf3, spanId=9807098383757902, traceId=66c1e174b367296a8f561a6ab4fb1c67, vnode.id=E6376372B510} - Flow [153c2e12-1dc9-48bb-8a9a-fee9b6219cf3] started
2024-08-18 11:56:49.986 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723981596050, corda.external.event.id=153c2e12-1dc9-48bb-8a9a-fee9b6219cf3-NSCr8AI8aLsDa6I3AoSq0u7HazdOy4BVgH999cLrNJg=-1, flow.id=153c2e12-1dc9-48bb-8a9a-fee9b6219cf3, spanId=354eb32b4765ea57, traceId=66c1e174b367296a8f561a6ab4fb1c67, vnode.id=E6376372B510} - Flow [153c2e12-1dc9-48bb-8a9a-fee9b6219cf3] completed successfully
2024-08-18 11:56:49.987 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723981596051, flow.id=8e659809-beca-4d3e-b2ae-af1add0ec690, spanId=05100943e2fcc677, traceId=66c1e1741ca9ada03990430ca3ce2d81, vnode.id=70D646C43105} - Flow [8e659809-beca-4d3e-b2ae-af1add0ec690] started
2024-08-18 11:56:50.014 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723981596051, corda.external.event.id=8e659809-beca-4d3e-b2ae-af1add0ec690-5MiDpKzUBE56LOnSzvlTNAFDGeU0i2Y6/Aq8qxJjADE=-1, flow.id=8e659809-beca-4d3e-b2ae-af1add0ec690, spanId=139de53a9d7fc765, traceId=66c1e1741ca9ada03990430ca3ce2d81, vnode.id=70D646C43105} - Flow [8e659809-beca-4d3e-b2ae-af1add0ec690] completed successfully
2024-08-18 11:56:50.015 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723981596051, flow.id=e4f148f8-d088-4537-b1ff-2118fd3d54e7, spanId=68c4d53641f0d5a6, traceId=66c1e174c54e235288bf4ec089aae38c, vnode.id=2F24A5C4BB8B} - Flow [e4f148f8-d088-4537-b1ff-2118fd3d54e7] started
2024-08-18 11:56:50.032 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723981596051, corda.external.event.id=e4f148f8-d088-4537-b1ff-2118fd3d54e7-5MiDpKzUBE56LOnSzvlTNAFDGeU0i2Y6/Aq8qxJjADE=-1, flow.id=e4f148f8-d088-4537-b1ff-2118fd3d54e7, spanId=8d62a457b0201293, traceId=66c1e174c54e235288bf4ec089aae38c, vnode.id=2F24A5C4BB8B} - Flow [e4f148f8-d088-4537-b1ff-2118fd3d54e7] completed successfully
2024-08-18 11:56:50.033 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723981596051, flow.id=582552dc-f30a-4b37-8f8a-82b4d1371a77, spanId=cf940ff4b9b12536, traceId=66c1e174f6bfcae088861a68a666bc8d, vnode.id=F87FD80A917B} - Flow [582552dc-f30a-4b37-8f8a-82b4d1371a77] started
2024-08-18 11:56:50.052 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723981596051, corda.external.event.id=582552dc-f30a-4b37-8f8a-82b4d1371a77-5MiDpKzUBE56LOnSzvlTNAFDGeU0i2Y6/Aq8qxJjADE=-1, flow.id=582552dc-f30a-4b37-8f8a-82b4d1371a77, spanId=aa1ac9139d6ac78e, traceId=66c1e174f6bfcae088861a68a666bc8d, vnode.id=F87FD80A917B} - Flow [582552dc-f30a-4b37-8f8a-82b4d1371a77] completed successfully
2024-08-18 11:56:50.052 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723981596051, flow.id=f1d8266a-520a-43fe-a6c4-07158e67f768, spanId=7d996561f48cd76b, traceId=66c1e17401598fb6efaa310d6383bf54, vnode.id=E23A18A57E27} - Flow [f1d8266a-520a-43fe-a6c4-07158e67f768] started
2024-08-18 11:56:50.069 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723981596051, corda.external.event.id=f1d8266a-520a-43fe-a6c4-07158e67f768-5MiDpKzUBE56LOnSzvlTNAFDGeU0i2Y6/Aq8qxJjADE=-1, flow.id=f1d8266a-520a-43fe-a6c4-07158e67f768, spanId=ae646700c32653f9, traceId=66c1e17401598fb6efaa310d6383bf54, vnode.id=E23A18A57E27} - Flow [f1d8266a-520a-43fe-a6c4-07158e67f768] completed successfully
2024-08-18 12:09:18.910 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f714eb54cdd06b3c, traceId=66c1e46ec34972ccf714eb54cdd06b3c} - {"traceId":"66c1e46ec34972ccf714eb54cdd06b3c","id":"f714eb54cdd06b3c","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723982958884454,"duration":25401,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"138","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 12:19:17.535 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:19:17.541 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 12:19:17.968 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:19:17.969 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:19:18.421 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:19:18.422 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:19:18.424 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 12:19:18.426 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 12:19:18.426 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 12:19:29.117 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c2bb75f62d8928ab, traceId=66c1e6d16f0d7d09c2bb75f62d8928ab} - {"traceId":"66c1e6d16f0d7d09c2bb75f62d8928ab","id":"c2bb75f62d8928ab","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723983569071404,"duration":44215,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"140","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 12:37:15.432 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:37:15.434 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:37:15.435 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 12:37:15.435 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 12:37:15.466 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:37:15.467 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 12:37:15.963 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:37:15.966 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:37:15.985 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:37:15.991 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:37:16.506 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:37:16.507 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:37:16.511 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 12:37:16.509 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 12:37:16.509 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 12:37:27.155 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1e2919478bfd48ce, traceId=66c1eb0759c0ba011e2919478bfd48ce} - {"traceId":"66c1eb0759c0ba011e2919478bfd48ce","id":"1e2919478bfd48ce","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723984647114303,"duration":40057,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"142","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 12:37:35.438 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:37:35.443 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:37:35.478 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 12:37:35.478 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 12:37:35.478 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 12:45:28.022 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:45:28.026 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 12:45:28.030 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:45:28.030 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 12:45:28.035 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:45:28.035 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 12:45:28.533 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:45:28.540 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:45:28.951 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:45:28.953 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:45:28.956 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 12:45:28.960 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 12:45:28.968 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 12:45:34.000 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=01aefedf2b70ec5a, traceId=66c1ecedc53d843b01aefedf2b70ec5a} - {"traceId":"66c1ecedc53d843b01aefedf2b70ec5a","id":"01aefedf2b70ec5a","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723985133983747,"duration":16213,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"30","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 12:45:34.134 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 103 ms
2024-08-18 12:45:34.276 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723984534238, flow.id=36085969-227a-462f-bfb5-0139e390a123, spanId=ccc3003fb280bc25, traceId=66c1eceeaae8ede1893f90d2608c2389, vnode.id=E6376372B510} - Flow [36085969-227a-462f-bfb5-0139e390a123] started
2024-08-18 12:45:34.339 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723984534238, corda.external.event.id=36085969-227a-462f-bfb5-0139e390a123-92K0HHA/5aJwB0RGid8k5TVNxqKVOdnLymrINw1rn/U=-1, flow.id=36085969-227a-462f-bfb5-0139e390a123, spanId=0051213267b691fa, traceId=66c1eceeaae8ede1893f90d2608c2389, vnode.id=E6376372B510} - Flow [36085969-227a-462f-bfb5-0139e390a123] completed successfully
2024-08-18 12:45:34.340 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723984534239, flow.id=16392dc9-1b31-4688-957c-772f89fbfebb, spanId=6386d5324adb3684, traceId=66c1eceecdc2ad4f258627475085c38a, vnode.id=70D646C43105} - Flow [16392dc9-1b31-4688-957c-772f89fbfebb] started
2024-08-18 12:45:34.349 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723984534239, corda.external.event.id=16392dc9-1b31-4688-957c-772f89fbfebb-WPfic9awHAwfnSTGpv7Fs5+UsjQ1O2IgMlVD1F5MECE=-1, flow.id=16392dc9-1b31-4688-957c-772f89fbfebb, spanId=d19d0c512b51c273, traceId=66c1eceecdc2ad4f258627475085c38a, vnode.id=70D646C43105} - Flow [16392dc9-1b31-4688-957c-772f89fbfebb] completed successfully
2024-08-18 12:45:34.350 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723984534239, flow.id=0123370a-912f-461f-a72c-41d2245dbfd5, spanId=625466a89ca80fa9, traceId=66c1ecee8d43b001c31bf5665a052c85, vnode.id=2F24A5C4BB8B} - Flow [0123370a-912f-461f-a72c-41d2245dbfd5] started
2024-08-18 12:45:34.362 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723984534239, corda.external.event.id=0123370a-912f-461f-a72c-41d2245dbfd5-WPfic9awHAwfnSTGpv7Fs5+UsjQ1O2IgMlVD1F5MECE=-1, flow.id=0123370a-912f-461f-a72c-41d2245dbfd5, spanId=68830330941179ae, traceId=66c1ecee8d43b001c31bf5665a052c85, vnode.id=2F24A5C4BB8B} - Flow [0123370a-912f-461f-a72c-41d2245dbfd5] completed successfully
2024-08-18 12:45:34.362 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723984534239, flow.id=97f378d3-b247-4d06-8d06-ec99477b7c4b, spanId=140fa5d7dfa6b17d, traceId=66c1eceed7f0bf9b81a0112045e59db1, vnode.id=F87FD80A917B} - Flow [97f378d3-b247-4d06-8d06-ec99477b7c4b] started
2024-08-18 12:45:34.370 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723984534239, corda.external.event.id=97f378d3-b247-4d06-8d06-ec99477b7c4b-WPfic9awHAwfnSTGpv7Fs5+UsjQ1O2IgMlVD1F5MECE=-1, flow.id=97f378d3-b247-4d06-8d06-ec99477b7c4b, spanId=ad8be5fcebc19d1b, traceId=66c1eceed7f0bf9b81a0112045e59db1, vnode.id=F87FD80A917B} - Flow [97f378d3-b247-4d06-8d06-ec99477b7c4b] completed successfully
2024-08-18 12:45:34.371 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723984534239, flow.id=46ac2c38-fc9f-453f-8d1a-08d5ebdd775d, spanId=e031d5ec33a80e3e, traceId=66c1eceec1e1dcd751023ae56d42cd9d, vnode.id=E23A18A57E27} - Flow [46ac2c38-fc9f-453f-8d1a-08d5ebdd775d] started
2024-08-18 12:45:34.379 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723984534239, corda.external.event.id=46ac2c38-fc9f-453f-8d1a-08d5ebdd775d-WPfic9awHAwfnSTGpv7Fs5+UsjQ1O2IgMlVD1F5MECE=-1, flow.id=46ac2c38-fc9f-453f-8d1a-08d5ebdd775d, spanId=a7dea27fc90c49b5, traceId=66c1eceec1e1dcd751023ae56d42cd9d, vnode.id=E23A18A57E27} - Flow [46ac2c38-fc9f-453f-8d1a-08d5ebdd775d] completed successfully
2024-08-18 12:45:39.750 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=3189de695de582e9, traceId=66c1ecf31ca46deb3189de695de582e9} - {"traceId":"66c1ecf31ca46deb3189de695de582e9","id":"3189de695de582e9","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723985139730378,"duration":19693,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"144","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 12:45:48.049 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 12:45:48.049 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 12:45:48.049 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 12:47:55.848 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2390e130c0c9e677, traceId=66c1ed7b978d77692390e130c0c9e677} - {"traceId":"66c1ed7b978d77692390e130c0c9e677","id":"2390e130c0c9e677","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723985275815285,"duration":30513,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"146","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 12:54:30.405 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 12:54:30.440 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 12:54:30.963 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:54:30.965 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:54:31.423 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 12:54:31.424 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 12:54:31.425 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 12:54:31.427 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 12:54:31.427 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 12:54:41.960 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=405dcd1bbbc97a8b, traceId=66c1ef11770a4cd3405dcd1bbbc97a8b} - {"traceId":"66c1ef11770a4cd3405dcd1bbbc97a8b","id":"405dcd1bbbc97a8b","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723985681916754,"duration":41984,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"148","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 12:59:04.452 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=df905013131e3032, traceId=66c1f0186225e9f5df905013131e3032} - {"traceId":"66c1f0186225e9f5df905013131e3032","id":"df905013131e3032","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723985944427479,"duration":23916,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"150","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:14:26.300 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:14:26.300 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:14:26.300 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:14:26.303 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 13:14:26.303 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 13:14:26.303 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 13:14:27.283 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:14:27.284 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:14:27.285 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 13:14:27.285 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 13:14:27.288 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 13:14:32.242 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=dea9c86d85f81d7f, traceId=66c1f3b860779c6adea9c86d85f81d7f} - {"traceId":"66c1f3b860779c6adea9c86d85f81d7f","id":"dea9c86d85f81d7f","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723986872224794,"duration":17203,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"32","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 13:14:32.366 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 115 ms
2024-08-18 13:14:32.499 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723986272454, flow.id=04bc50d2-213c-4e59-abd2-f93d1395d61f, spanId=1ed757b29c2ecd0a, traceId=66c1f3b8c4ef98cf669fafd99d8a026f, vnode.id=E6376372B510} - Flow [04bc50d2-213c-4e59-abd2-f93d1395d61f] started
2024-08-18 13:14:32.598 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723986272454, corda.external.event.id=04bc50d2-213c-4e59-abd2-f93d1395d61f-3tu9dI3xZ6G9lnk08JlXV45YolqJ7R0o9VVp8jiNL+c=-1, flow.id=04bc50d2-213c-4e59-abd2-f93d1395d61f, spanId=5b27102d15de6683, traceId=66c1f3b8c4ef98cf669fafd99d8a026f, vnode.id=E6376372B510} - Flow [04bc50d2-213c-4e59-abd2-f93d1395d61f] completed successfully
2024-08-18 13:14:32.598 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723986272456, flow.id=31c1feff-3e07-4778-b9b5-6e1e741e4ab1, spanId=b394dfd37d0d6dae, traceId=66c1f3b8d97b0d0a390ba5cd72903916, vnode.id=70D646C43105} - Flow [31c1feff-3e07-4778-b9b5-6e1e741e4ab1] started
2024-08-18 13:14:32.609 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723986272456, corda.external.event.id=31c1feff-3e07-4778-b9b5-6e1e741e4ab1-7xu7f3ThkyKsl/UlNrHyh/2Cg5hkbWigcXhhSOPIn2c=-1, flow.id=31c1feff-3e07-4778-b9b5-6e1e741e4ab1, spanId=21da6892ed63281e, traceId=66c1f3b8d97b0d0a390ba5cd72903916, vnode.id=70D646C43105} - Flow [31c1feff-3e07-4778-b9b5-6e1e741e4ab1] completed successfully
2024-08-18 13:14:32.611 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723986272456, flow.id=035589b0-b43d-4546-9fda-fbe134f6c637, spanId=836afcd8d2a6d210, traceId=66c1f3b82d104433a63b08da6dd98707, vnode.id=2F24A5C4BB8B} - Flow [035589b0-b43d-4546-9fda-fbe134f6c637] started
2024-08-18 13:14:32.622 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723986272456, corda.external.event.id=035589b0-b43d-4546-9fda-fbe134f6c637-7xu7f3ThkyKsl/UlNrHyh/2Cg5hkbWigcXhhSOPIn2c=-1, flow.id=035589b0-b43d-4546-9fda-fbe134f6c637, spanId=f8370bc7e1bbb051, traceId=66c1f3b82d104433a63b08da6dd98707, vnode.id=2F24A5C4BB8B} - Flow [035589b0-b43d-4546-9fda-fbe134f6c637] completed successfully
2024-08-18 13:14:32.623 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723986272456, flow.id=65a22c1e-737d-48b1-857d-323ba12097bf, spanId=7428479732f63363, traceId=66c1f3b8c5b259dd078174e26fd0d7b3, vnode.id=F87FD80A917B} - Flow [65a22c1e-737d-48b1-857d-323ba12097bf] started
2024-08-18 13:14:32.643 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723986272456, corda.external.event.id=65a22c1e-737d-48b1-857d-323ba12097bf-7xu7f3ThkyKsl/UlNrHyh/2Cg5hkbWigcXhhSOPIn2c=-1, flow.id=65a22c1e-737d-48b1-857d-323ba12097bf, spanId=5b71ef00da0df8cd, traceId=66c1f3b8c5b259dd078174e26fd0d7b3, vnode.id=F87FD80A917B} - Flow [65a22c1e-737d-48b1-857d-323ba12097bf] completed successfully
2024-08-18 13:14:32.646 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723986272456, flow.id=0a7c9fcc-dca4-4860-b60a-41dc56a20722, spanId=6f46cabf57b43ebe, traceId=66c1f3b82bc5b0d0231744dfb9ccf1b9, vnode.id=E23A18A57E27} - Flow [0a7c9fcc-dca4-4860-b60a-41dc56a20722] started
2024-08-18 13:14:32.669 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723986272456, corda.external.event.id=0a7c9fcc-dca4-4860-b60a-41dc56a20722-7xu7f3ThkyKsl/UlNrHyh/2Cg5hkbWigcXhhSOPIn2c=-1, flow.id=0a7c9fcc-dca4-4860-b60a-41dc56a20722, spanId=01f06fab88ad8f43, traceId=66c1f3b82bc5b0d0231744dfb9ccf1b9, vnode.id=E23A18A57E27} - Flow [0a7c9fcc-dca4-4860-b60a-41dc56a20722] completed successfully
2024-08-18 13:14:38.217 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=54c98b004da0a2fe, traceId=66c1f3be002844ff54c98b004da0a2fe} - {"traceId":"66c1f3be002844ff54c98b004da0a2fe","id":"54c98b004da0a2fe","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723986878176186,"duration":36927,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"152","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:14:46.308 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:14:46.315 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:14:46.385 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:14:46.385 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:14:46.551 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:14:46.552 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:14:46.556 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 13:14:46.556 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 13:14:46.556 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:23:18.891 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:23:18.892 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:23:18.892 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:23:18.891 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:23:18.891 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:23:18.895 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 13:23:18.895 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 13:23:18.895 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 13:23:18.895 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 13:23:18.895 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 13:23:21.935 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:23:21.935 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:23:21.935 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:23:30.829 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f2137af26ae078f9, traceId=66c1f5d29bd09acaf2137af26ae078f9} - {"traceId":"66c1f5d29bd09acaf2137af26ae078f9","id":"f2137af26ae078f9","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723987410802351,"duration":25939,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"154","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:23:39.058 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:23:39.060 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 13:23:39.060 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 13:23:39.061 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:23:39.063 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 13:25:49.792 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f55ef063c344e356, traceId=66c1f65dd551cdebf55ef063c344e356} - {"traceId":"66c1f65dd551cdebf55ef063c344e356","id":"f55ef063c344e356","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723987549757596,"duration":32878,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"156","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:34:04.274 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:34:04.273 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:34:04.273 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:34:04.273 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:34:04.276 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 13:34:04.276 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 13:34:04.276 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 13:34:04.276 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 13:34:05.202 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:34:05.203 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:34:05.204 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 13:34:05.204 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 13:34:05.206 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 13:34:05.250 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:34:05.251 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:34:05.251 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:34:05.252 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:34:05.252 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 13:34:16.321 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b393a43cc8397da9, traceId=66c1f858fc1f8ffab393a43cc8397da9} - {"traceId":"66c1f858fc1f8ffab393a43cc8397da9","id":"b393a43cc8397da9","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723988056283795,"duration":36580,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"158","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:35:22.514 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=27e71ceceb679146, traceId=66c1f89a3446b2a827e71ceceb679146} - {"traceId":"66c1f89a3446b2a827e71ceceb679146","id":"27e71ceceb679146","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723988122484925,"duration":26630,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"34","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 13:35:22.679 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 138 ms
2024-08-18 13:35:22.747 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723987522680, flow.id=6ca1cce5-2f7a-482d-83f6-80d645b10320, spanId=84e52b11c74cf51e, traceId=66c1f89a9f0386330797fad03ad5346d, vnode.id=E6376372B510} - Flow [6ca1cce5-2f7a-482d-83f6-80d645b10320] started
2024-08-18 13:35:22.811 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723987522680, corda.external.event.id=6ca1cce5-2f7a-482d-83f6-80d645b10320-ynvxyWLz+HHDEsv34fsh1lMXzAKCVzQpEZ1bcQPmpvU=-1, flow.id=6ca1cce5-2f7a-482d-83f6-80d645b10320, spanId=1e8e7cee194a0257, traceId=66c1f89a9f0386330797fad03ad5346d, vnode.id=E6376372B510} - Flow [6ca1cce5-2f7a-482d-83f6-80d645b10320] completed successfully
2024-08-18 13:35:22.812 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723987522682, flow.id=789d89a8-b615-4c5e-bc9a-bba71c672e04, spanId=1ff4147e5e286038, traceId=66c1f89adb4c568ab721b52608ce59c8, vnode.id=70D646C43105} - Flow [789d89a8-b615-4c5e-bc9a-bba71c672e04] started
2024-08-18 13:35:22.822 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723987522682, corda.external.event.id=789d89a8-b615-4c5e-bc9a-bba71c672e04-g5uiC+o6gYj5mguLcCA64p8b4iY/TEDm1P9swC9uEZQ=-1, flow.id=789d89a8-b615-4c5e-bc9a-bba71c672e04, spanId=2bb8f5d457eb56b2, traceId=66c1f89adb4c568ab721b52608ce59c8, vnode.id=70D646C43105} - Flow [789d89a8-b615-4c5e-bc9a-bba71c672e04] completed successfully
2024-08-18 13:35:22.822 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723987522682, flow.id=0398e0d9-64df-410a-be59-d397bca4b254, spanId=b9f1091b62689456, traceId=66c1f89ad8a4fd78e05e1e3d2ed4226e, vnode.id=2F24A5C4BB8B} - Flow [0398e0d9-64df-410a-be59-d397bca4b254] started
2024-08-18 13:35:22.834 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723987522682, corda.external.event.id=0398e0d9-64df-410a-be59-d397bca4b254-g5uiC+o6gYj5mguLcCA64p8b4iY/TEDm1P9swC9uEZQ=-1, flow.id=0398e0d9-64df-410a-be59-d397bca4b254, spanId=adf8b192a4e11c62, traceId=66c1f89ad8a4fd78e05e1e3d2ed4226e, vnode.id=2F24A5C4BB8B} - Flow [0398e0d9-64df-410a-be59-d397bca4b254] completed successfully
2024-08-18 13:35:22.834 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723987522682, flow.id=542fefe0-d683-46db-b77c-0efd2c47161b, spanId=3e33bbb073ad45ef, traceId=66c1f89a404450920a2b81f342504f28, vnode.id=F87FD80A917B} - Flow [542fefe0-d683-46db-b77c-0efd2c47161b] started
2024-08-18 13:35:22.843 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723987522682, corda.external.event.id=542fefe0-d683-46db-b77c-0efd2c47161b-g5uiC+o6gYj5mguLcCA64p8b4iY/TEDm1P9swC9uEZQ=-1, flow.id=542fefe0-d683-46db-b77c-0efd2c47161b, spanId=0fdd92bc52ae7475, traceId=66c1f89a404450920a2b81f342504f28, vnode.id=F87FD80A917B} - Flow [542fefe0-d683-46db-b77c-0efd2c47161b] completed successfully
2024-08-18 13:35:22.843 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723987522682, flow.id=660d2fc7-8d78-4163-93e0-e3903f6c3430, spanId=38d882e66b5510b3, traceId=66c1f89a60276bada7ca866b34b51ed6, vnode.id=E23A18A57E27} - Flow [660d2fc7-8d78-4163-93e0-e3903f6c3430] started
2024-08-18 13:35:22.853 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723987522682, corda.external.event.id=660d2fc7-8d78-4163-93e0-e3903f6c3430-g5uiC+o6gYj5mguLcCA64p8b4iY/TEDm1P9swC9uEZQ=-1, flow.id=660d2fc7-8d78-4163-93e0-e3903f6c3430, spanId=15ec2abbe2b0c104, traceId=66c1f89a60276bada7ca866b34b51ed6, vnode.id=E23A18A57E27} - Flow [660d2fc7-8d78-4163-93e0-e3903f6c3430] completed successfully
2024-08-18 13:35:28.650 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=36d3b8a048dcf539, traceId=66c1f8a034f5c9f136d3b8a048dcf539} - {"traceId":"66c1f8a034f5c9f136d3b8a048dcf539","id":"36d3b8a048dcf539","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723988128602540,"duration":46781,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"160","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:45:55.107 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:45:55.110 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:45:55.109 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:45:55.108 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:45:55.108 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:45:55.113 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 13:45:55.113 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 13:45:55.113 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 13:45:55.113 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 13:45:55.113 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 13:45:58.168 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:45:58.168 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:45:58.168 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:46:07.290 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=98f0808391a652dc, traceId=66c1fb1f991e439f98f0808391a652dc} - {"traceId":"66c1fb1f991e439f98f0808391a652dc","id":"98f0808391a652dc","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723988767231039,"duration":58454,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"162","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 13:46:15.529 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:46:15.543 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 13:46:15.543 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 13:46:15.544 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:46:15.547 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: .
2024-08-18 13:54:09.347 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:54:09.348 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:54:09.347 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:54:09.347 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 13:54:09.352 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 13:54:09.352 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 13:54:09.352 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 13:54:09.352 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 13:54:09.914 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:54:09.918 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:54:10.373 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 13:54:10.377 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 13:54:10.378 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 13:54:10.385 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 13:54:10.384 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: .
2024-08-18 13:54:12.389 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:54:12.389 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:54:12.389 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 13:54:21.545 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=826a7b2e5db185a2, traceId=66c1fd0d79420ed7826a7b2e5db185a2} - {"traceId":"66c1fd0d79420ed7826a7b2e5db185a2","id":"826a7b2e5db185a2","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723989261517923,"duration":25969,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"164","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:04:27.012 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=24f95d70c7d21873, traceId=66c1ff6aaf62521324f95d70c7d21873} - {"traceId":"66c1ff6aaf62521324f95d70c7d21873","id":"24f95d70c7d21873","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723989866981205,"duration":29971,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"166","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:09:20.040 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2e6478fa7305f3e1, traceId=66c2009081bc8a8c2e6478fa7305f3e1} - {"traceId":"66c2009081bc8a8c2e6478fa7305f3e1","id":"2e6478fa7305f3e1","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723990160009417,"duration":29756,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"36","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 14:09:20.219 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723989560153, flow.id=fba7037d-a7cf-41a8-9776-6f0566278025, spanId=dfee802d2ee59a58, traceId=66c2009089735a3153440c21653befc6, vnode.id=E6376372B510} - Flow [fba7037d-a7cf-41a8-9776-6f0566278025] started
2024-08-18 14:09:20.223 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 171 ms
2024-08-18 14:09:20.287 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723989560153, corda.external.event.id=fba7037d-a7cf-41a8-9776-6f0566278025-O0d02GkO2EPP8y0m47wGpm5QfIdfn4mjY9tSKt0ugag=-1, flow.id=fba7037d-a7cf-41a8-9776-6f0566278025, spanId=1a546a80e6076be8, traceId=66c2009089735a3153440c21653befc6, vnode.id=E6376372B510} - Flow [fba7037d-a7cf-41a8-9776-6f0566278025] completed successfully
2024-08-18 14:09:20.722 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723989560158, flow.id=36f4e0bd-84b3-4a01-b160-f7de8091cd9c, spanId=e9bc825d4ef2ed0c, traceId=66c20090c6c89926b55522e8a0d7ab5b, vnode.id=70D646C43105} - Flow [36f4e0bd-84b3-4a01-b160-f7de8091cd9c] started
2024-08-18 14:09:20.735 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723989560158, corda.external.event.id=36f4e0bd-84b3-4a01-b160-f7de8091cd9c-OfYhgVxeYtcdF7edxzGDHYZDi1VvLlXlOP4ppK+2DH0=-1, flow.id=36f4e0bd-84b3-4a01-b160-f7de8091cd9c, spanId=22d5a5982f691757, traceId=66c20090c6c89926b55522e8a0d7ab5b, vnode.id=70D646C43105} - Flow [36f4e0bd-84b3-4a01-b160-f7de8091cd9c] completed successfully
2024-08-18 14:09:20.736 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723989560159, flow.id=2507f131-041f-426d-aee5-8109b1716732, spanId=f2290cd6ceced30b, traceId=66c20090b97ae0d94a76c4e6e0696f84, vnode.id=2F24A5C4BB8B} - Flow [2507f131-041f-426d-aee5-8109b1716732] started
2024-08-18 14:09:20.768 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723989560159, corda.external.event.id=2507f131-041f-426d-aee5-8109b1716732-F9VLax/VH/G4oKfm4YyAgiQT4msew6LEy1bvi/RMTac=-1, flow.id=2507f131-041f-426d-aee5-8109b1716732, spanId=34bbae50295e117c, traceId=66c20090b97ae0d94a76c4e6e0696f84, vnode.id=2F24A5C4BB8B} - Flow [2507f131-041f-426d-aee5-8109b1716732] completed successfully
2024-08-18 14:09:20.769 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723989560159, flow.id=ae27889a-f73f-4252-b275-8572d5120759, spanId=affa6c3e8fffb922, traceId=66c20090929dacd8542ae2adcabfeb3b, vnode.id=F87FD80A917B} - Flow [ae27889a-f73f-4252-b275-8572d5120759] started
2024-08-18 14:09:20.781 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723989560159, corda.external.event.id=ae27889a-f73f-4252-b275-8572d5120759-F9VLax/VH/G4oKfm4YyAgiQT4msew6LEy1bvi/RMTac=-1, flow.id=ae27889a-f73f-4252-b275-8572d5120759, spanId=92f5e9a81c62c679, traceId=66c20090929dacd8542ae2adcabfeb3b, vnode.id=F87FD80A917B} - Flow [ae27889a-f73f-4252-b275-8572d5120759] completed successfully
2024-08-18 14:09:20.782 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723989560159, flow.id=5b9fb546-1e6c-49a6-be72-a8346850e128, spanId=2bc0ceb430eadc71, traceId=66c200902e0be3e932291bcae4d3e1aa, vnode.id=E23A18A57E27} - Flow [5b9fb546-1e6c-49a6-be72-a8346850e128] started
2024-08-18 14:09:20.792 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723989560159, corda.external.event.id=5b9fb546-1e6c-49a6-be72-a8346850e128-F9VLax/VH/G4oKfm4YyAgiQT4msew6LEy1bvi/RMTac=-1, flow.id=5b9fb546-1e6c-49a6-be72-a8346850e128, spanId=e81a4c8b2d439589, traceId=66c200902e0be3e932291bcae4d3e1aa, vnode.id=E23A18A57E27} - Flow [5b9fb546-1e6c-49a6-be72-a8346850e128] completed successfully
2024-08-18 14:09:26.367 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=8c0805e3918771d2, traceId=66c2009610265b3b8c0805e3918771d2} - {"traceId":"66c2009610265b3b8c0805e3918771d2","id":"8c0805e3918771d2","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723990166324592,"duration":41651,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"168","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:13:53.323 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cddeaf1c6a5cfab4, traceId=66c201a16bf9d0dfcddeaf1c6a5cfab4} - {"traceId":"66c201a16bf9d0dfcddeaf1c6a5cfab4","id":"cddeaf1c6a5cfab4","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723990433301072,"duration":21318,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"170","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:18:43.625 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=0681bdc405b1bf95, traceId=66c202c37e5b3e180681bdc405b1bf95} - {"traceId":"66c202c37e5b3e180681bdc405b1bf95","id":"0681bdc405b1bf95","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723990723594855,"duration":29230,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"172","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:23:09.341 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=844651e0febebc04, traceId=66c203cdebd0c5ff844651e0febebc04} - {"traceId":"66c203cdebd0c5ff844651e0febebc04","id":"844651e0febebc04","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723990989287389,"duration":52220,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"174","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:29:28.192 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 14:29:28.192 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 14:29:28.199 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 14:29:28.192 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 14:29:28.214 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 14:29:28.214 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 14:29:28.214 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 14:29:28.223 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 14:29:28.214 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 14:29:28.225 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 14:29:28.248 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 14:29:28.248 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 14:29:28.253 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 14:29:28.253 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 14:29:28.259 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 14:29:28.259 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 14:29:29.170 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 14:29:29.175 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 14:29:29.178 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 14:29:29.186 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: .
2024-08-18 14:29:29.176 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 14:29:34.222 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=fcba6dce51264aa4, traceId=66c2054e4fc1a52cfcba6dce51264aa4} - {"traceId":"66c2054e4fc1a52cfcba6dce51264aa4","id":"fcba6dce51264aa4","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723991374167890,"duration":53738,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"38","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 14:29:34.354 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723990774270, flow.id=de9ddddc-b179-4998-b4b1-57ba17ab6618, spanId=6e5d386dab015f8c, traceId=66c2054ed6941ce204fe955556f28a1e, vnode.id=E6376372B510} - Flow [de9ddddc-b179-4998-b4b1-57ba17ab6618] started
2024-08-18 14:29:34.427 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 194 ms
2024-08-18 14:29:34.439 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723990774270, corda.external.event.id=de9ddddc-b179-4998-b4b1-57ba17ab6618-0SskPWGjvPXspKgvU0X8ZCcTCsLHJ8pxFE2B6p2mq00=-1, flow.id=de9ddddc-b179-4998-b4b1-57ba17ab6618, spanId=a9521de2de60dc11, traceId=66c2054ed6941ce204fe955556f28a1e, vnode.id=E6376372B510} - Flow [de9ddddc-b179-4998-b4b1-57ba17ab6618] completed successfully
2024-08-18 14:29:34.440 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723990774271, flow.id=82b68560-06e2-4e7e-99c6-83f512c8d487, spanId=967049f8a14db8f0, traceId=66c2054eb922bc4f1947692814d95cb9, vnode.id=70D646C43105} - Flow [82b68560-06e2-4e7e-99c6-83f512c8d487] started
2024-08-18 14:29:34.460 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723990774271, corda.external.event.id=82b68560-06e2-4e7e-99c6-83f512c8d487-TweaEsFkZH9bHqjH3q4Td4K2WVV9PmxwRI4gRwGHbI8=-1, flow.id=82b68560-06e2-4e7e-99c6-83f512c8d487, spanId=36e8d584a2cb1549, traceId=66c2054eb922bc4f1947692814d95cb9, vnode.id=70D646C43105} - Flow [82b68560-06e2-4e7e-99c6-83f512c8d487] completed successfully
2024-08-18 14:29:34.465 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723990774271, flow.id=5eb5c8f3-d1f4-4e13-ba49-46601832c9ae, spanId=9c60027ec21750c6, traceId=66c2054e25d3efeec5ef5d1d27443af5, vnode.id=2F24A5C4BB8B} - Flow [5eb5c8f3-d1f4-4e13-ba49-46601832c9ae] started
2024-08-18 14:29:34.480 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723990774271, corda.external.event.id=5eb5c8f3-d1f4-4e13-ba49-46601832c9ae-TweaEsFkZH9bHqjH3q4Td4K2WVV9PmxwRI4gRwGHbI8=-1, flow.id=5eb5c8f3-d1f4-4e13-ba49-46601832c9ae, spanId=45818d6818127745, traceId=66c2054e25d3efeec5ef5d1d27443af5, vnode.id=2F24A5C4BB8B} - Flow [5eb5c8f3-d1f4-4e13-ba49-46601832c9ae] completed successfully
2024-08-18 14:29:34.481 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723990774271, flow.id=a3de7065-3f93-43db-be8c-c5b308a95447, spanId=1f84b1908af064a3, traceId=66c2054ed571474b8575621c1cf15643, vnode.id=F87FD80A917B} - Flow [a3de7065-3f93-43db-be8c-c5b308a95447] started
2024-08-18 14:29:34.491 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723990774271, corda.external.event.id=a3de7065-3f93-43db-be8c-c5b308a95447-TweaEsFkZH9bHqjH3q4Td4K2WVV9PmxwRI4gRwGHbI8=-1, flow.id=a3de7065-3f93-43db-be8c-c5b308a95447, spanId=e5fff59772820e02, traceId=66c2054ed571474b8575621c1cf15643, vnode.id=F87FD80A917B} - Flow [a3de7065-3f93-43db-be8c-c5b308a95447] completed successfully
2024-08-18 14:29:34.492 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723990774272, flow.id=acfdd34e-198a-4f06-aab5-7cdfda27bcee, spanId=081fef294c32bb48, traceId=66c2054e66829b170b9cfeea0e15f4e1, vnode.id=E23A18A57E27} - Flow [acfdd34e-198a-4f06-aab5-7cdfda27bcee] started
2024-08-18 14:29:34.500 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723990774272, corda.external.event.id=acfdd34e-198a-4f06-aab5-7cdfda27bcee-nCov2hzTkFjIBlDgIuWowxCy8JvwL6JNdh/N8U4OwkE=-1, flow.id=acfdd34e-198a-4f06-aab5-7cdfda27bcee, spanId=263ab918376e3b36, traceId=66c2054e66829b170b9cfeea0e15f4e1, vnode.id=E23A18A57E27} - Flow [acfdd34e-198a-4f06-aab5-7cdfda27bcee] completed successfully
2024-08-18 14:29:40.741 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c5d77af834e9ce8f, traceId=66c20554a90ed423c5d77af834e9ce8f} - {"traceId":"66c20554a90ed423c5d77af834e9ce8f","id":"c5d77af834e9ce8f","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723991380683148,"duration":56695,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"176","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:29:48.271 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 14:29:48.271 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 14:29:48.275 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 14:29:48.275 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 14:29:48.331 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 14:29:48.331 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 14:29:48.568 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 14:29:48.568 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 14:29:48.568 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 14:34:34.573 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=0ad2f4659b4fc1c2, traceId=66c2067ac8b5ff2a0ad2f4659b4fc1c2} - {"traceId":"66c2067ac8b5ff2a0ad2f4659b4fc1c2","id":"0ad2f4659b4fc1c2","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723991674535891,"duration":36193,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"178","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:35:37.173 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=6ed6ae9434e0b384, traceId=66c206b9059655a26ed6ae9434e0b384} - {"traceId":"66c206b9059655a26ed6ae9434e0b384","id":"6ed6ae9434e0b384","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723991737144884,"duration":26797,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"180","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:36:48.230 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=84958140ac1b3f65, traceId=66c2070024174c6884958140ac1b3f65} - {"traceId":"66c2070024174c6884958140ac1b3f65","id":"84958140ac1b3f65","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723991808182518,"duration":46305,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"182","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:38:47.636 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=acb2458134de7e27, traceId=66c207771110d3eaacb2458134de7e27} - {"traceId":"66c207771110d3eaacb2458134de7e27","id":"acb2458134de7e27","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723991927599090,"duration":35985,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"184","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:43:21.438 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=595559b88f4f0c76, traceId=66c208892e4bc601595559b88f4f0c76} - {"traceId":"66c208892e4bc601595559b88f4f0c76","id":"595559b88f4f0c76","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723992201413650,"duration":23206,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"186","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:48:22.653 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=988654cd36937f57, traceId=66c209b6ab5ee43b988654cd36937f57} - {"traceId":"66c209b6ab5ee43b988654cd36937f57","id":"988654cd36937f57","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723992502605717,"duration":46768,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"188","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:52:26.107 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2804e3398d8f040b, traceId=66c20aaa2dc488712804e3398d8f040b} - {"traceId":"66c20aaa2dc488712804e3398d8f040b","id":"2804e3398d8f040b","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723992746065836,"duration":40094,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"190","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:54:08.395 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=ddd0e1bb7ec75482, traceId=66c20b10950e321addd0e1bb7ec75482} - {"traceId":"66c20b10950e321addd0e1bb7ec75482","id":"ddd0e1bb7ec75482","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723992848350085,"duration":44693,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"40","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 14:54:08.507 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723992248428, flow.id=3834f2c8-75cd-4264-ad42-48aedf05868d, spanId=1a6100fed0a54c25, traceId=66c20b10852366c1a648aad383a8f148, vnode.id=E6376372B510} - Flow [3834f2c8-75cd-4264-ad42-48aedf05868d] started
2024-08-18 14:54:08.528 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 122 ms
2024-08-18 14:54:08.610 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723992248428, corda.external.event.id=3834f2c8-75cd-4264-ad42-48aedf05868d-2fublxNzGDqqVVGEyQvVwHXQ13gfcMValEmFA8DC/TQ=-1, flow.id=3834f2c8-75cd-4264-ad42-48aedf05868d, spanId=82562432c75169d5, traceId=66c20b10852366c1a648aad383a8f148, vnode.id=E6376372B510} - Flow [3834f2c8-75cd-4264-ad42-48aedf05868d] completed successfully
2024-08-18 14:54:08.611 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723992248430, flow.id=2e6c8380-65e5-4f69-8207-54315d33a51c, spanId=e97321571865360c, traceId=66c20b10adbbf5d408bfafd60b6034d3, vnode.id=70D646C43105} - Flow [2e6c8380-65e5-4f69-8207-54315d33a51c] started
2024-08-18 14:54:08.627 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723992248430, corda.external.event.id=2e6c8380-65e5-4f69-8207-54315d33a51c-4IjY0x21+xkz9nF5kXRnjLogBZfH1fbRNdPeUbFkIcs=-1, flow.id=2e6c8380-65e5-4f69-8207-54315d33a51c, spanId=f02fde3e75c57557, traceId=66c20b10adbbf5d408bfafd60b6034d3, vnode.id=70D646C43105} - Flow [2e6c8380-65e5-4f69-8207-54315d33a51c] completed successfully
2024-08-18 14:54:08.627 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723992248430, flow.id=9c1cd0a8-6ce8-4f9a-9822-8c64fda42446, spanId=986e9ebeb3930d6e, traceId=66c20b106b06c7e899ccd8758a021910, vnode.id=2F24A5C4BB8B} - Flow [9c1cd0a8-6ce8-4f9a-9822-8c64fda42446] started
2024-08-18 14:54:08.648 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723992248430, corda.external.event.id=9c1cd0a8-6ce8-4f9a-9822-8c64fda42446-4IjY0x21+xkz9nF5kXRnjLogBZfH1fbRNdPeUbFkIcs=-1, flow.id=9c1cd0a8-6ce8-4f9a-9822-8c64fda42446, spanId=3ff5d0b6ccef69f8, traceId=66c20b106b06c7e899ccd8758a021910, vnode.id=2F24A5C4BB8B} - Flow [9c1cd0a8-6ce8-4f9a-9822-8c64fda42446] completed successfully
2024-08-18 14:54:08.648 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723992248430, flow.id=19be7038-55ff-4e5d-852b-f91a4043c0b0, spanId=a1bdd861b8f662fc, traceId=66c20b10995e8754f9d4cb72742e5ab8, vnode.id=F87FD80A917B} - Flow [19be7038-55ff-4e5d-852b-f91a4043c0b0] started
2024-08-18 14:54:08.663 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723992248430, corda.external.event.id=19be7038-55ff-4e5d-852b-f91a4043c0b0-4IjY0x21+xkz9nF5kXRnjLogBZfH1fbRNdPeUbFkIcs=-1, flow.id=19be7038-55ff-4e5d-852b-f91a4043c0b0, spanId=6de11415d9805629, traceId=66c20b10995e8754f9d4cb72742e5ab8, vnode.id=F87FD80A917B} - Flow [19be7038-55ff-4e5d-852b-f91a4043c0b0] completed successfully
2024-08-18 14:54:08.664 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723992248430, flow.id=06c21f4b-7a2f-4a77-a8d9-574f21b28865, spanId=9fdd8becc4766d0a, traceId=66c20b107476a7e46e90879d3a990642, vnode.id=E23A18A57E27} - Flow [06c21f4b-7a2f-4a77-a8d9-574f21b28865] started
2024-08-18 14:54:08.684 [flow-event-mediator-thread-4] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723992248430, corda.external.event.id=06c21f4b-7a2f-4a77-a8d9-574f21b28865-4IjY0x21+xkz9nF5kXRnjLogBZfH1fbRNdPeUbFkIcs=-1, flow.id=06c21f4b-7a2f-4a77-a8d9-574f21b28865, spanId=8a1f53c35ae64c30, traceId=66c20b107476a7e46e90879d3a990642, vnode.id=E23A18A57E27} - Flow [06c21f4b-7a2f-4a77-a8d9-574f21b28865] completed successfully
2024-08-18 14:54:15.276 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c72a44faee45f80d, traceId=66c20b17bdbf4fcdc72a44faee45f80d} - {"traceId":"66c20b17bdbf4fcdc72a44faee45f80d","id":"c72a44faee45f80d","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723992855267337,"duration":8954,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"192","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 14:55:24.302 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a122b9df9194b0f5, traceId=66c20b5c9bae526ea122b9df9194b0f5} - {"traceId":"66c20b5c9bae526ea122b9df9194b0f5","id":"a122b9df9194b0f5","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723992924238862,"duration":61780,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"194","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:01:34.877 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before successfully committing offsets {flow.session-0=OffsetAndMetadata{offset=34, leaderEpoch=null, metadata=''}}
2024-08-18 15:01:34.895 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 15:01:35.007 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 15:01:35.023 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 15:01:35.724 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 15:01:35.724 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 15:01:36.201 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 15:01:36.201 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 15:01:36.204 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 15:01:36.205 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 15:01:36.205 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 15:01:48.061 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=e092e8e9b14eb38e, traceId=66c20cdc2a457091e092e8e9b14eb38e} - {"traceId":"66c20cdc2a457091e092e8e9b14eb38e","id":"e092e8e9b14eb38e","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723993308009324,"duration":50639,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"196","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:05:55.223 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a68238eea95e63c4, traceId=66c20dd3d34a91aaa68238eea95e63c4} - {"traceId":"66c20dd3d34a91aaa68238eea95e63c4","id":"a68238eea95e63c4","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723993555178902,"duration":43135,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"198","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:19:54.917 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 15:19:54.949 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 15:19:54.953 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 15:19:55.114 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-18 15:19:55.027 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions revoked: 0.
2024-08-18 15:19:55.027 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions revoked: 0.
2024-08-18 15:19:55.335 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions revoked: 0.
2024-08-18 15:19:55.235 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-18 15:19:55.795 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-18 15:19:55.848 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 15:19:58.741 [flow-mapper-event-mediator-long-running-thread-ccf1a85c-4679-4b58-9d66-9633158b645f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--fef20c75-1636-43ec-b132-cb22c9945eaa {} - Partitions assigned: 0.
2024-08-18 15:19:58.741 [flow-mapper-event-mediator-long-running-thread-ea865d54-1c69-4fc5-9efd-e618c8cf9b26] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--9f5c39ce-f73b-438d-b9ca-59c03ca16e04 {} - Partitions assigned: 0.
2024-08-18 15:19:58.741 [flow-mapper-event-mediator-long-running-thread-9c0f1694-c3a4-473a-986a-66387aa6de3f] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--2ad12d65-9644-4263-b662-065269d6cd01 {} - Partitions assigned: 0.
2024-08-18 15:20:00.949 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=6a615fe1426fd2ef, traceId=66c21120c9c706646a615fe1426fd2ef} - {"traceId":"66c21120c9c706646a615fe1426fd2ef","id":"6a615fe1426fd2ef","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723994400896872,"duration":48648,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"42","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 15:20:01.418 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 429 ms
2024-08-18 15:20:08.074 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=033efaa8232783e6, traceId=66c211275da5412a033efaa8232783e6} - {"traceId":"66c211275da5412a033efaa8232783e6","id":"033efaa8232783e6","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994408001266,"duration":70886,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"200","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:20:14.876 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 15:20:14.905 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 15:20:15.613 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-18 15:20:15.613 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-18 15:20:15.626 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 15:20:15.626 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-18 15:20:15.626 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-18 15:20:15.679 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723993801009, flow.id=74736925-b2a3-4f3e-b4be-5ae60443aaf6, spanId=6ea70f94b70c8371, traceId=66c211212d0999f9aa6fd07dc7ed3b07, vnode.id=E6376372B510} - Flow [74736925-b2a3-4f3e-b4be-5ae60443aaf6] started
2024-08-18 15:20:16.239 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723993801009, corda.external.event.id=74736925-b2a3-4f3e-b4be-5ae60443aaf6-k+u+mV/awxXQ1FrojPNHOhXTuX+wWhvFAnDvqqSCDuk=-1, flow.id=74736925-b2a3-4f3e-b4be-5ae60443aaf6, spanId=9a83b8734e2ea148, traceId=66c211212d0999f9aa6fd07dc7ed3b07, vnode.id=E6376372B510} - Flow [74736925-b2a3-4f3e-b4be-5ae60443aaf6] completed successfully
2024-08-18 15:20:16.240 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723993801037, flow.id=04f5f4e2-e203-4705-8a8e-d321e9b9b4c5, spanId=33adccfffff53230, traceId=66c2112166f34514ebec4c87bff8ae56, vnode.id=70D646C43105} - Flow [04f5f4e2-e203-4705-8a8e-d321e9b9b4c5] started
2024-08-18 15:20:16.296 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723993801037, corda.external.event.id=04f5f4e2-e203-4705-8a8e-d321e9b9b4c5-HSA1YJYRDAw3NzAfYkG8aeEqI/xXxbHOAlszAamem4w=-1, flow.id=04f5f4e2-e203-4705-8a8e-d321e9b9b4c5, spanId=19438a71376f5308, traceId=66c2112166f34514ebec4c87bff8ae56, vnode.id=70D646C43105} - Flow [04f5f4e2-e203-4705-8a8e-d321e9b9b4c5] completed successfully
2024-08-18 15:20:16.297 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723993801038, flow.id=9b67b914-f3d6-45ee-896e-04a4122e8fe9, spanId=b09c287924db8984, traceId=66c211216e910bfd503b81e659cb565f, vnode.id=2F24A5C4BB8B} - Flow [9b67b914-f3d6-45ee-896e-04a4122e8fe9] started
2024-08-18 15:20:16.347 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723993801038, corda.external.event.id=9b67b914-f3d6-45ee-896e-04a4122e8fe9-1mFKEom95M6Fcm7ElqElMZXBTx6ZNl40fxRmVG12Fg4=-1, flow.id=9b67b914-f3d6-45ee-896e-04a4122e8fe9, spanId=4bfd93094242a3e2, traceId=66c211216e910bfd503b81e659cb565f, vnode.id=2F24A5C4BB8B} - Flow [9b67b914-f3d6-45ee-896e-04a4122e8fe9] completed successfully
2024-08-18 15:20:16.360 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723993801038, flow.id=fd731699-ee9a-42c5-b982-139a98e6c535, spanId=41ddd264498d6202, traceId=66c21121c165baa91e0fe1be9984d8ae, vnode.id=F87FD80A917B} - Flow [fd731699-ee9a-42c5-b982-139a98e6c535] started
2024-08-18 15:20:16.515 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723993801038, corda.external.event.id=fd731699-ee9a-42c5-b982-139a98e6c535-1mFKEom95M6Fcm7ElqElMZXBTx6ZNl40fxRmVG12Fg4=-1, flow.id=fd731699-ee9a-42c5-b982-139a98e6c535, spanId=526d5d8e117b57bb, traceId=66c21121c165baa91e0fe1be9984d8ae, vnode.id=F87FD80A917B} - Flow [fd731699-ee9a-42c5-b982-139a98e6c535] completed successfully
2024-08-18 15:20:16.516 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723993801038, flow.id=f43e2fbe-4da4-4441-a3f1-77429a22c1ec, spanId=c24dc841b72b4d49, traceId=66c211216cf19c5a1d86477f2393c1fe, vnode.id=E23A18A57E27} - Flow [f43e2fbe-4da4-4441-a3f1-77429a22c1ec] started
2024-08-18 15:20:16.596 [flow-event-mediator-thread-6] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723993801038, corda.external.event.id=f43e2fbe-4da4-4441-a3f1-77429a22c1ec-1mFKEom95M6Fcm7ElqElMZXBTx6ZNl40fxRmVG12Fg4=-1, flow.id=f43e2fbe-4da4-4441-a3f1-77429a22c1ec, spanId=b72ecd12f11cfc41, traceId=66c211216cf19c5a1d86477f2393c1fe, vnode.id=E23A18A57E27} - Flow [f43e2fbe-4da4-4441-a3f1-77429a22c1ec] completed successfully
2024-08-18 15:21:08.154 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=817d5be24dcdc6de, traceId=66c21164e6f95f42817d5be24dcdc6de} - {"traceId":"66c21164e6f95f42817d5be24dcdc6de","id":"817d5be24dcdc6de","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994468108186,"duration":44886,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"202","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:22:08.246 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=861437cfadc1b52b, traceId=66c211a04ea7cdb4861437cfadc1b52b} - {"traceId":"66c211a04ea7cdb4861437cfadc1b52b","id":"861437cfadc1b52b","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994528212611,"duration":32899,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"204","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:23:08.318 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b89eaa2396a0c65b, traceId=66c211dccada2b7bb89eaa2396a0c65b} - {"traceId":"66c211dccada2b7bb89eaa2396a0c65b","id":"b89eaa2396a0c65b","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994588276388,"duration":40602,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"206","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:24:08.377 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1411f1de6d16cc46, traceId=66c21218bdb40f4c1411f1de6d16cc46} - {"traceId":"66c21218bdb40f4c1411f1de6d16cc46","id":"1411f1de6d16cc46","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994648344116,"duration":31791,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"208","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:25:08.423 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=54e5e0d8759b8843, traceId=66c212546fb1ede954e5e0d8759b8843} - {"traceId":"66c212546fb1ede954e5e0d8759b8843","id":"54e5e0d8759b8843","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994708407432,"duration":15141,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"210","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:26:08.478 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=7b565f83ddfa88ea, traceId=66c21290fbf1e71b7b565f83ddfa88ea} - {"traceId":"66c21290fbf1e71b7b565f83ddfa88ea","id":"7b565f83ddfa88ea","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994768438527,"duration":38356,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"212","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:27:08.520 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b7325439ef31c5a2, traceId=66c212ccecfd36a9b7325439ef31c5a2} - {"traceId":"66c212ccecfd36a9b7325439ef31c5a2","id":"b7325439ef31c5a2","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994828499574,"duration":20053,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"214","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:28:08.565 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1625c7d9ddf14395, traceId=66c2130845b8853c1625c7d9ddf14395} - {"traceId":"66c2130845b8853c1625c7d9ddf14395","id":"1625c7d9ddf14395","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994888546126,"duration":18075,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"216","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:29:08.641 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a0c1b0b92d92c9c7, traceId=66c213446eb3474ba0c1b0b92d92c9c7} - {"traceId":"66c213446eb3474ba0c1b0b92d92c9c7","id":"a0c1b0b92d92c9c7","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723994948606066,"duration":34018,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"218","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:30:01.100 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=09af527153ace1c5, traceId=66c213791a74a5dc09af527153ace1c5} - {"traceId":"66c213791a74a5dc09af527153ace1c5","id":"09af527153ace1c5","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723995001064926,"duration":34957,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"44","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 15:30:01.243 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723994401126, flow.id=1e604183-a3fc-403e-8081-ecd9cd79c0cb, spanId=a74edc0a23c73627, traceId=66c213793d8dd1cff7e3148d4699952b, vnode.id=E6376372B510} - Flow [1e604183-a3fc-403e-8081-ecd9cd79c0cb] started
2024-08-18 15:30:01.290 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 155 ms
2024-08-18 15:30:01.362 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723994401126, corda.external.event.id=1e604183-a3fc-403e-8081-ecd9cd79c0cb-NmKj6YuV/Dkq7YIdN61B9ZLuBTjzHHb23Qgn3ew9sj0=-1, flow.id=1e604183-a3fc-403e-8081-ecd9cd79c0cb, spanId=bb4d13ed92b54cc3, traceId=66c213793d8dd1cff7e3148d4699952b, vnode.id=E6376372B510} - Flow [1e604183-a3fc-403e-8081-ecd9cd79c0cb] completed successfully
2024-08-18 15:30:01.363 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723994401130, flow.id=320e67c6-c64b-4d83-93cb-5180b9769782, spanId=139021bd8b832d47, traceId=66c21379e2d745f7b320e3c97d7f75c2, vnode.id=70D646C43105} - Flow [320e67c6-c64b-4d83-93cb-5180b9769782] started
2024-08-18 15:30:01.396 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723994401130, corda.external.event.id=320e67c6-c64b-4d83-93cb-5180b9769782-Lf+pCmGwy+N6Vzpw3mid/NdVckEAKdQ4EfPSK7zV7HQ=-1, flow.id=320e67c6-c64b-4d83-93cb-5180b9769782, spanId=2ce63ed1e858ac02, traceId=66c21379e2d745f7b320e3c97d7f75c2, vnode.id=70D646C43105} - Flow [320e67c6-c64b-4d83-93cb-5180b9769782] completed successfully
2024-08-18 15:30:01.397 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723994401130, flow.id=6f2d4175-4918-48d8-9b2f-a278f0941f43, spanId=a8c68c34f3a31643, traceId=66c213798aeabf3f63ab30af0f01feb0, vnode.id=2F24A5C4BB8B} - Flow [6f2d4175-4918-48d8-9b2f-a278f0941f43] started
2024-08-18 15:30:01.416 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723994401130, corda.external.event.id=6f2d4175-4918-48d8-9b2f-a278f0941f43-Lf+pCmGwy+N6Vzpw3mid/NdVckEAKdQ4EfPSK7zV7HQ=-1, flow.id=6f2d4175-4918-48d8-9b2f-a278f0941f43, spanId=d201bede7a51a70f, traceId=66c213798aeabf3f63ab30af0f01feb0, vnode.id=2F24A5C4BB8B} - Flow [6f2d4175-4918-48d8-9b2f-a278f0941f43] completed successfully
2024-08-18 15:30:01.417 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723994401130, flow.id=fec668c6-a40a-43d5-91da-a7eb67ea3ba4, spanId=73d699d4dfb28671, traceId=66c21379e0f787803668f7421af29817, vnode.id=F87FD80A917B} - Flow [fec668c6-a40a-43d5-91da-a7eb67ea3ba4] started
2024-08-18 15:30:01.435 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723994401130, corda.external.event.id=fec668c6-a40a-43d5-91da-a7eb67ea3ba4-Lf+pCmGwy+N6Vzpw3mid/NdVckEAKdQ4EfPSK7zV7HQ=-1, flow.id=fec668c6-a40a-43d5-91da-a7eb67ea3ba4, spanId=f7172b11b83d45d4, traceId=66c21379e0f787803668f7421af29817, vnode.id=F87FD80A917B} - Flow [fec668c6-a40a-43d5-91da-a7eb67ea3ba4] completed successfully
2024-08-18 15:30:01.436 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723994401130, flow.id=fcb95253-d884-48ba-9bae-5512bc59bd3b, spanId=8178c645f4f50d7d, traceId=66c213791a5c685d7512f138a0ab2276, vnode.id=E23A18A57E27} - Flow [fcb95253-d884-48ba-9bae-5512bc59bd3b] started
2024-08-18 15:30:01.466 [flow-event-mediator-thread-7] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723994401130, corda.external.event.id=fcb95253-d884-48ba-9bae-5512bc59bd3b-Lf+pCmGwy+N6Vzpw3mid/NdVckEAKdQ4EfPSK7zV7HQ=-1, flow.id=fcb95253-d884-48ba-9bae-5512bc59bd3b, spanId=7f7f6c74c7b8bba1, traceId=66c213791a5c685d7512f138a0ab2276, vnode.id=E23A18A57E27} - Flow [fcb95253-d884-48ba-9bae-5512bc59bd3b] completed successfully
2024-08-18 15:30:08.665 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=33907cdd5facfad2, traceId=66c213800aa2418633907cdd5facfad2} - {"traceId":"66c213800aa2418633907cdd5facfad2","id":"33907cdd5facfad2","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995008657726,"duration":7536,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"220","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:31:08.714 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d56daadea3f40ed2, traceId=66c213bc7a627db8d56daadea3f40ed2} - {"traceId":"66c213bc7a627db8d56daadea3f40ed2","id":"d56daadea3f40ed2","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995068688868,"duration":24335,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"222","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:32:08.752 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=acdfcabe27f7f2c9, traceId=66c213f8e96b4fbcacdfcabe27f7f2c9} - {"traceId":"66c213f8e96b4fbcacdfcabe27f7f2c9","id":"acdfcabe27f7f2c9","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995128731653,"duration":19863,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"224","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:33:08.838 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d562fc2d4ef9fa77, traceId=66c2143497864231d562fc2d4ef9fa77} - {"traceId":"66c2143497864231d562fc2d4ef9fa77","id":"d562fc2d4ef9fa77","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995188777649,"duration":56079,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"226","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:34:08.876 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=640f4cba71387f8f, traceId=66c2147047c2d33f640f4cba71387f8f} - {"traceId":"66c2147047c2d33f640f4cba71387f8f","id":"640f4cba71387f8f","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995248858141,"duration":17604,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"228","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:35:08.923 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a2b8b219cddf16a8, traceId=66c214acec2d7dc3a2b8b219cddf16a8} - {"traceId":"66c214acec2d7dc3a2b8b219cddf16a8","id":"a2b8b219cddf16a8","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995308900626,"duration":21841,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"230","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:36:08.964 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1bb35971254ad7fe, traceId=66c214e8970b19551bb35971254ad7fe} - {"traceId":"66c214e8970b19551bb35971254ad7fe","id":"1bb35971254ad7fe","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995368940956,"duration":21745,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"232","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:37:09.023 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9dcd2d089b1b9ef7, traceId=66c21525378bf9309dcd2d089b1b9ef7} - {"traceId":"66c21525378bf9309dcd2d089b1b9ef7","id":"9dcd2d089b1b9ef7","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995429002635,"duration":19326,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"234","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:38:09.060 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d352b17dc6498fc7, traceId=66c2156152b25469d352b17dc6498fc7} - {"traceId":"66c2156152b25469d352b17dc6498fc7","id":"d352b17dc6498fc7","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995489043217,"duration":15806,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"236","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:39:09.110 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9ccbe29c513e2d3f, traceId=66c2159dd45848859ccbe29c513e2d3f} - {"traceId":"66c2159dd45848859ccbe29c513e2d3f","id":"9ccbe29c513e2d3f","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723995549085365,"duration":22174,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"238","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 15:40:01.288 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d659cd4666039890, traceId=66c215d1366a8576d659cd4666039890} - {"traceId":"66c215d1366a8576d659cd4666039890","id":"d659cd4666039890","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723995601268082,"duration":18851,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"46","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 15:40:01.460 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723995001326, flow.id=0bc1150d-d9c6-4d53-adcf-c79e1a4f66a8, spanId=92810fcd13251bf5, traceId=66c215d1b2d5271a35341a71171e87b5, vnode.id=E6376372B510} - Flow [0bc1150d-d9c6-4d53-adcf-c79e1a4f66a8] started
2024-08-18 15:40:01.503 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 175 ms
2024-08-18 15:40:01.544 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723995001326, corda.external.event.id=0bc1150d-d9c6-4d53-adcf-c79e1a4f66a8-apyxP2/p9S3QG6qISB0sQhXeonxVK8M0hSrx2AJgswU=-1, flow.id=0bc1150d-d9c6-4d53-adcf-c79e1a4f66a8, spanId=a635bf65566a0eac, traceId=66c215d1b2d5271a35341a71171e87b5, vnode.id=E6376372B510} - Flow [0bc1150d-d9c6-4d53-adcf-c79e1a4f66a8] completed successfully
2024-08-18 15:40:01.545 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723995001340, flow.id=72caa817-d9ca-48f1-b9ad-c6e55e76aada, spanId=3cad7c34490ec50f, traceId=66c215d116c8ca015eb6eb9ab5b8ae7b, vnode.id=70D646C43105} - Flow [72caa817-d9ca-48f1-b9ad-c6e55e76aada] started
2024-08-18 15:40:01.563 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723995001340, corda.external.event.id=72caa817-d9ca-48f1-b9ad-c6e55e76aada-Z+FPXa578ZdSNWEh5+ksAHL+MDjwJJFYID3Z3UrfyRU=-1, flow.id=72caa817-d9ca-48f1-b9ad-c6e55e76aada, spanId=32c02ad63455a94c, traceId=66c215d116c8ca015eb6eb9ab5b8ae7b, vnode.id=70D646C43105} - Flow [72caa817-d9ca-48f1-b9ad-c6e55e76aada] completed successfully
2024-08-18 15:40:01.564 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723995001340, flow.id=602f0a69-2f88-4dd7-89c2-cc3d7e58c09f, spanId=2b9a44ae6f9c8664, traceId=66c215d171a2b1edb848b920e2ba8f82, vnode.id=2F24A5C4BB8B} - Flow [602f0a69-2f88-4dd7-89c2-cc3d7e58c09f] started
2024-08-18 15:40:01.582 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723995001340, corda.external.event.id=602f0a69-2f88-4dd7-89c2-cc3d7e58c09f-Z+FPXa578ZdSNWEh5+ksAHL+MDjwJJFYID3Z3UrfyRU=-1, flow.id=602f0a69-2f88-4dd7-89c2-cc3d7e58c09f, spanId=17fd1d955f1f1e36, traceId=66c215d171a2b1edb848b920e2ba8f82, vnode.id=2F24A5C4BB8B} - Flow [602f0a69-2f88-4dd7-89c2-cc3d7e58c09f] completed successfully
2024-08-18 15:40:01.583 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723995001340, flow.id=796cce94-c104-4d82-89c5-3c854871acb9, spanId=1f6e43043d302f3e, traceId=66c215d17a9372305c61087290803578, vnode.id=F87FD80A917B} - Flow [796cce94-c104-4d82-89c5-3c854871acb9] started
2024-08-18 15:40:01.609 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723995001340, corda.external.event.id=796cce94-c104-4d82-89c5-3c854871acb9-Z+FPXa578ZdSNWEh5+ksAHL+MDjwJJFYID3Z3UrfyRU=-1, flow.id=796cce94-c104-4d82-89c5-3c854871acb9, spanId=f6a1bbd1d3e933aa, traceId=66c215d17a9372305c61087290803578, vnode.id=F87FD80A917B} - Flow [796cce94-c104-4d82-89c5-3c854871acb9] completed successfully
2024-08-18 15:40:01.609 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723995001340, flow.id=d509cdee-9f16-4d1e-b247-c02782a77b19, spanId=1c2d27315a8db3be, traceId=66c215d1a34a95b5cfbbbd133919be8d, vnode.id=E23A18A57E27} - Flow [d509cdee-9f16-4d1e-b247-c02782a77b19] started
2024-08-18 15:40:01.626 [flow-event-mediator-thread-0] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723995001340, corda.external.event.id=d509cdee-9f16-4d1e-b247-c02782a77b19-Z+FPXa578ZdSNWEh5+ksAHL+MDjwJJFYID3Z3UrfyRU=-1, flow.id=d509cdee-9f16-4d1e-b247-c02782a77b19, spanId=a6016ae48531f0e7, traceId=66c215d1a34a95b5cfbbbd133919be8d, vnode.id=E23A18A57E27} - Flow [d509cdee-9f16-4d1e-b247-c02782a77b19] completed successfully
2024-08-18 15:40:09.182 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=11f6b3b9396b0cc6, traceId=66c215d9cc560d7b11f6b3b9396b0cc6} - {"traceId":"66c215d9cc560d7b11f6b3b9396b0cc6","id":"11f6b3b9396b0cc6","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995609147131,"duration":34018,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"240","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:41:09.219 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a008ebbb8c7e0b1f, traceId=66c21615375b919ca008ebbb8c7e0b1f} - {"traceId":"66c21615375b919ca008ebbb8c7e0b1f","id":"a008ebbb8c7e0b1f","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995669200593,"duration":17441,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"242","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:42:09.259 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b62dc8acc1d30253, traceId=66c2165125349300b62dc8acc1d30253} - {"traceId":"66c2165125349300b62dc8acc1d30253","id":"b62dc8acc1d30253","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995729232667,"duration":25400,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"244","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:43:09.511 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=6df54b17c452b07e, traceId=66c2168dc62c9af86df54b17c452b07e} - {"traceId":"66c2168dc62c9af86df54b17c452b07e","id":"6df54b17c452b07e","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995789276982,"duration":219083,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"246","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:44:09.582 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c689a6fd5d226974, traceId=66c216c9a34a90c6c689a6fd5d226974} - {"traceId":"66c216c9a34a90c6c689a6fd5d226974","id":"c689a6fd5d226974","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995849549452,"duration":22424,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"248","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:45:09.651 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9520f468c3c436a7, traceId=66c21705f5d9725a9520f468c3c436a7} - {"traceId":"66c21705f5d9725a9520f468c3c436a7","id":"9520f468c3c436a7","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995909615106,"duration":35093,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"250","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:46:09.732 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=802dd5dbd3c87b25, traceId=66c2174133c3e2d2802dd5dbd3c87b25} - {"traceId":"66c2174133c3e2d2802dd5dbd3c87b25","id":"802dd5dbd3c87b25","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723995969705211,"duration":25983,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"252","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:47:09.793 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=ad2e155b112d4498, traceId=66c2177d725f1ff3ad2e155b112d4498} - {"traceId":"66c2177d725f1ff3ad2e155b112d4498","id":"ad2e155b112d4498","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996029766404,"duration":26044,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"254","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:48:09.911 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9a5654594907199d, traceId=66c217b9be77012f9a5654594907199d} - {"traceId":"66c217b9be77012f9a5654594907199d","id":"9a5654594907199d","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996089887973,"duration":22613,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"256","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:49:09.968 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=64052959ff746e62, traceId=66c217f5082668ed64052959ff746e62} - {"traceId":"66c217f5082668ed64052959ff746e62","id":"64052959ff746e62","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996149943444,"duration":23156,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"258","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:50:01.460 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f26c98b5d9ca1717, traceId=66c21829bfa1c2d6f26c98b5d9ca1717} - {"traceId":"66c21829bfa1c2d6f26c98b5d9ca1717","id":"f26c98b5d9ca1717","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723996201421273,"duration":38151,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"48","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 15:50:01.657 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723995601499, flow.id=75e094fd-b22d-4a16-b0e3-0d40de4ee515, spanId=e6f6c8495a835cfa, traceId=66c21829a57986e3780a7b0cb7c58a14, vnode.id=E6376372B510} - Flow [75e094fd-b22d-4a16-b0e3-0d40de4ee515] started
2024-08-18 15:50:01.718 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 244 ms
2024-08-18 15:50:01.825 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723995601499, corda.external.event.id=75e094fd-b22d-4a16-b0e3-0d40de4ee515-eLLfkXhI+OMiea7bD/SfU7X+4wQHc7V7XlzKQ/FhZfg=-1, flow.id=75e094fd-b22d-4a16-b0e3-0d40de4ee515, spanId=c869871d7e93ae3b, traceId=66c21829a57986e3780a7b0cb7c58a14, vnode.id=E6376372B510} - Flow [75e094fd-b22d-4a16-b0e3-0d40de4ee515] completed successfully
2024-08-18 15:50:01.827 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723995601512, flow.id=6870588a-b7a5-40cc-8dad-3ed0ddc5bb27, spanId=d416aadbe7d77c9e, traceId=66c21829f81da2cb85369ebffd366c46, vnode.id=70D646C43105} - Flow [6870588a-b7a5-40cc-8dad-3ed0ddc5bb27] started
2024-08-18 15:50:01.854 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723995601512, corda.external.event.id=6870588a-b7a5-40cc-8dad-3ed0ddc5bb27-iDvi8oSI2+uQVrcLh0ELjfzhsx1s5B8QcSfxwMXMaAk=-1, flow.id=6870588a-b7a5-40cc-8dad-3ed0ddc5bb27, spanId=c052fe621f421712, traceId=66c21829f81da2cb85369ebffd366c46, vnode.id=70D646C43105} - Flow [6870588a-b7a5-40cc-8dad-3ed0ddc5bb27] completed successfully
2024-08-18 15:50:01.856 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723995601513, flow.id=14c2c304-17d2-4ab2-8f4b-ec984961e784, spanId=e74c807a741d0191, traceId=66c218296ee459418bf9118df1ebd582, vnode.id=2F24A5C4BB8B} - Flow [14c2c304-17d2-4ab2-8f4b-ec984961e784] started
2024-08-18 15:50:01.890 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723995601513, corda.external.event.id=14c2c304-17d2-4ab2-8f4b-ec984961e784-x06NT6C2hIYd7qws5ebM1Qh8bAkyTvHVcOp7FzfI08c=-1, flow.id=14c2c304-17d2-4ab2-8f4b-ec984961e784, spanId=8cd5eecff3c7566d, traceId=66c218296ee459418bf9118df1ebd582, vnode.id=2F24A5C4BB8B} - Flow [14c2c304-17d2-4ab2-8f4b-ec984961e784] completed successfully
2024-08-18 15:50:01.892 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723995601513, flow.id=9539045e-3550-481a-be8b-7e4eda34e945, spanId=df574d7ed707887e, traceId=66c2182958c067eb59c043687dfcaca7, vnode.id=F87FD80A917B} - Flow [9539045e-3550-481a-be8b-7e4eda34e945] started
2024-08-18 15:50:01.919 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723995601513, corda.external.event.id=9539045e-3550-481a-be8b-7e4eda34e945-x06NT6C2hIYd7qws5ebM1Qh8bAkyTvHVcOp7FzfI08c=-1, flow.id=9539045e-3550-481a-be8b-7e4eda34e945, spanId=205cdf1d4d6619e8, traceId=66c2182958c067eb59c043687dfcaca7, vnode.id=F87FD80A917B} - Flow [9539045e-3550-481a-be8b-7e4eda34e945] completed successfully
2024-08-18 15:50:01.919 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723995601513, flow.id=1636c08a-4bc5-4f4f-b70e-91a38d595158, spanId=0a4c3a65d23dcc36, traceId=66c218293aa1797cc58732d309077f97, vnode.id=E23A18A57E27} - Flow [1636c08a-4bc5-4f4f-b70e-91a38d595158] started
2024-08-18 15:50:01.943 [flow-event-mediator-thread-1] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723995601513, corda.external.event.id=1636c08a-4bc5-4f4f-b70e-91a38d595158-x06NT6C2hIYd7qws5ebM1Qh8bAkyTvHVcOp7FzfI08c=-1, flow.id=1636c08a-4bc5-4f4f-b70e-91a38d595158, spanId=30beccb5b9325864, traceId=66c218293aa1797cc58732d309077f97, vnode.id=E23A18A57E27} - Flow [1636c08a-4bc5-4f4f-b70e-91a38d595158] completed successfully
2024-08-18 15:50:10.048 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4d312b3b73cda41e, traceId=66c21832cfe4c2bd4d312b3b73cda41e} - {"traceId":"66c21832cfe4c2bd4d312b3b73cda41e","id":"4d312b3b73cda41e","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996210008923,"duration":37132,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"260","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:51:10.144 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=ec16cb36c75520b5, traceId=66c2186ec15e4bd2ec16cb36c75520b5} - {"traceId":"66c2186ec15e4bd2ec16cb36c75520b5","id":"ec16cb36c75520b5","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996270079710,"duration":63867,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"262","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:52:10.224 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=45c488eff52bcbd9, traceId=66c218aad895059e45c488eff52bcbd9} - {"traceId":"66c218aad895059e45c488eff52bcbd9","id":"45c488eff52bcbd9","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996330176639,"duration":45042,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"264","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:53:10.278 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=17d2b06bad2fa2e6, traceId=66c218e6f33e1e0b17d2b06bad2fa2e6} - {"traceId":"66c218e6f33e1e0b17d2b06bad2fa2e6","id":"17d2b06bad2fa2e6","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996390244910,"duration":31480,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"266","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:54:10.360 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d3a815a0b3f3032e, traceId=66c21922d71d8f88d3a815a0b3f3032e} - {"traceId":"66c21922d71d8f88d3a815a0b3f3032e","id":"d3a815a0b3f3032e","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996450307732,"duration":50837,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"268","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:55:10.462 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=7e4af59297397cbc, traceId=66c2195e77d0e1c37e4af59297397cbc} - {"traceId":"66c2195e77d0e1c37e4af59297397cbc","id":"7e4af59297397cbc","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996510403266,"duration":58232,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"270","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:56:10.512 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cc8bf719632030ae, traceId=66c2199ad1b9bd2bcc8bf719632030ae} - {"traceId":"66c2199ad1b9bd2bcc8bf719632030ae","id":"cc8bf719632030ae","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996570488591,"duration":22007,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"272","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:57:10.576 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4b64dddd3078ba4d, traceId=66c219d68e98c3f44b64dddd3078ba4d} - {"traceId":"66c219d68e98c3f44b64dddd3078ba4d","id":"4b64dddd3078ba4d","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996630532102,"duration":42668,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"274","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:58:10.631 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cfd6a6119ed230ce, traceId=66c21a128115ac58cfd6a6119ed230ce} - {"traceId":"66c21a128115ac58cfd6a6119ed230ce","id":"cfd6a6119ed230ce","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996690598329,"duration":32275,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"276","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 15:59:10.677 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4008dec881676d0c, traceId=66c21a4e0671b5974008dec881676d0c} - {"traceId":"66c21a4e0671b5974008dec881676d0c","id":"4008dec881676d0c","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996750650664,"duration":25519,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"278","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:00:01.621 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=653bd3371f5708c5, traceId=66c21a81e1b07abf653bd3371f5708c5} - {"traceId":"66c21a81e1b07abf653bd3371f5708c5","id":"653bd3371f5708c5","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1723996801548307,"duration":72275,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"50","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-18 16:00:01.755 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723996201656, flow.id=7567597d-1ae2-4b8e-89f7-25063f9a4932, spanId=7e7e0b7006b123aa, traceId=66c21a81e4167a4064c508690df9dd31, vnode.id=E6376372B510} - Flow [7567597d-1ae2-4b8e-89f7-25063f9a4932] started
2024-08-18 16:00:01.796 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 164 ms
2024-08-18 16:00:01.885 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723996201656, corda.external.event.id=7567597d-1ae2-4b8e-89f7-25063f9a4932-pjKUHdLsOy2XYlpy+4VtSTw7P9B/ZRs688dK8X4BmS0=-1, flow.id=7567597d-1ae2-4b8e-89f7-25063f9a4932, spanId=84a74f9d32811f71, traceId=66c21a81e4167a4064c508690df9dd31, vnode.id=E6376372B510} - Flow [7567597d-1ae2-4b8e-89f7-25063f9a4932] completed successfully
2024-08-18 16:00:01.886 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723996201660, flow.id=a88f936e-461f-4807-a873-ab6435a87628, spanId=69be10949727fd47, traceId=66c21a817939c96189ec6cbae3249072, vnode.id=70D646C43105} - Flow [a88f936e-461f-4807-a873-ab6435a87628] started
2024-08-18 16:00:01.903 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723996201660, corda.external.event.id=a88f936e-461f-4807-a873-ab6435a87628-CFVSyHD7hT3vYOy3GPaHRy4H1ogqAM6y/4fjqa0kSSg=-1, flow.id=a88f936e-461f-4807-a873-ab6435a87628, spanId=6062dbcf761b15a3, traceId=66c21a817939c96189ec6cbae3249072, vnode.id=70D646C43105} - Flow [a88f936e-461f-4807-a873-ab6435a87628] completed successfully
2024-08-18 16:00:01.904 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723996201660, flow.id=c0e4067d-bdcb-4f16-84a2-5510fde1bf88, spanId=51e5eff3c6440576, traceId=66c21a8174ca97653e5e76ab87fd6b8f, vnode.id=2F24A5C4BB8B} - Flow [c0e4067d-bdcb-4f16-84a2-5510fde1bf88] started
2024-08-18 16:00:01.930 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723996201660, corda.external.event.id=c0e4067d-bdcb-4f16-84a2-5510fde1bf88-CFVSyHD7hT3vYOy3GPaHRy4H1ogqAM6y/4fjqa0kSSg=-1, flow.id=c0e4067d-bdcb-4f16-84a2-5510fde1bf88, spanId=869c2d7b67458342, traceId=66c21a8174ca97653e5e76ab87fd6b8f, vnode.id=2F24A5C4BB8B} - Flow [c0e4067d-bdcb-4f16-84a2-5510fde1bf88] completed successfully
2024-08-18 16:00:01.933 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723996201660, flow.id=a4b5d8c7-1199-4ba2-9904-550738710948, spanId=0d891af7363f3ab0, traceId=66c21a81d76e281ebde056d984f9fb42, vnode.id=F87FD80A917B} - Flow [a4b5d8c7-1199-4ba2-9904-550738710948] started
2024-08-18 16:00:01.948 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723996201660, corda.external.event.id=a4b5d8c7-1199-4ba2-9904-550738710948-CFVSyHD7hT3vYOy3GPaHRy4H1ogqAM6y/4fjqa0kSSg=-1, flow.id=a4b5d8c7-1199-4ba2-9904-550738710948, spanId=c39abdc56e7d516c, traceId=66c21a81d76e281ebde056d984f9fb42, vnode.id=F87FD80A917B} - Flow [a4b5d8c7-1199-4ba2-9904-550738710948] completed successfully
2024-08-18 16:00:01.949 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723996201660, flow.id=f5a7ddde-cc30-49cd-8cb7-126fad1aca99, spanId=2a59a5a60a207889, traceId=66c21a81bc11f6bed8d597c31dbad000, vnode.id=E23A18A57E27} - Flow [f5a7ddde-cc30-49cd-8cb7-126fad1aca99] started
2024-08-18 16:00:01.964 [flow-event-mediator-thread-2] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723996201660, corda.external.event.id=f5a7ddde-cc30-49cd-8cb7-126fad1aca99-CFVSyHD7hT3vYOy3GPaHRy4H1ogqAM6y/4fjqa0kSSg=-1, flow.id=f5a7ddde-cc30-49cd-8cb7-126fad1aca99, spanId=6a69ac2af4410f2e, traceId=66c21a81bc11f6bed8d597c31dbad000, vnode.id=E23A18A57E27} - Flow [f5a7ddde-cc30-49cd-8cb7-126fad1aca99] completed successfully
2024-08-18 16:00:10.714 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2d47e6210c3765d7, traceId=66c21a8a2eeb3ce22d47e6210c3765d7} - {"traceId":"66c21a8a2eeb3ce22d47e6210c3765d7","id":"2d47e6210c3765d7","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996810703275,"duration":10725,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"280","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:01:10.770 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f0064b2032b7f0ac, traceId=66c21ac6122b7a56f0064b2032b7f0ac} - {"traceId":"66c21ac6122b7a56f0064b2032b7f0ac","id":"f0064b2032b7f0ac","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996870739739,"duration":26306,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"282","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:02:10.825 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=eb9209c0ae820739, traceId=66c21b02e77964feeb9209c0ae820739} - {"traceId":"66c21b02e77964feeb9209c0ae820739","id":"eb9209c0ae820739","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723996930804214,"duration":20214,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"284","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:03:40.904 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=76cdaca7316351fe, traceId=66c21b5cdce8e37f76cdaca7316351fe} - {"traceId":"66c21b5cdce8e37f76cdaca7316351fe","id":"76cdaca7316351fe","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997020832764,"duration":66159,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"286","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:04:40.973 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=e68ca58f627a2a2b, traceId=66c21b98765bca92e68ca58f627a2a2b} - {"traceId":"66c21b98765bca92e68ca58f627a2a2b","id":"e68ca58f627a2a2b","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997080939587,"duration":32595,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"288","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:05:41.050 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=254caaf7429ee983, traceId=66c21bd544c24047254caaf7429ee983} - {"traceId":"66c21bd544c24047254caaf7429ee983","id":"254caaf7429ee983","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997141002671,"duration":46575,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"290","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:06:41.133 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=8d89573f8964c98b, traceId=66c21c110c2535c48d89573f8964c98b} - {"traceId":"66c21c110c2535c48d89573f8964c98b","id":"8d89573f8964c98b","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997201091789,"duration":40025,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"292","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:07:41.189 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=ae043efa346c6093, traceId=66c21c4d70ff043fae043efa346c6093} - {"traceId":"66c21c4d70ff043fae043efa346c6093","id":"ae043efa346c6093","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997261161666,"duration":26267,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"294","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:08:41.260 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=25e9b359ce629f85, traceId=66c21c89f46581d025e9b359ce629f85} - {"traceId":"66c21c89f46581d025e9b359ce629f85","id":"25e9b359ce629f85","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997321212881,"duration":46200,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"296","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:09:41.355 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b52b861af02a877c, traceId=66c21cc5e98b066eb52b861af02a877c} - {"traceId":"66c21cc5e98b066eb52b861af02a877c","id":"b52b861af02a877c","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997381297213,"duration":54673,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"298","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:10:01.690 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=23c9226c76e5f2ac, traceId=66c21cd967c8399b23c9226c76e5f2ac} - {"traceId":"66c21cd967c8399b23c9226c76e5f2ac","id":"23c9226c76e5f2ac","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723997401664641,"duration":24959,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"52","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 16:10:01.874 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723996801735, flow.id=d1f52289-0136-4842-9963-03cc892d352e, spanId=73c18d4057aee938, traceId=66c21cd9549f436b7570f0d8f74e3eee, vnode.id=E6376372B510} - Flow [d1f52289-0136-4842-9963-03cc892d352e] started
2024-08-18 16:10:01.937 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 199 ms
2024-08-18 16:10:02.018 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723996801735, corda.external.event.id=d1f52289-0136-4842-9963-03cc892d352e-MbKVcEMcr6t3LoST/qhv80so6xBkWDZgOpBfhD7hzCk=-1, flow.id=d1f52289-0136-4842-9963-03cc892d352e, spanId=c1454004a622ebb3, traceId=66c21cd9549f436b7570f0d8f74e3eee, vnode.id=E6376372B510} - Flow [d1f52289-0136-4842-9963-03cc892d352e] completed successfully
2024-08-18 16:10:02.019 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723996801740, flow.id=ea9cfbc7-fb0c-4161-ae57-00e3b7a5e94a, spanId=52c36823ee168a5b, traceId=66c21cd9abaa44879f948e1522bf790f, vnode.id=70D646C43105} - Flow [ea9cfbc7-fb0c-4161-ae57-00e3b7a5e94a] started
2024-08-18 16:10:02.039 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723996801740, corda.external.event.id=ea9cfbc7-fb0c-4161-ae57-00e3b7a5e94a-YpQ2fcmRbrjuTheY9bZrmUOJCFQRcSuXrcZGXZmWhA0=-1, flow.id=ea9cfbc7-fb0c-4161-ae57-00e3b7a5e94a, spanId=871a2708839b5b4d, traceId=66c21cd9abaa44879f948e1522bf790f, vnode.id=70D646C43105} - Flow [ea9cfbc7-fb0c-4161-ae57-00e3b7a5e94a] completed successfully
2024-08-18 16:10:02.041 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723996801741, flow.id=f2d720d5-b12c-4efb-82c6-2c1c74a69f93, spanId=7a9d2f971e7a2b23, traceId=66c21cd931cef466c459d130fea75429, vnode.id=2F24A5C4BB8B} - Flow [f2d720d5-b12c-4efb-82c6-2c1c74a69f93] started
2024-08-18 16:10:02.069 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723996801741, corda.external.event.id=f2d720d5-b12c-4efb-82c6-2c1c74a69f93-fU3HsN3ERMVn2UVufjL+FUBgrSfzyXi7pu7E2f3nddA=-1, flow.id=f2d720d5-b12c-4efb-82c6-2c1c74a69f93, spanId=88772cd22305971a, traceId=66c21cd931cef466c459d130fea75429, vnode.id=2F24A5C4BB8B} - Flow [f2d720d5-b12c-4efb-82c6-2c1c74a69f93] completed successfully
2024-08-18 16:10:02.070 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723996801741, flow.id=22a459ad-92fa-4686-a8f1-d8e41015ec35, spanId=9b1c575402756ac2, traceId=66c21cd9c55cb6ab12ec55d151d22ab9, vnode.id=F87FD80A917B} - Flow [22a459ad-92fa-4686-a8f1-d8e41015ec35] started
2024-08-18 16:10:02.088 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723996801741, corda.external.event.id=22a459ad-92fa-4686-a8f1-d8e41015ec35-fU3HsN3ERMVn2UVufjL+FUBgrSfzyXi7pu7E2f3nddA=-1, flow.id=22a459ad-92fa-4686-a8f1-d8e41015ec35, spanId=259444072279efde, traceId=66c21cd9c55cb6ab12ec55d151d22ab9, vnode.id=F87FD80A917B} - Flow [22a459ad-92fa-4686-a8f1-d8e41015ec35] completed successfully
2024-08-18 16:10:02.089 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723996801741, flow.id=d19931d0-6b02-4e62-b910-6e2297509dd8, spanId=f068ae5776748b23, traceId=66c21cd9ca638bb38349aa4ecf4c8663, vnode.id=E23A18A57E27} - Flow [d19931d0-6b02-4e62-b910-6e2297509dd8] started
2024-08-18 16:10:02.108 [flow-event-mediator-thread-3] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723996801741, corda.external.event.id=d19931d0-6b02-4e62-b910-6e2297509dd8-fU3HsN3ERMVn2UVufjL+FUBgrSfzyXi7pu7E2f3nddA=-1, flow.id=d19931d0-6b02-4e62-b910-6e2297509dd8, spanId=49c67667525cc8c6, traceId=66c21cd9ca638bb38349aa4ecf4c8663, vnode.id=E23A18A57E27} - Flow [d19931d0-6b02-4e62-b910-6e2297509dd8] completed successfully
2024-08-18 16:10:41.429 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c546b2f9af8f6995, traceId=66c21d018e922777c546b2f9af8f6995} - {"traceId":"66c21d018e922777c546b2f9af8f6995","id":"c546b2f9af8f6995","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1723997441385663,"duration":42033,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"300","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-18 16:11:41.517 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2ed1df7510d918b6, traceId=66c21d3d541b88ee2ed1df7510d918b6} - {"traceId":"66c21d3d541b88ee2ed1df7510d918b6","id":"2ed1df7510d918b6","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997501481660,"duration":34042,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"302","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:12:41.587 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a5e3eb1a2ca330ba, traceId=66c21d79cee9d955a5e3eb1a2ca330ba} - {"traceId":"66c21d79cee9d955a5e3eb1a2ca330ba","id":"a5e3eb1a2ca330ba","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997561550269,"duration":35735,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"304","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:13:41.639 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4499a9f9a4e065f4, traceId=66c21db5755cc2da4499a9f9a4e065f4} - {"traceId":"66c21db5755cc2da4499a9f9a4e065f4","id":"4499a9f9a4e065f4","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997621610619,"duration":27203,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"306","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:14:41.727 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=a3ebdbb714c4a485, traceId=66c21df1fd2827f1a3ebdbb714c4a485} - {"traceId":"66c21df1fd2827f1a3ebdbb714c4a485","id":"a3ebdbb714c4a485","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997681659752,"duration":53169,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"308","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:15:41.816 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=104f8b80d0e9256a, traceId=66c21e2d2eed6c5d104f8b80d0e9256a} - {"traceId":"66c21e2d2eed6c5d104f8b80d0e9256a","id":"104f8b80d0e9256a","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997741792606,"duration":21223,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"310","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:16:41.908 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=3ba8c9ad6caceeed, traceId=66c21e69393007f73ba8c9ad6caceeed} - {"traceId":"66c21e69393007f73ba8c9ad6caceeed","id":"3ba8c9ad6caceeed","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997801848930,"duration":57714,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"312","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:17:41.992 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4b5c85474fb2b208, traceId=66c21ea5c9e08a914b5c85474fb2b208} - {"traceId":"66c21ea5c9e08a914b5c85474fb2b208","id":"4b5c85474fb2b208","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997861960817,"duration":29660,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"314","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:18:42.134 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=ca36ab69611b95c8, traceId=66c21ee24775ca78ca36ab69611b95c8} - {"traceId":"66c21ee24775ca78ca36ab69611b95c8","id":"ca36ab69611b95c8","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997922015976,"duration":117436,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"316","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:19:42.288 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cd7ebc3ceb647643, traceId=66c21f1ee5678637cd7ebc3ceb647643} - {"traceId":"66c21f1ee5678637cd7ebc3ceb647643","id":"cd7ebc3ceb647643","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723997982237074,"duration":47669,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"318","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:20:01.853 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=e436e9cfb03abf79, traceId=66c21f313b9afc6be436e9cfb03abf79} - {"traceId":"66c21f313b9afc6be436e9cfb03abf79","id":"e436e9cfb03abf79","name":"kafka producer - send record to topic scheduled.task.ledger.repair","timestamp":1723998001805067,"duration":46872,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"54","send.partition":"0","send.topic":"scheduled.task.ledger.repair"}}
2024-08-18 16:20:01.974 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E6376372B510-1723997401874, flow.id=c9c5f23d-ca82-4ef9-9dfb-52fcfb5aa009, spanId=a96162cd8e63e529, traceId=66c21f31e5be7d40b3d02a5c152ef3b2, vnode.id=E6376372B510} - Flow [c9c5f23d-ca82-4ef9-9dfb-52fcfb5aa009] started
2024-08-18 16:20:02.037 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 153 ms
2024-08-18 16:20:02.228 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E6376372B510-1723997401874, corda.external.event.id=c9c5f23d-ca82-4ef9-9dfb-52fcfb5aa009-FFnALIEox6QKJC90IbcDyRJ6JcZFTfQG9shuizOIyOE=-1, flow.id=c9c5f23d-ca82-4ef9-9dfb-52fcfb5aa009, spanId=eaf1e4b0656913b8, traceId=66c21f31e5be7d40b3d02a5c152ef3b2, vnode.id=E6376372B510} - Flow [c9c5f23d-ca82-4ef9-9dfb-52fcfb5aa009] completed successfully
2024-08-18 16:20:02.229 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-70D646C43105-1723997401876, flow.id=7d264af1-7f4f-4cde-a27b-f7154896e0e8, spanId=fe1b0348569e8797, traceId=66c21f3116a56ac3715b9a8d082b8ed6, vnode.id=70D646C43105} - Flow [7d264af1-7f4f-4cde-a27b-f7154896e0e8] started
2024-08-18 16:20:02.279 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-70D646C43105-1723997401876, corda.external.event.id=7d264af1-7f4f-4cde-a27b-f7154896e0e8-QPOp6AWhXjlxhmvnaqAel9oZK5Aia6M1odQDSgile0U=-1, flow.id=7d264af1-7f4f-4cde-a27b-f7154896e0e8, spanId=d4049e2a2034f5d5, traceId=66c21f3116a56ac3715b9a8d082b8ed6, vnode.id=70D646C43105} - Flow [7d264af1-7f4f-4cde-a27b-f7154896e0e8] completed successfully
2024-08-18 16:20:02.280 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723997401876, flow.id=5b73c74c-994f-4b17-92a3-f2b1ea6fd306, spanId=272a902b0227f843, traceId=66c21f31242f0ef6b100ebe35d9e9cae, vnode.id=2F24A5C4BB8B} - Flow [5b73c74c-994f-4b17-92a3-f2b1ea6fd306] started
2024-08-18 16:20:02.298 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-2F24A5C4BB8B-1723997401876, corda.external.event.id=5b73c74c-994f-4b17-92a3-f2b1ea6fd306-QPOp6AWhXjlxhmvnaqAel9oZK5Aia6M1odQDSgile0U=-1, flow.id=5b73c74c-994f-4b17-92a3-f2b1ea6fd306, spanId=1a3ec7928fafab01, traceId=66c21f31242f0ef6b100ebe35d9e9cae, vnode.id=2F24A5C4BB8B} - Flow [5b73c74c-994f-4b17-92a3-f2b1ea6fd306] completed successfully
2024-08-18 16:20:02.310 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-F87FD80A917B-1723997401876, flow.id=fda4475e-2d25-4084-8cf8-b9c395f1fed6, spanId=d403c76d573df60a, traceId=66c21f314a698fa54310a7fdabd33989, vnode.id=F87FD80A917B} - Flow [fda4475e-2d25-4084-8cf8-b9c395f1fed6] started
2024-08-18 16:20:02.340 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-F87FD80A917B-1723997401876, corda.external.event.id=fda4475e-2d25-4084-8cf8-b9c395f1fed6-QPOp6AWhXjlxhmvnaqAel9oZK5Aia6M1odQDSgile0U=-1, flow.id=fda4475e-2d25-4084-8cf8-b9c395f1fed6, spanId=cb967606ed4f41d7, traceId=66c21f314a698fa54310a7fdabd33989, vnode.id=F87FD80A917B} - Flow [fda4475e-2d25-4084-8cf8-b9c395f1fed6] completed successfully
2024-08-18 16:20:02.341 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.events.StartFlowEventHandler {corda.client.id=ledger-repair-E23A18A57E27-1723997401876, flow.id=da9b4655-a881-4463-880a-5e5a9b6f35f2, spanId=96e3ed221ff80f44, traceId=66c21f3105c34fbe69507a6bfc08db7b, vnode.id=E23A18A57E27} - Flow [da9b4655-a881-4463-880a-5e5a9b6f35f2] started
2024-08-18 16:20:02.357 [flow-event-mediator-thread-5] INFO  net.corda.flow.pipeline.handlers.requests.FlowFinishedRequestHandler {corda.client.id=ledger-repair-E23A18A57E27-1723997401876, corda.external.event.id=da9b4655-a881-4463-880a-5e5a9b6f35f2-QPOp6AWhXjlxhmvnaqAel9oZK5Aia6M1odQDSgile0U=-1, flow.id=da9b4655-a881-4463-880a-5e5a9b6f35f2, spanId=fa74c4e3a87104b8, traceId=66c21f3105c34fbe69507a6bfc08db7b, vnode.id=E23A18A57E27} - Flow [da9b4655-a881-4463-880a-5e5a9b6f35f2] completed successfully
2024-08-18 16:20:42.368 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f249dc17e544c577, traceId=66c21f5ac453164bf249dc17e544c577} - {"traceId":"66c21f5ac453164bf249dc17e544c577","id":"f249dc17e544c577","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723998042336303,"duration":30439,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"320","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:21:42.449 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=ce1799d672c643a3, traceId=66c21f9632841934ce1799d672c643a3} - {"traceId":"66c21f9632841934ce1799d672c643a3","id":"ce1799d672c643a3","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1723998102413329,"duration":34749,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"322","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-18 16:22:42.602 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=90c631ad5d39c101, traceId=66c21fd26d86c11490c631ad5d39c101} - {"traceId":"66c21fd26d86c11490c631ad5d39c101","id":"90c631ad5d39c101","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723998162506336,"duration":86574,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"324","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 16:23:42.682 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=937a1d563a717c41, traceId=66c2200ecade2787937a1d563a717c41} - {"traceId":"66c2200ecade2787937a1d563a717c41","id":"937a1d563a717c41","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723998222657941,"duration":23149,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"326","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 16:24:42.753 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c2af4cfd294dac01, traceId=66c2204a55265a37c2af4cfd294dac01} - {"traceId":"66c2204a55265a37c2af4cfd294dac01","id":"c2af4cfd294dac01","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723998282699543,"duration":50333,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"328","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 16:25:42.849 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c1e106524dc8b406, traceId=66c220865e532a2fc1e106524dc8b406} - {"traceId":"66c220865e532a2fc1e106524dc8b406","id":"c1e106524dc8b406","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723998342785647,"duration":57748,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"330","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 16:26:43.131 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=19df25ce63f86f5d, traceId=66c220c3c66fb05719df25ce63f86f5d} - {"traceId":"66c220c3c66fb05719df25ce63f86f5d","id":"19df25ce63f86f5d","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1723998403069216,"duration":60331,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.96.5"},"tags":{"send.offset":"332","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-18 16:26:49.991 [shutdown] INFO  net.corda.applications.workers.combined.CombinedWorker {} - Combined worker stopping.
2024-08-18 16:26:50.005 [shutdown] INFO  net.corda.processors.uniqueness.internal.UniquenessProcessorImpl {} - Uniqueness processor stopping.
2024-08-18 16:26:50.004 [lifecycle-coordinator-604] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.crypto.CryptoProcessor from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.007 [lifecycle-coordinator-602] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.uniqueness.internal.UniquenessProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.007 [shutdown] INFO  net.corda.processors.token.cache.internal.TokenCacheProcessorImpl {} - Token cache processor stopping.
2024-08-18 16:26:50.007 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.configuration.read.ConfigurationReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.007 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.db.connection.manager.DbConnectionManager from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.008 [lifecycle-coordinator-602] INFO  net.corda.uniqueness.checker.impl.BatchedUniquenessCheckerLifecycleImpl {} - Uniqueness checker stopping
2024-08-18 16:26:50.008 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.virtualnode.write.db.VirtualNodeInfoWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.008 [shutdown] INFO  net.corda.processors.persistence.internal.PersistenceProcessorImpl {} - Persistence processor stopping.
2024-08-18 16:26:50.008 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.virtualnode.read.VirtualNodeInfoReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.008 [lifecycle-coordinator-600] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.uniqueness.checker.UniquenessCheckerLifecycle from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.008 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.DBProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.008 [lifecycle-coordinator-603] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.token.cache.internal.TokenCacheProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.009 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.persistence.internal.PersistenceProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.009 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.verification.internal.VerificationProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.010 [lifecycle-coordinator-602] INFO  net.corda.processors.uniqueness.internal.UniquenessProcessorImpl {} - Uniqueness processor received event StopEvent(errored=false).
2024-08-18 16:26:50.009 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.rest.internal.RestProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.009 [shutdown] INFO  net.corda.processors.db.internal.DBProcessorImpl {} - DB processor stopping.
2024-08-18 16:26:50.009 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.config.Configuration> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.010 [lifecycle-coordinator-599] INFO  net.corda.processors.db.internal.DBProcessorImpl {} - DB processor is DOWN
2024-08-18 16:26:50.014 [lifecycle-coordinator-606] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.cpiinfo.read.CpiInfoReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.014 [shutdown] INFO  net.corda.processors.flow.internal.FlowProcessorImpl {} - Flow processor stopping.
2024-08-18 16:26:50.014 [lifecycle-coordinator-609] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.utxo.token.cache.services.TokenCacheComponent from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.015 [lifecycle-coordinator-607] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-abb511de-eb75-4871-b136-3385e46dd000 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.015 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.DBProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.015 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.membership.PersistentMemberInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.016 [lifecycle-coordinator-599] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.config.Configuration> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.016 [lifecycle-coordinator-599] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.config.Configuration> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.config.Configuration> changing to state DOWN
2024-08-18 16:26:50.016 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.client.SessionEncryptionOpsClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.016 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.flow.internal.FlowProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.016 [lifecycle-coordinator-607] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-abb511de-eb75-4871-b136-3385e46dd000 is stopping
2024-08-18 16:26:50.016 [lifecycle-coordinator-606] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.cpiupload.endpoints.v1.CpiUploadRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-18 16:26:50.016 [lifecycle-coordinator-614] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.DBProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.017 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.MemberInfoReconciler$MemberInfoReconcilerReadWriter received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.018 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MemberSynchronisationServiceImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.020 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.020 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.MGMRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.020 [lifecycle-coordinator-602] INFO  net.corda.processors.db.internal.reconcile.db.MemberInfoReconciler {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.processors.db.internal.reconcile.db.MemberInfoReconciler$MemberInfoReconcilerReadWriter,coordinators=net.corda.configuration.read.ConfigurationReadService), status=DOWN).
2024-08-18 16:26:50.019 [lifecycle-coordinator-608] INFO  net.corda.processors.verification.internal.VerificationProcessorImpl {} - Verification processor is DOWN
2024-08-18 16:26:50.022 [lifecycle-coordinator-599] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.verification.internal.VerificationProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.021 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.virtualnode.write.db.VirtualNodeInfoWriteService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.025 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.write.db.VirtualNodeInfoWriteService changing to state DOWN
2024-08-18 16:26:50.022 [lifecycle-coordinator-610] INFO  net.corda.processors.rest.internal.RestProcessorImpl {} - REST processor is DOWN
2024-08-18 16:26:50.025 [shutdown] INFO  net.corda.processors.flow.mapper.internal.FlowMapperProcessorImpl {} - Flow mapper processor stopping.
2024-08-18 16:26:50.024 [lifecycle-coordinator-599] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.031 [lifecycle-coordinator-599] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.synchronisation.SynchronisationProxy received RegistrationStatusChangeEvent DOWN due to net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl changing to state DOWN
2024-08-18 16:26:50.023 [lifecycle-coordinator-612] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.configuration.write.ConfigWriteService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.031 [shutdown] INFO  net.corda.processors.verification.internal.VerificationProcessorImpl {} - Verification processor stopping.
2024-08-18 16:26:50.031 [lifecycle-coordinator-602] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.membership.PersistentMemberInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.033 [lifecycle-coordinator-602] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.membership.PersistentMemberInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.membership.PersistentMemberInfo> changing to state DOWN
2024-08-18 16:26:50.022 [lifecycle-coordinator-621] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.client.SessionEncryptionOpsClient from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.033 [lifecycle-coordinator-621] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator StatefulSessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.SessionEncryptionOpsClient changing to state DOWN
2024-08-18 16:26:50.033 [lifecycle-coordinator-621] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.member.MemberProcessor from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.030 [lifecycle-coordinator-610] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.flow.mapper.internal.FlowMapperProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.030 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.ExpirationProcessor received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.034 [shutdown] INFO  net.corda.processors.rest.internal.RestProcessorImpl {} - REST processor stopping.
2024-08-18 16:26:50.029 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.scheduler.impl.SchedulerProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.035 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.MemberLookupRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.028 [lifecycle-coordinator-608] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.rest.internal.RestProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.028 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.036 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.cpiupload.endpoints.v1.CpiUploadRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.036 [shutdown] INFO  net.corda.processors.p2p.linkmanager.internal.LinkManagerProcessorImpl {} - Link manager processor stopping.
2024-08-18 16:26:50.037 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.035 [lifecycle-coordinator-606] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.entityprocessor.FlowPersistenceService received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-18 16:26:50.033 [lifecycle-coordinator-602] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.membership.PersistentMemberInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.033 [lifecycle-coordinator-611] INFO  net.corda.membership.impl.synchronisation.SynchronisationProxyImpl {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.membership.synchronisation.SynchronisationProxy,coordinators=net.corda.configuration.read.ConfigurationReadService, net.corda.membership.grouppolicy.GroupPolicyProvider, net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl, net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MemberSynchronisationServiceImpl), status=DOWN)
2024-08-18 16:26:50.031 [lifecycle-coordinator-619] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.config.Configuration> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.031 [lifecycle-coordinator-617] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.utxo.token.cache.services.TokenCacheSubscriptionHandler from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.023 [lifecycle-coordinator-616] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.flow.internal.FlowProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.036 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.grouppolicy.GroupPolicyProvider from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.039 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.RegistrationProxy received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.039 [lifecycle-coordinator-619] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.service.FlowService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.036 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.securitymanager.SecurityConfigHandler received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.041 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.virtualnode.endpoints.v1.VirtualNodeRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.027 [lifecycle-coordinator-594] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.MemberInfoReconciler$MemberInfoReconcilerReadWriter from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.042 [lifecycle-coordinator-625] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.verification.LedgerVerificationComponent from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.044 [lifecycle-coordinator-602] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.components.rest.RestGateway from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.045 [lifecycle-coordinator-628] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.persistence.LedgerPersistenceService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.041 [lifecycle-coordinator-623] INFO  net.corda.processors.scheduler.impl.SchedulerProcessorImpl {} - Scheduler processor is DOWN
2024-08-18 16:26:50.037 [lifecycle-coordinator-615] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.cpk.read.CpkReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.049 [lifecycle-coordinator-615] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent received RegistrationStatusChangeEvent DOWN due to net.corda.cpk.read.CpkReadService changing to state DOWN
2024-08-18 16:26:50.070 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.read.MembershipGroupReaderProvider from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.071 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.p2p.MembershipP2PReadService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.037 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.p2p.linkmanager.internal.LinkManagerProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.037 [lifecycle-coordinator-618] INFO  StatefulSessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.072 [lifecycle-coordinator-618] INFO  StatefulSessionManagerImpl-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.039 [shutdown] INFO  net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl {} - Gateway processor stopping.
2024-08-18 16:26:50.063 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.virtualnode.maintenance.endpoints.v1.VirtualNodeMaintenanceRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.060 [lifecycle-coordinator-623] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.RegistrationProxy from status UP to DOWN. Reason: Dependencies of RegistrationProxy are down.
2024-08-18 16:26:50.073 [lifecycle-coordinator-623] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.service.MemberOpsService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.registration.RegistrationProxy changing to state DOWN
2024-08-18 16:26:50.047 [lifecycle-coordinator-630] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.MGMRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.074 [lifecycle-coordinator-636] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.service.FlowExecutor from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.047 [lifecycle-coordinator-640] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.rest.FlowRestResourceService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.046 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.ledger.persistence.LedgerPersistenceService received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.076 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.persistence.service.MembershipPersistenceService received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.046 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.storage.reader.PermissionStorageReaderService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.077 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.virtualnode.write.db.VirtualNodeWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.043 [lifecycle-coordinator-594] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.securitymanager.SecurityConfigHandler from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.043 [lifecycle-coordinator-608] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.maintenance.FlowMaintenance from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.046 [lifecycle-coordinator-629] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.session.mapper.service.FlowMapperService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.080 [shutdown] INFO  net.corda.processors.scheduler.impl.SchedulerProcessorImpl {} - Scheduler processor stopping.
2024-08-18 16:26:50.077 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.flow.mapper.internal.FlowMapperProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.046 [lifecycle-coordinator-627] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.client.hsm.HSMRegistrationClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.076 [lifecycle-coordinator-606] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.rest.v1.FlowClassRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-18 16:26:50.081 [lifecycle-coordinator-606] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.grouppolicy.GroupPolicyProvider received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-18 16:26:50.081 [lifecycle-coordinator-606] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-18 16:26:50.046 [lifecycle-coordinator-621] INFO  net.corda.membership.impl.registration.RegistrationProxyImpl {} - Registration proxy stopping.
2024-08-18 16:26:50.083 [lifecycle-coordinator-621] INFO  net.corda.membership.service.impl.MemberOpsServiceImpl {} - Stopping...
2024-08-18 16:26:50.046 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.047 [lifecycle-coordinator-633] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-37343faf-b808-4d86-8507-177629dd6481 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.084 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> changing to state DOWN
2024-08-18 16:26:50.047 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator inbound_message_processor_group-link.in-subscription-tile-13 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.048 [lifecycle-coordinator-622] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.scheduler.impl.SchedulerProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.063 [lifecycle-coordinator-632] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.cpi.upload.endpoints.service.CpiUploadService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.084 [lifecycle-coordinator-630] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.persistence.client.MembershipQueryClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.084 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.071 [lifecycle-coordinator-634] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.085 [lifecycle-coordinator-621] INFO  net.corda.membership.impl.registration.dynamic.RegistrationManagementServiceImpl {} - Stopping component.
2024-08-18 16:26:50.084 [lifecycle-coordinator-632] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.virtualnode.maintenance.endpoints.v1.VirtualNodeMaintenanceRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpi.upload.endpoints.service.CpiUploadService changing to state DOWN
2024-08-18 16:26:50.084 [lifecycle-coordinator-624] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.persistence.client.MembershipPersistenceClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.086 [lifecycle-coordinator-624] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.certificate.client.CertificatesClient received RegistrationStatusChangeEvent DOWN due to net.corda.membership.persistence.client.MembershipPersistenceClient changing to state DOWN
2024-08-18 16:26:50.087 [lifecycle-coordinator-626] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-18 16:26:50.087 [lifecycle-coordinator-647] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.read.GroupParametersReaderService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.088 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionHealthManager-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.089 [lifecycle-coordinator-619] INFO  SessionHealthManager-1 {} - Stopping resources
2024-08-18 16:26:50.089 [lifecycle-coordinator-619] INFO  SessionHealthManager-1 {} - Unregistered for Config updates.
2024-08-18 16:26:50.090 [lifecycle-coordinator-619] INFO  SessionHealthManager-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.084 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.090 [lifecycle-coordinator-633] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-37343faf-b808-4d86-8507-177629dd6481 is stopping
2024-08-18 16:26:50.075 [lifecycle-coordinator-637] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.MemberLookupRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.083 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.092 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.076 [lifecycle-coordinator-638] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.p2p.filter.FlowP2PFilterService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.081 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.session.mapper.service.FlowMapperService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.094 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.groupparams.writer.service.GroupParametersWriterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.097 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.certificate.publisher.MembersClientCertificatePublisher received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.100 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.client.CryptoOpsClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.102 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.storage.writer.PermissionStorageWriterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.103 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.client.MGMResourceClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.105 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.components.scheduler.TriggerPublisher received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.108 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.p2p.filter.FlowP2PFilterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.108 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.read.MembershipGroupReaderProvider received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.109 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.configuration.endpoints.v1.ConfigRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.110 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.persistence.client.MembershipQueryClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.110 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.member.DynamicMemberRegistrationService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.081 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.HsmRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.080 [lifecycle-coordinator-644] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.080 [lifecycle-coordinator-594] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.client.MGMResourceClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.115 [lifecycle-coordinator-594] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.MGMAdminRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.client.MGMResourceClient changing to state DOWN
2024-08-18 16:26:50.116 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.MGMAdminRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.079 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.client.CryptoOpsClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.118 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.119 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator DynamicKeyStore-1 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.119 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.KeyRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.120 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.hes.StableKeyPairDecryptor received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.122 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.CertificatesRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.122 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.123 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.CertificateRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.123 [lifecycle-coordinator-667] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.123 [lifecycle-coordinator-667] INFO  SessionManagerImpl-1 {} - Unregistered for Config updates.
2024-08-18 16:26:50.124 [lifecycle-coordinator-667] INFO  SessionManagerImpl-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.124 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator SessionManagerImpl-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.124 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator StatefulSessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to SessionManagerImpl-1 changing to state DOWN
2024-08-18 16:26:50.124 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.CertificatesRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.079 [lifecycle-coordinator-616] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-18 16:26:50.124 [lifecycle-coordinator-666] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.CertificateRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.124 [lifecycle-coordinator-669] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.hes.StableKeyPairDecryptor from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.079 [lifecycle-coordinator-610] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-18 16:26:50.079 [lifecycle-coordinator-643] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StatefulSessionManagerImpl-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.079 [lifecycle-coordinator-641] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.client.MemberResourceClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.133 [lifecycle-coordinator-641] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.MemberRegistrationRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.client.MemberResourceClient changing to state DOWN
2024-08-18 16:26:50.120 [lifecycle-coordinator-662] INFO  DynamicKeyStore-1 {} - Stopping resources
2024-08-18 16:26:50.136 [lifecycle-coordinator-662] INFO  DynamicKeyStore-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.115 [lifecycle-coordinator-664] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.configuration.endpoints.v1.ConfigRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.115 [lifecycle-coordinator-663] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.HsmRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.111 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.certificate.service.CertificatesService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.154 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.validation.cache.PermissionValidationCacheService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.154 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpi.upload.endpoints.service.CpiUploadService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.155 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.client.MemberResourceClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.156 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpk.read.CpkReadService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.157 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.components.rest.RestGateway received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.157 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.p2p.linkmanager.internal.LinkManagerProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.160 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.persistence.client.MembershipPersistenceClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.162 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.client.hsm.HSMRegistrationClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.081 [lifecycle-coordinator-623] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.member.MemberProcessor received RegistrationStatusChangeEvent DOWN due to net.corda.membership.registration.RegistrationProxy changing to state DOWN
2024-08-18 16:26:50.105 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.certificate.publisher.MembersClientCertificatePublisher from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.081 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.RegistrationManagementService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.172 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.173 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator InMemorySessionReplayer-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.174 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator inbound_message_processor_group-link.in-subscription-tile-13 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.175 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionHealthManager-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.102 [lifecycle-coordinator-617] INFO  net.corda.web.server.JavalinServer {} - Starting Worker Web Server on port: 7004
2024-08-18 16:26:50.099 [lifecycle-coordinator-659] INFO  net.corda.membership.groupparams.writer.service.impl.GroupParametersWriterServiceImpl {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.membership.groupparams.writer.service.GroupParametersWriterService,coordinators=net.corda.configuration.read.ConfigurationReadService), status=DOWN).
2024-08-18 16:26:50.177 [lifecycle-coordinator-659] INFO  net.corda.membership.groupparams.writer.service.impl.GroupParametersWriterServiceImpl {} - Handling registration changed event.
2024-08-18 16:26:50.093 [lifecycle-coordinator-633] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.093 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.uniqueness.backingstore.BackingStoreLifecycle received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.179 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.chunking.read.ChunkReadService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.183 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpk.write.CpkWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.184 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.185 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.configuration.write.ConfigWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-18 16:26:50.092 [lifecycle-coordinator-637] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.083 [lifecycle-coordinator-646] INFO  net.corda.membership.service.impl.MemberOpsServiceImpl {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.membership.service.MemberOpsService,coordinators=net.corda.configuration.read.ConfigurationReadService, net.corda.membership.registration.RegistrationProxy, net.corda.virtualnode.read.VirtualNodeInfoReadService, net.corda.membership.read.MembershipGroupReaderProvider, net.corda.membership.persistence.client.MembershipQueryClient, net.corda.crypto.client.CryptoOpsClient, net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService), status=DOWN)
2024-08-18 16:26:50.083 [lifecycle-coordinator-648] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.permissions.storage.reader.PermissionStorageReaderService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.084 [lifecycle-coordinator-650] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.persistence.service.MembershipPersistenceService from status UP to DOWN. Reason: Dependencies are down.
2024-08-18 16:26:50.087 [lifecycle-coordinator-654] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.088 [lifecycle-coordinator-621] INFO  net.corda.membership.impl.synchronisation.SynchronisationProxyImpl {} - Synchronisation proxy stopping.
2024-08-18 16:26:50.191 [lifecycle-coordinator-621] INFO  net.corda.membership.groupparams.writer.service.impl.GroupParametersWriterServiceImpl {} - GroupParametersWriterService stopped.
2024-08-18 16:26:50.193 [lifecycle-coordinator-621] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-18 16:26:50.088 [lifecycle-coordinator-657] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.components.scheduler.TriggerPublisher from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.088 [lifecycle-coordinator-656] INFO  CommonComponents-2 {} - Stopping resources
2024-08-18 16:26:50.195 [lifecycle-coordinator-656] INFO  CommonComponents-2 {} - Unregistered for Config updates.
2024-08-18 16:26:50.196 [lifecycle-coordinator-656] INFO  CommonComponents-2 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.196 [lifecycle-coordinator-654] INFO  CommonComponents-2 {} - Stopping resources
2024-08-18 16:26:50.197 [lifecycle-coordinator-654] INFO  CommonComponents-2 {} - Stopping resources
2024-08-18 16:26:50.198 [lifecycle-coordinator-654] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator CommonComponents-2 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.199 [lifecycle-coordinator-654] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator LinkManager-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-2 changing to state DOWN
2024-08-18 16:26:50.200 [lifecycle-coordinator-654] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator outbound_message_processor_group-p2p.out-subscription-tile-12 received RegistrationStatusChangeEvent DOWN due to CommonComponents-2 changing to state DOWN
2024-08-18 16:26:50.087 [lifecycle-coordinator-655] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.rest.v1.FlowClassRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.087 [lifecycle-coordinator-653] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.certificate.client.CertificatesClient from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.203 [lifecycle-coordinator-653] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.NetworkRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.certificate.client.CertificatesClient changing to state DOWN
2024-08-18 16:26:50.085 [lifecycle-coordinator-651] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-85c91f7f-b408-4e0d-a582-5524702857f8 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.206 [lifecycle-coordinator-651] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-85c91f7f-b408-4e0d-a582-5524702857f8 is stopping
2024-08-18 16:26:50.085 [lifecycle-coordinator-622] INFO  inbound_message_processor_group-link.in-subscription-tile-13 {} - The status of net.corda.membership.grouppolicy.GroupPolicyProvider changed from UP to DOWN, stopping subscription.
2024-08-18 16:26:50.208 [lifecycle-coordinator-622] INFO  inbound_message_processor_group-link.in-subscription-tile-13 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.200 [lifecycle-coordinator-648] INFO  outbound_message_processor_group-p2p.out-subscription-tile-12 {} - The status of CommonComponents-2 changed from UP to DOWN, stopping subscription.
2024-08-18 16:26:50.200 [lifecycle-coordinator-656] INFO  LinkManager-1 {} - Stopping resources
2024-08-18 16:26:50.212 [lifecycle-coordinator-656] INFO  LinkManager-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.214 [lifecycle-coordinator-651] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator LinkManager-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.194 [lifecycle-coordinator-657] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-flow-status-cleanup received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-18 16:26:50.220 [lifecycle-coordinator-657] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-ledger-repair received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-18 16:26:50.222 [lifecycle-coordinator-657] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-flow-session-timeout received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-18 16:26:50.224 [lifecycle-coordinator-657] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-deduplication-table-clean-up-task received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-18 16:26:50.225 [lifecycle-coordinator-657] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-flow-mapper-state-cleanup received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-18 16:26:50.089 [lifecycle-coordinator-658] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.RegistrationManagementService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.231 [lifecycle-coordinator-658] INFO  net.corda.membership.impl.registration.dynamic.RegistrationManagementServiceImpl {} - Received event StopEvent(errored=false)
2024-08-18 16:26:50.092 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator SessionHealthManager-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.243 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to SessionHealthManager-1 changing to state DOWN
2024-08-18 16:26:50.186 [lifecycle-coordinator-667] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.246 [lifecycle-coordinator-667] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> changing to state DOWN
2024-08-18 16:26:50.180 [lifecycle-coordinator-633] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.uniqueness.backingstore.BackingStoreLifecycle,coordinators=net.corda.db.connection.manager.DbConnectionManager), status=DOWN)
2024-08-18 16:26:50.176 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.175 [lifecycle-coordinator-660] INFO  InMemorySessionReplayer-1 {} - Stopping resources
2024-08-18 16:26:50.255 [lifecycle-coordinator-660] INFO  InMemorySessionReplayer-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.171 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator InMemorySessionReplayer-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.171 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.mgm.MGMRegistrationService received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.171 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.staticnetwork.StaticMemberRegistrationService received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.261 [lifecycle-coordinator-605] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.rest.FlowRestResourceService received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-18 16:26:50.171 [lifecycle-coordinator-647] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - Received event StopEvent(errored=false).
2024-08-18 16:26:50.165 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.264 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.management.cache.PermissionManagementCacheService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.265 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.read.GroupParametersReaderService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.266 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpiinfo.read.CpiInfoReadService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.268 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.virtualnode.read.VirtualNodeInfoReadService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.271 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.mtls.allowed.list.service.AllowedCertificatesReaderWriterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.272 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.274 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpiinfo.write.CpiInfoWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.155 [lifecycle-coordinator-664] INFO  net.corda.permissions.validation.cache.PermissionValidationCacheService {} - Registration status change received: DOWN.
2024-08-18 16:26:50.278 [lifecycle-coordinator-664] INFO  net.corda.permissions.validation.cache.PermissionValidationCacheService {} - Performing down transition
2024-08-18 16:26:50.139 [flow-event-mediator-long-running-thread-018875ac-406c-4e97-a185-2763c0a6a0f2] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--568848af-1180-4763-95f3-5ebcbacf0e6c {} - Partitions revoked: 0.
2024-08-18 16:26:50.139 [flow-event-mediator-long-running-thread-b98a914a-3af5-43a6-b72e-f79d504bb629] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--02da1976-ec5e-40dc-a02d-bf0366fad43e {} - Partitions revoked: 0.
2024-08-18 16:26:50.138 [flow-event-mediator-long-running-thread-48b2288b-9366-4fc7-a3df-13a6d5bb1ba5] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--8bb16bf0-cbf4-4e9d-baa5-811ac6103712 {} - Partitions revoked: 0.
2024-08-18 16:26:50.138 [lifecycle-coordinator-668] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator DynamicKeyStore-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.137 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.MemberRegistrationRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.295 [lifecycle-coordinator-673] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.mtls.allowed.list.service.AllowedCertificatesReaderWriterService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.134 [lifecycle-coordinator-666] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.122 [lifecycle-coordinator-665] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.KeyRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.133 [lifecycle-coordinator-643] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to StatefulSessionManagerImpl-1 changing to state DOWN
2024-08-18 16:26:50.301 [lifecycle-coordinator-643] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to StatefulSessionManagerImpl-1 changing to state DOWN
2024-08-18 16:26:50.301 [lifecycle-coordinator-673] INFO  CommonComponents-2 {} - Stopping resources
2024-08-18 16:26:50.296 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.management.PermissionManagementService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.291 [lifecycle-coordinator-668] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-1 received RegistrationStatusChangeEvent DOWN due to DynamicKeyStore-1 changing to state DOWN
2024-08-18 16:26:50.304 [lifecycle-coordinator-643] INFO  CommonComponents-1 {} - Stopping resources
2024-08-18 16:26:50.262 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.KeysRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.304 [lifecycle-coordinator-618] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-18 16:26:50.262 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.304 [lifecycle-coordinator-620] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-18 16:26:50.261 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.mgm.MGMRegistrationService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.256 [lifecycle-coordinator-667] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator InMemorySessionReplayer-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.305 [lifecycle-coordinator-667] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to InMemorySessionReplayer-1 changing to state DOWN
2024-08-18 16:26:50.305 [lifecycle-coordinator-652] INFO  InMemorySessionReplayer-1 {} - Stopping resources
2024-08-18 16:26:50.252 [lifecycle-coordinator-633] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store is DOWN
2024-08-18 16:26:50.248 [lifecycle-coordinator-623] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.247 [lifecycle-coordinator-637] INFO  SessionHealthManager-1 {} - Stopping resources
2024-08-18 16:26:50.246 [lifecycle-coordinator-651] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.183 [lifecycle-coordinator-669] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.chunking.read.ChunkReadService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.230 [lifecycle-coordinator-601] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-flow-mapper-state-cleanup from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.226 [lifecycle-coordinator-639] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-deduplication-table-clean-up-task from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.225 [lifecycle-coordinator-650] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-flow-session-timeout from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.223 [lifecycle-coordinator-655] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-ledger-repair from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.221 [lifecycle-coordinator-656] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-flow-status-cleanup from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.210 [lifecycle-coordinator-648] INFO  outbound_message_processor_group-p2p.out-subscription-tile-12 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.205 [lifecycle-coordinator-654] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.NetworkRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.306 [lifecycle-coordinator-637] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.306 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.uniqueness.backingstore.BackingStoreLifecycle from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.308 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.uniqueness.checker.UniquenessCheckerLifecycle received RegistrationStatusChangeEvent DOWN due to net.corda.uniqueness.backingstore.BackingStoreLifecycle changing to state DOWN
2024-08-18 16:26:50.262 [lifecycle-coordinator-598] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-18 16:26:50.304 [lifecycle-coordinator-673] INFO  net.corda.permissions.management.internal.PermissionManagementServiceEventHandler {} - Registration status change received: DOWN.
2024-08-18 16:26:50.304 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.KeysRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-18 16:26:50.304 [lifecycle-coordinator-643] INFO  CommonComponents-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.266 [lifecycle-coordinator-672] INFO  net.corda.permissions.management.cache.PermissionManagementCacheService {} - Registration status change received: DOWN.
2024-08-18 16:26:50.309 [lifecycle-coordinator-598] INFO  net.corda.membership.impl.read.cache.MembershipGroupReadCache$Impl {} - Clearing membership group read cache.
2024-08-18 16:26:50.266 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.staticnetwork.StaticMemberRegistrationService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.309 [lifecycle-coordinator-598] INFO  net.corda.membership.impl.read.cache.MemberListCache$Impl {} - Clearing member list cache.
2024-08-18 16:26:50.264 [lifecycle-coordinator-647] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - Handling stop event.
2024-08-18 16:26:50.303 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.group.policy.validation.MembershipGroupPolicyValidator received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.310 [lifecycle-coordinator-596] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.rest.KeyRotationRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-18 16:26:50.310 [lifecycle-coordinator-673] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.group.policy.validation.MembershipGroupPolicyValidator from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.301 [lifecycle-coordinator-660] INFO  StatefulSessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.301 [lifecycle-coordinator-665] INFO  message-tracker-group-p2p.out.markers-subscription-tile-1 {} - The status of StatefulSessionManagerImpl-1 changed from UP to DOWN, stopping subscription.
2024-08-18 16:26:50.310 [lifecycle-coordinator-643] INFO  net.corda.crypto.rest.impl.KeyRotationRestResourceImpl {} - Handling KeyRotationRestResource event, RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.crypto.rest.KeyRotationRestResource,coordinators=net.corda.configuration.read.ConfigurationReadService), status=DOWN).
2024-08-18 16:26:50.310 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.permissions.management.PermissionManagementService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.311 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.permissions.endpoints.v1.role.RoleEndpoint received RegistrationStatusChangeEvent DOWN due to net.corda.permissions.management.PermissionManagementService changing to state DOWN
2024-08-18 16:26:50.311 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.permissions.endpoints.v1.user.UserEndpoint received RegistrationStatusChangeEvent DOWN due to net.corda.permissions.management.PermissionManagementService changing to state DOWN
2024-08-18 16:26:50.309 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator CommonComponents-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.311 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator Gateway-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-1 changing to state DOWN
2024-08-18 16:26:50.308 [lifecycle-coordinator-637] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.312 [lifecycle-coordinator-637] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.310 [lifecycle-coordinator-647] INFO  net.corda.membership.impl.read.cache.MemberDataCache$Impl {} - Clearing member data cache.
2024-08-18 16:26:50.311 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.rest.KeyRotationRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.312 [lifecycle-coordinator-643] INFO  net.corda.libs.permissions.endpoints.common.PermissionEndpointEventHandler {} - RoleEndpoint: Received status update from PermissionServiceComponent: DOWN.
2024-08-18 16:26:50.311 [lifecycle-coordinator-665] INFO  message-tracker-group-p2p.out.markers-subscription-tile-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.312 [lifecycle-coordinator-637] INFO  net.corda.libs.permissions.endpoints.common.PermissionEndpointEventHandler {} - UserEndpoint: Received status update from PermissionServiceComponent: DOWN.
2024-08-18 16:26:50.312 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.components.rbac.RBACSecurityManagerService received RegistrationStatusChangeEvent DOWN due to net.corda.permissions.management.PermissionManagementService changing to state DOWN
2024-08-18 16:26:50.311 [lifecycle-coordinator-598] INFO  net.corda.membership.impl.read.cache.MemberDataCache$Impl {} - Clearing member data cache.
2024-08-18 16:26:50.313 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.permissions.endpoints.v1.permission.PermissionEndpoint received RegistrationStatusChangeEvent DOWN due to net.corda.permissions.management.PermissionManagementService changing to state DOWN
2024-08-18 16:26:50.312 [lifecycle-coordinator-673] INFO  Gateway-1 {} - Stopping resources
2024-08-18 16:26:50.313 [lifecycle-coordinator-673] INFO  Gateway-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.312 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator OutboundMessageHandler-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-1 changing to state DOWN
2024-08-18 16:26:50.313 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator ReconfigurableHttpServer-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-1 changing to state DOWN
2024-08-18 16:26:50.313 [lifecycle-coordinator-637] INFO  net.corda.components.rbac.RBACSecurityManagerService {} - Received registration status update DOWN.
2024-08-18 16:26:50.313 [lifecycle-coordinator-643] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.permissions.endpoints.v1.user.UserEndpoint from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.313 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.permissions.endpoints.v1.role.RoleEndpoint from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.314 [lifecycle-coordinator-654] INFO  ReconfigurableHttpServer-1 {} - Stopping resources
2024-08-18 16:26:50.313 [lifecycle-coordinator-671] INFO  OutboundMessageHandler-1 {} - Stopping resources
2024-08-18 16:26:50.313 [lifecycle-coordinator-652] INFO  net.corda.libs.permissions.endpoints.common.PermissionEndpointEventHandler {} - PermissionEndpoint: Received status update from PermissionServiceComponent: DOWN.
2024-08-18 16:26:50.314 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.permissions.endpoints.v1.permission.PermissionEndpoint from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.314 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator Gateway-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.314 [lifecycle-coordinator-671] INFO  OutboundMessageHandler-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-18 16:26:50.315 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator OutboundMessageHandler-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.315 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator Gateway-1 received RegistrationStatusChangeEvent DOWN due to OutboundMessageHandler-1 changing to state DOWN
2024-08-18 16:26:50.315 [lifecycle-coordinator-671] INFO  Gateway-1 {} - Stopping resources
2024-08-18 16:26:50.376 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.member.DynamicMemberRegistrationService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.741 [lifecycle-coordinator-600] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store stopping
2024-08-18 16:26:50.742 [lifecycle-coordinator-640] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.virtualnode.write.db.VirtualNodeWriteService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.742 [lifecycle-coordinator-652] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.rest.FlowStatusLookupService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.742 [lifecycle-coordinator-603] INFO  LinkManager-1 {} - Stopping resources
2024-08-18 16:26:50.742 [lifecycle-coordinator-671] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-31616f89-c86d-45a7-aaf7-55e1f73282ec from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.744 [lifecycle-coordinator-671] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-31616f89-c86d-45a7-aaf7-55e1f73282ec is stopping
2024-08-18 16:26:50.741 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stop event received, stopping dependencies.
2024-08-18 16:26:50.744 [lifecycle-coordinator-621] INFO  net.corda.processors.member.internal.lifecycle.MemberProcessorLifecycleHandler {} - Member processor stopping.
2024-08-18 16:26:50.744 [lifecycle-coordinator-649] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for flow-status-cleanup
2024-08-18 16:26:50.746 [lifecycle-coordinator-649] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for deduplication-table-clean-up-task
2024-08-18 16:26:50.746 [lifecycle-coordinator-649] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for flow-mapper-state-cleanup
2024-08-18 16:26:50.747 [lifecycle-coordinator-649] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for flow-session-timeout
2024-08-18 16:26:50.747 [lifecycle-coordinator-649] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for ledger-repair
2024-08-18 16:26:50.744 [lifecycle-coordinator-603] INFO  LinkManager-1 {} - Stopping child CommonComponents-2
2024-08-18 16:26:50.756 [lifecycle-coordinator-603] INFO  LinkManager-1 {} - Stopping child outbound_message_processor_group-p2p.out-subscription-tile-12
2024-08-18 16:26:50.756 [lifecycle-coordinator-603] INFO  LinkManager-1 {} - Stopping child inbound_message_processor_group-link.in-subscription-tile-13
2024-08-18 16:26:50.742 [lifecycle-coordinator-661] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-d098c6b0-744b-4ff0-9829-dd633835644a from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.758 [lifecycle-coordinator-661] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to StateManager-d098c6b0-744b-4ff0-9829-dd633835644a changing to state DOWN
2024-08-18 16:26:50.759 [lifecycle-coordinator-661] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator StatefulSessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to StateManager-d098c6b0-744b-4ff0-9829-dd633835644a changing to state DOWN
2024-08-18 16:26:50.743 [lifecycle-coordinator-637] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.virtualnode.endpoints.v1.VirtualNodeRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.761 [lifecycle-coordinator-661] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-d098c6b0-744b-4ff0-9829-dd633835644a is stopping
2024-08-18 16:26:50.743 [lifecycle-coordinator-673] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.virtualnode.maintenance.endpoints.v1.VirtualNodeMaintenanceRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-18 16:26:50.760 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: CpiUploadRestResourceImpl
2024-08-18 16:26:50.759 [lifecycle-coordinator-616] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.components.rbac.RBACSecurityManagerService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.757 [lifecycle-coordinator-644] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator InboundAssignmentListener-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.766 [lifecycle-coordinator-644] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator outbound_message_processor_group-p2p.out-subscription-tile-12 received RegistrationStatusChangeEvent DOWN due to InboundAssignmentListener-1 changing to state DOWN
2024-08-18 16:26:50.757 [lifecycle-coordinator-603] INFO  LinkManager-1 {} - State updated from StoppedDueToChildStopped to StoppedByParent
2024-08-18 16:26:50.757 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator DeliveryTracker-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.770 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator outbound_message_processor_group-p2p.out-subscription-tile-12 received RegistrationStatusChangeEvent DOWN due to DeliveryTracker-1 changing to state DOWN
2024-08-18 16:26:50.743 [lifecycle-coordinator-635] INFO  Gateway-1 {} - Stopping resources
2024-08-18 16:26:50.771 [lifecycle-coordinator-635] INFO  Gateway-1 {} - Stopping child CommonComponents-1
2024-08-18 16:26:50.746 [lifecycle-coordinator-621] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.permissions.validation.PermissionValidationService from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.756 [lifecycle-coordinator-649] INFO  CommonComponents-2 {} - Stopping resources
2024-08-18 16:26:50.770 [lifecycle-coordinator-613] INFO  DeliveryTracker-1 {} - Stopping resources
2024-08-18 16:26:50.774 [lifecycle-coordinator-613] INFO  DeliveryTracker-1 {} - Stopping child message-tracker-group-p2p.out.markers-subscription-tile-1
2024-08-18 16:26:50.784 [lifecycle-coordinator-613] INFO  DeliveryTracker-1 {} - State updated from Started to StoppedByParent
2024-08-18 16:26:50.768 [lifecycle-coordinator-616] INFO  net.corda.components.rbac.RBACSecurityManagerService {} - Stop event received, stopping dependencies and setting status to DOWN.
2024-08-18 16:26:50.768 [lifecycle-coordinator-644] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to InboundAssignmentListener-1 changing to state DOWN
2024-08-18 16:26:50.788 [lifecycle-coordinator-637] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator Publisher-11 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.790 [lifecycle-coordinator-637] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to Publisher-11 changing to state DOWN
2024-08-18 16:26:50.765 [lifecycle-coordinator-661] ERROR net.corda.lifecycle.impl.LifecycleProcessor {} - Registration(registeringCoordinator=CommonComponents-2,coordinators=StateManager-d098c6b0-744b-4ff0-9829-dd633835644a) on StateManager-d098c6b0-744b-4ff0-9829-dd633835644a not closed.
2024-08-18 16:26:50.792 [lifecycle-coordinator-661] ERROR net.corda.lifecycle.impl.LifecycleProcessor {} - Registration(registeringCoordinator=StatefulSessionManagerImpl-1,coordinators=StateManager-d098c6b0-744b-4ff0-9829-dd633835644a) on StateManager-d098c6b0-744b-4ff0-9829-dd633835644a not closed.
2024-08-18 16:26:50.765 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: VirtualNodeRestResourceImpl
2024-08-18 16:26:50.761 [lifecycle-coordinator-610] INFO  StatefulSessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.742 [lifecycle-coordinator-660] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store received event StopEvent(errored=false)
2024-08-18 16:26:50.803 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: HsmRestResourceImpl
2024-08-18 16:26:50.806 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: KeyRestResourceImpl
2024-08-18 16:26:50.807 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: KeysRestResourceImpl
2024-08-18 16:26:50.809 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: KeyRotationRestResourceImpl
2024-08-18 16:26:50.800 [lifecycle-coordinator-661] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.ExpirationProcessor from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.792 [lifecycle-coordinator-603] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator ReplayScheduler-2 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.818 [lifecycle-coordinator-603] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to ReplayScheduler-2 changing to state DOWN
2024-08-18 16:26:50.819 [lifecycle-coordinator-603] INFO  ReplayScheduler-2 {} - Stopping resources
2024-08-18 16:26:50.788 [lifecycle-coordinator-626] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.773 [lifecycle-coordinator-649] INFO  CommonComponents-2 {} - Stopping child LinkManagerHostingMapImpl-1
2024-08-18 16:26:50.772 [lifecycle-coordinator-635] INFO  Gateway-1 {} - Stopping child InboundMessageHandler-1
2024-08-18 16:26:50.772 [lifecycle-coordinator-621] INFO  net.corda.permissions.validation.PermissionValidationService {} - Stop event received, stopping dependencies.
2024-08-18 16:26:50.772 [lifecycle-coordinator-673] INFO  CommonComponents-1 {} - Stopping resources
2024-08-18 16:26:50.826 [lifecycle-coordinator-673] INFO  CommonComponents-1 {} - Stopping child DynamicKeyStore-1
2024-08-18 16:26:50.825 [lifecycle-coordinator-610] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator InboundMessageHandler-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.826 [lifecycle-coordinator-610] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator Gateway-1 received RegistrationStatusChangeEvent DOWN due to InboundMessageHandler-1 changing to state DOWN
2024-08-18 16:26:50.825 [lifecycle-coordinator-635] INFO  Gateway-1 {} - Stopping child OutboundMessageHandler-1
2024-08-18 16:26:50.823 [lifecycle-coordinator-626] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator LinkManagerHostingMapImpl-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.827 [lifecycle-coordinator-626] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to LinkManagerHostingMapImpl-1 changing to state DOWN
2024-08-18 16:26:50.827 [lifecycle-coordinator-626] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to LinkManagerHostingMapImpl-1 changing to state DOWN
2024-08-18 16:26:50.823 [lifecycle-coordinator-649] INFO  CommonComponents-2 {} - Stopping child Publisher-2
2024-08-18 16:26:50.821 [lifecycle-coordinator-603] INFO  ReplayScheduler-2 {} - Unregistered for Config updates.
2024-08-18 16:26:50.814 [lifecycle-coordinator-637] INFO  net.corda.crypto.rest.impl.KeyRotationRestResourceImpl {} - Handling KeyRotationRestResource event, StopEvent(errored=false).
2024-08-18 16:26:50.828 [lifecycle-coordinator-603] INFO  ReplayScheduler-2 {} - State updated from Started to StoppedByParent
2024-08-18 16:26:50.827 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator Publisher-2 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.828 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to Publisher-2 changing to state DOWN
2024-08-18 16:26:50.827 [lifecycle-coordinator-649] INFO  CommonComponents-2 {} - Stopping child StatefulSessionManagerImpl-1
2024-08-18 16:26:50.828 [lifecycle-coordinator-660] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to Publisher-2 changing to state DOWN
2024-08-18 16:26:50.827 [lifecycle-coordinator-621] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.827 [lifecycle-coordinator-626] INFO  LinkManagerHostingMapImpl-1 {} - Stopping resources
2024-08-18 16:26:50.829 [lifecycle-coordinator-626] INFO  LinkManagerHostingMapImpl-1 {} - Stopping child linkmanager_stub_hosting_map-p2p.hosted.identities-subscription-tile-6
2024-08-18 16:26:50.829 [lifecycle-coordinator-626] INFO  LinkManagerHostingMapImpl-1 {} - Stopping child LinkManagerHostingMapImplBlocking-4
2024-08-18 16:26:50.827 [lifecycle-coordinator-661] INFO  OutboundMessageHandler-1 {} - Stopping resources
2024-08-18 16:26:50.830 [lifecycle-coordinator-661] INFO  OutboundMessageHandler-1 {} - Stopping child outbound-message-handler-link.out-subscription-tile-5
2024-08-18 16:26:50.827 [lifecycle-coordinator-635] INFO  Gateway-1 {} - Stopping child GatewayRevocationChecker-GatewayRevocationChecker-subscription-tile-1
2024-08-18 16:26:50.831 [lifecycle-coordinator-635] INFO  Gateway-1 {} - State updated from StoppedDueToChildStopped to StoppedByParent
2024-08-18 16:26:50.832 [lifecycle-coordinator-673] INFO  CommonComponents-1 {} - Stopping child TrustStoresMap-1
2024-08-18 16:26:50.833 [lifecycle-coordinator-673] INFO  CommonComponents-1 {} - State updated from StoppedDueToChildStopped to StoppedByParent
2024-08-18 16:26:50.827 [lifecycle-coordinator-610] INFO  InboundMessageHandler-1 {} - Stopping resources
2024-08-18 16:26:50.833 [lifecycle-coordinator-610] INFO  InboundMessageHandler-1 {} - Stopping child SessionPartitionMapperImpl-1
2024-08-18 16:26:50.834 [lifecycle-coordinator-610] INFO  InboundMessageHandler-1 {} - Stopping child Publisher-0
2024-08-18 16:26:50.834 [lifecycle-coordinator-610] INFO  InboundMessageHandler-1 {} - Stopping child ReconfigurableHttpServer-1
2024-08-18 16:26:50.835 [lifecycle-coordinator-610] INFO  InboundMessageHandler-1 {} - Stopping child gateway_certificates_allowed_client_subjects_reader-gateway.allowed.client.certificate.subjects-subscription-tile-4
2024-08-18 16:26:50.830 [lifecycle-coordinator-661] INFO  OutboundMessageHandler-1 {} - Stopping child Publisher-1
2024-08-18 16:26:50.829 [lifecycle-coordinator-616] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator LinkManagerHostingMapImplBlocking-4 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.829 [lifecycle-coordinator-626] INFO  LinkManagerHostingMapImpl-1 {} - State updated from Started to StoppedByParent
2024-08-18 16:26:50.829 [lifecycle-coordinator-621] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-158927a2-3a3e-4984-8e53-3395e5d7bf85 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.829 [lifecycle-coordinator-660] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.838 [lifecycle-coordinator-649] INFO  CommonComponents-2 {} - Stopping child TrustStoresPublisher-1
2024-08-18 16:26:50.814 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: FlowClassRestResourceImpl
2024-08-18 16:26:50.838 [lifecycle-coordinator-621] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-158927a2-3a3e-4984-8e53-3395e5d7bf85 is stopping
2024-08-18 16:26:50.837 [lifecycle-coordinator-616] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator LinkManagerHostingMapImpl-1 received RegistrationStatusChangeEvent DOWN due to LinkManagerHostingMapImplBlocking-4 changing to state DOWN
2024-08-18 16:26:50.836 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator Publisher-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.836 [lifecycle-coordinator-661] INFO  OutboundMessageHandler-1 {} - State updated from StoppedDueToChildStopped to StoppedByParent
2024-08-18 16:26:50.835 [lifecycle-coordinator-610] INFO  InboundMessageHandler-1 {} - State updated from Started to StoppedByParent
2024-08-18 16:26:50.834 [lifecycle-coordinator-673] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator Publisher-0 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.830 [lifecycle-coordinator-603] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator ReconfigurableConnectionManager-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.844 [lifecycle-coordinator-673] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator InboundMessageHandler-1 received RegistrationStatusChangeEvent DOWN due to Publisher-0 changing to state DOWN
2024-08-18 16:26:50.830 [lifecycle-coordinator-644] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator GatewayConfigReader-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.833 [lifecycle-coordinator-613] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator TrustStoresMap-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.832 [lifecycle-coordinator-635] INFO  DynamicKeyStore-1 {} - Stopping resources
2024-08-18 16:26:50.834 [lifecycle-coordinator-645] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator SessionPartitionMapperImpl-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-18 16:26:50.843 [lifecycle-coordinator-662] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator OutboundMessageHandler-1 received RegistrationStatusChangeEvent DOWN due to Publisher-1 changing to state DOWN
2024-08-18 16:26:50.840 [lifecycle-coordinator-656] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to TrustStoresPublisher-1 changing to state DOWN
2024-08-18 16:26:50.840 [lifecycle-coordinator-655] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator StatefulSessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to Publisher-3 changing to state DOWN
2024-08-18 16:26:50.840 [lifecycle-coordinator-626] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-18 16:26:50.839 [lifecycle-coordinator-649] INFO  CommonComponents-2 {} - Stopping child TlsCertificatesPublisher-1
2024-08-18 16:26:50.840 [lifecycle-coordinator-602] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stopping: FlowRestResourceImpl
