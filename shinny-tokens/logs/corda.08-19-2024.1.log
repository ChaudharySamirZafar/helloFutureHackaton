2024-08-19 00:06:52.313 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 00:06:52.409 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 00:06:52.827 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 00:06:52.828 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 00:07:12.374 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 00:07:12.374 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 00:07:12.374 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 00:07:20.406 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=558d77a8d19be7c7, traceId=66c28cb8d5628241558d77a8d19be7c7} - {"traceId":"66c28cb8d5628241558d77a8d19be7c7","id":"558d77a8d19be7c7","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724026040371380,"duration":33631,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"94","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 00:18:02.902 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 00:18:02.904 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 00:18:02.905 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 00:18:02.908 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 00:18:03.853 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 00:18:03.856 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 00:18:03.856 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 00:18:03.856 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 00:18:03.859 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: .
2024-08-19 00:18:27.392 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cb86416766941fb7, traceId=66c28f5354503742cb86416766941fb7} - {"traceId":"66c28f5354503742cb86416766941fb7","id":"cb86416766941fb7","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724026707255499,"duration":134213,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"10","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 00:18:27.579 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 1 ms
2024-08-19 00:18:31.019 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=323c94986ac84e34, traceId=66c28f563c1110a4323c94986ac84e34} - {"traceId":"66c28f563c1110a4323c94986ac84e34","id":"323c94986ac84e34","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724026710984594,"duration":32724,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"96","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 01:10:28.512 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 01:10:28.517 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions revoked: 0.
2024-08-19 01:10:28.521 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 01:10:28.523 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 01:10:28.524 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 01:10:28.524 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 01:10:29.072 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 01:10:29.074 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 01:10:29.536 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 01:10:29.536 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 01:10:29.537 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 01:10:29.537 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 01:10:29.540 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 01:10:29.540 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 01:10:29.541 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 01:10:29.542 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: .
2024-08-19 01:10:29.542 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 01:10:29.542 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 01:10:56.106 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=927d1e526c1dd406, traceId=66c29ba04b0a7079927d1e526c1dd406} - {"traceId":"66c29ba04b0a7079927d1e526c1dd406","id":"927d1e526c1dd406","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724029856077992,"duration":26989,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"98","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 01:34:27.922 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 01:34:27.923 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 01:34:27.923 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 01:34:27.925 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 01:34:28.011 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 01:34:28.012 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 01:34:28.465 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 01:34:28.466 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 01:34:28.467 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 01:34:28.467 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 01:34:28.466 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 01:34:28.928 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 01:34:28.935 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 01:34:28.935 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: .
2024-08-19 01:34:28.937 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 01:34:28.944 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 01:34:55.770 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b2a57d8162bccc18, traceId=66c2a13f665c47e8b2a57d8162bccc18} - {"traceId":"66c2a13f665c47e8b2a57d8162bccc18","id":"b2a57d8162bccc18","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724031295725863,"duration":43105,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"100","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 03:00:52.369 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 03:00:52.370 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 03:00:52.884 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:00:52.885 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:00:54.154 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:00:54.190 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:00:54.500 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 03:00:54.512 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 03:00:54.501 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 03:01:20.633 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b4cd516fb735ddf6, traceId=66c2b580123f7ffdb4cd516fb735ddf6} - {"traceId":"66c2b580123f7ffdb4cd516fb735ddf6","id":"b4cd516fb735ddf6","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724036480298167,"duration":333835,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"102","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 03:59:36.316 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 03:59:36.318 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 03:59:36.319 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 03:59:36.320 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 03:59:36.795 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:59:36.796 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:59:36.801 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:59:36.801 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:59:56.965 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:59:56.969 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:59:57.135 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 03:59:57.141 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:59:57.140 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:59:57.180 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 03:59:57.235 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 03:59:57.235 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 03:59:57.235 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: .
2024-08-19 03:59:57.425 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 03:59:57.425 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 03:59:57.425 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 04:00:00.447 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=86634ce468c6f1af, traceId=66c2c340f416c98e86634ce468c6f1af} - {"traceId":"66c2c340f416c98e86634ce468c6f1af","id":"86634ce468c6f1af","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724040000413075,"duration":31941,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"12","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 04:00:00.478 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 0 ms
2024-08-19 04:00:05.410 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cdce1a5a9b7ae849, traceId=66c2c3456d031fa8cdce1a5a9b7ae849} - {"traceId":"66c2c3456d031fa8cdce1a5a9b7ae849","id":"cdce1a5a9b7ae849","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724040005386296,"duration":23111,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"104","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 04:36:29.706 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=8e35815b04f987c6, traceId=66c2cbcd80433f2b8e35815b04f987c6} - {"traceId":"66c2cbcd80433f2b8e35815b04f987c6","id":"8e35815b04f987c6","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724042189680847,"duration":22959,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"106","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 05:12:07.499 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:12:07.499 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:12:07.502 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 05:12:07.502 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 05:12:08.020 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:12:08.022 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:12:08.022 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:12:08.022 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:12:08.488 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:12:08.490 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:12:08.495 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:12:08.497 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:12:08.496 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 05:12:08.500 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 05:12:08.500 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 05:12:08.500 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 05:12:08.500 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 05:12:08.500 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: .
2024-08-19 05:12:37.122 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=0086a82a15035eab, traceId=66c2d444f041f5a80086a82a15035eab} - {"traceId":"66c2d444f041f5a80086a82a15035eab","id":"0086a82a15035eab","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724044356884399,"duration":228996,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"108","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 05:44:47.969 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:44:47.970 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:44:47.969 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:44:47.970 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:44:47.970 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:44:47.970 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 05:44:47.971 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 05:44:47.971 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 05:44:47.971 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions revoked: 0.
2024-08-19 05:44:47.971 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 05:44:47.971 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 05:44:48.024 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-19 05:44:48.065 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-19 05:44:48.068 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 05:44:48.071 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 05:44:48.071 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 05:44:51.002 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 05:44:51.002 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 05:44:51.002 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 05:45:08.099 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:45:08.099 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:45:08.167 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:45:08.167 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:45:08.429 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 05:45:08.431 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 05:45:08.545 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: .
2024-08-19 05:45:08.545 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 05:45:08.545 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 05:45:17.651 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b866a095802b84eb, traceId=66c2dbed99513dcbb866a095802b84eb} - {"traceId":"66c2dbed99513dcbb866a095802b84eb","id":"b866a095802b84eb","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724046317603553,"duration":46949,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"110","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 06:33:24.135 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 06:33:24.136 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 06:33:24.136 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 06:33:24.136 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 06:33:24.137 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 06:33:24.137 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 06:33:24.137 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 06:33:24.138 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 06:33:24.664 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 06:33:24.673 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 06:33:25.148 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 06:33:25.150 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 06:33:25.158 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 06:33:25.158 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 06:33:25.158 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 06:33:27.170 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 06:33:27.172 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 06:33:27.170 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 06:33:48.294 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=351075063c3c05a4, traceId=66c2e74c9688d7ae351075063c3c05a4} - {"traceId":"66c2e74c9688d7ae351075063c3c05a4","id":"351075063c3c05a4","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724049228251477,"duration":41579,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"14","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 06:33:48.309 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 0 ms
2024-08-19 06:33:53.892 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=83d84c11ec93423f, traceId=66c2e751eff1fd0183d84c11ec93423f} - {"traceId":"66c2e751eff1fd0183d84c11ec93423f","id":"83d84c11ec93423f","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724049233870208,"duration":20923,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"112","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 07:08:00.347 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 07:08:00.348 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 07:08:00.361 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 07:08:00.362 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 07:08:00.878 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:08:00.880 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:08:00.881 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 07:08:00.881 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 07:08:00.881 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 07:08:30.220 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9caeaa2f8335cc16, traceId=66c2ef6eada34b629caeaa2f8335cc16} - {"traceId":"66c2ef6eada34b629caeaa2f8335cc16","id":"9caeaa2f8335cc16","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724051310166673,"duration":47052,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"114","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 07:29:41.284 [lifecycle-coordinator-65] WARN  net.corda.messagebus.kafka.producer.CordaKafkaProducerImpl {} - Unexpected transient error committing transaction, re-trying
org.apache.kafka.common.errors.TimeoutException: Expiring 1 record(s) for scheduled.task.flow.processor-0:1270991 ms has passed since batch creation
2024-08-19 07:29:41.300 [lifecycle-coordinator-65] WARN  net.corda.messaging.publisher.CordaPublisherImpl {} - Attempting a single transaction retry
2024-08-19 07:29:41.332 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 07:29:41.333 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 07:29:41.345 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 07:29:41.345 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 07:29:41.378 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 07:29:41.379 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 07:29:41.427 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:29:41.428 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:29:41.856 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:29:41.857 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:29:42.364 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:29:42.372 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:29:42.376 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 07:29:42.376 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 07:29:42.377 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 07:30:01.418 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:30:01.431 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:30:01.635 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:30:01.637 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:30:01.644 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 07:30:01.644 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 07:30:01.644 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 07:45:34.965 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d705a390b06d6263, traceId=66c2f81ee42ffab2d705a390b06d6263} - {"traceId":"66c2f81ee42ffab2d705a390b06d6263","id":"d705a390b06d6263","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724053534943027,"duration":21322,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"116","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 07:45:35.038 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 07:45:35.039 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 07:45:35.539 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:45:35.541 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:45:36.778 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 07:45:36.780 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 07:45:36.783 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 07:45:36.784 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 07:45:36.785 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 08:01:09.321 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before successfully committing offsets {flow.session-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}}
2024-08-19 08:01:09.331 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:01:09.447 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:01:09.448 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 08:01:09.457 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:01:09.468 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:01:09.474 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 08:01:09.479 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:01:09.483 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions revoked: 0.
2024-08-19 08:01:09.489 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=1097b8c505dd5bbf, traceId=66c2fbc5ead84e241097b8c505dd5bbf} - {"traceId":"66c2fbc5ead84e241097b8c505dd5bbf","id":"1097b8c505dd5bbf","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1724054469440169,"duration":47974,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"118","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-19 08:01:09.458 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-19 08:01:09.491 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-19 08:01:09.492 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 08:01:09.508 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 08:01:09.508 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 08:01:09.508 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 08:01:10.009 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:01:10.009 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:01:29.547 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:01:29.556 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:01:29.832 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:01:29.833 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:01:29.838 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 08:01:29.838 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 08:01:29.838 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 08:01:33.639 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d493f9559a1c5251, traceId=66c2fbdd9406ca69d493f9559a1c5251} - {"traceId":"66c2fbdd9406ca69d493f9559a1c5251","id":"d493f9559a1c5251","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724054493595730,"duration":42097,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"16","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 08:01:33.649 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 0 ms
2024-08-19 08:12:58.849 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:12:58.848 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:12:58.848 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:12:58.848 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:12:58.856 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions revoked: 0.
2024-08-19 08:12:58.856 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 08:12:58.857 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 08:12:58.856 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-19 08:12:58.877 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-19 08:12:58.882 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 08:12:58.904 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=2b8c10c942760c9a, traceId=66c2fe8a74b309b42b8c10c942760c9a} - {"traceId":"66c2fe8a74b309b42b8c10c942760c9a","id":"2b8c10c942760c9a","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1724055178869181,"duration":34509,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"120","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-19 08:12:59.837 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:12:59.838 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:12:59.839 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:12:59.840 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:12:59.843 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 08:12:59.843 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 08:12:59.845 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 08:12:59.846 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 08:12:59.846 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 08:12:59.846 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 08:24:16.570 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:24:16.569 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:24:16.584 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 08:24:16.584 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 08:24:16.677 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=b394788afad04755, traceId=66c30130cb3e3776b394788afad04755} - {"traceId":"66c30130cb3e3776b394788afad04755","id":"b394788afad04755","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1724055856649593,"duration":22344,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"122","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-19 08:24:17.567 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:24:17.569 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 08:24:17.569 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:24:17.569 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 08:24:17.573 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: .
2024-08-19 08:33:05.060 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:33:05.074 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 08:33:05.105 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:33:05.106 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:33:05.114 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 08:33:05.116 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 08:33:05.143 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=96e1482718e71c65, traceId=66c303403ee4b53496e1482718e71c65} - {"traceId":"66c303403ee4b53496e1482718e71c65","id":"96e1482718e71c65","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724056384581849,"duration":560705,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"124","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 08:33:05.963 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:33:05.964 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:33:05.964 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 08:33:05.964 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 08:33:05.967 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: .
2024-08-19 08:33:24.944 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:33:24.974 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:33:25.101 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:33:25.102 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:33:25.242 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 08:33:25.242 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 08:33:25.242 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 08:56:38.076 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 08:56:38.084 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 08:56:38.500 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:56:38.501 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:56:38.969 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 08:56:38.974 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 08:56:38.990 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 08:56:38.992 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: .
2024-08-19 08:56:38.992 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: .
2024-08-19 08:56:39.436 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=dfd6e4bdcb4a6339, traceId=66c308c7c1886275dfd6e4bdcb4a6339} - {"traceId":"66c308c7c1886275dfd6e4bdcb4a6339","id":"dfd6e4bdcb4a6339","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724057799385816,"duration":49632,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"126","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 08:57:02.332 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=43f88d2243c59b40, traceId=66c308de4971a4ac43f88d2243c59b40} - {"traceId":"66c308de4971a4ac43f88d2243c59b40","id":"43f88d2243c59b40","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724057822228490,"duration":102369,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"18","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 08:57:02.348 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 0 ms
2024-08-19 09:06:24.088 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:06:24.092 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 09:06:24.616 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 09:06:24.618 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 09:06:25.501 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d5e2debba220d3db, traceId=66c30b1181fb7e3dd5e2debba220d3db} - {"traceId":"66c30b1181fb7e3dd5e2debba220d3db","id":"d5e2debba220d3db","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724058385471277,"duration":28997,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"128","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 09:06:44.111 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 09:06:44.114 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 09:06:44.114 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 09:06:44.115 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 09:06:44.116 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 09:43:54.846 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:43:54.846 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:43:54.846 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:43:54.846 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:43:54.846 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:43:54.861 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 09:43:54.861 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 09:43:54.854 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-19 09:43:54.854 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-19 09:43:54.893 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-19 09:43:54.893 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-19 09:43:54.855 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] ERROR net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Error attempting to commitSync offsets.
org.apache.kafka.clients.consumer.CommitFailedException: Offset commit cannot be completed since the consumer is not part of an active group for auto partition assignment; it is likely that the consumer was kicked out of the group.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.sendOffsetCommitRequest(ConsumerCoordinator.java:1351) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1188) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1450) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1349) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1306) ~[org.apache.servicemix.bundles.kafka-clients-3.6.1_1.jar:?]
	at net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl.syncCommitOffsets(CordaKafkaConsumerImpl.kt:314) ~[?:?]
	at net.corda.messaging.mediator.MessageBusConsumer.syncCommitOffsets(MessageBusConsumer.kt:20) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit$lambda$17(ConsumerProcessor.kt:273) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) ~[micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.commit(ConsumerProcessor.kt:272) ~[?:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop$lambda$1(ConsumerProcessor.kt:123) ~[?:?]
	at io.micrometer.core.instrument.composite.CompositeTimer.recordCallable(CompositeTimer.java:129) [micrometer-core-1.12.3.jar:1.12.3]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.pollLoop(ConsumerProcessor.kt:118) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.processor.ConsumerProcessor.processTopic(ConsumerProcessor.kt:76) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:51) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.messaging.mediator.MultiSourceEventMediatorImpl$runMediator$1$1.invoke(MultiSourceEventMediatorImpl.kt:48) [corda-messaging-impl-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:63) [corda-task-manager-5.2.0.0.jar:?]
	at net.corda.taskmanager.impl.TaskManagerImpl$executeLongRunningTask$1.invoke(TaskManagerImpl.kt:55) [corda-task-manager-5.2.0.0.jar:?]
	at kotlin.concurrent.ThreadsKt$thread$thread$1.run(Thread.kt:30) [kotlin-osgi-bundle-1.8.21.jar:1.8.21]
2024-08-19 09:43:54.901 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 09:43:54.903 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 09:43:54.904 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Error attempting to commitSync offsets..
2024-08-19 09:43:54.914 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 09:43:54.944 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 09:43:54.944 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 09:43:54.944 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 09:43:55.349 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 09:43:55.349 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 09:43:55.349 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 09:43:56.327 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=81ac2d9adc3b1b92, traceId=66c313dc0366577481ac2d9adc3b1b92} - {"traceId":"66c313dc0366577481ac2d9adc3b1b92","id":"81ac2d9adc3b1b92","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724060636315116,"duration":12517,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"131","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 09:54:04.476 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:54:04.477 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:54:04.478 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:54:04.476 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:54:04.479 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 09:54:04.484 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 09:54:04.484 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions revoked: 0.
2024-08-19 09:54:04.484 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 09:54:04.484 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions revoked: 0.
2024-08-19 09:54:04.485 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions revoked: 0.
2024-08-19 09:54:06.417 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=c7804730af7430cb, traceId=66c3163e8d60c56fc7804730af7430cb} - {"traceId":"66c3163e8d60c56fc7804730af7430cb","id":"c7804730af7430cb","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724061246124294,"duration":265085,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"132","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 09:54:07.544 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: 0.
2024-08-19 09:54:07.544 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: 0.
2024-08-19 09:54:07.544 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 09:54:24.464 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 09:54:24.479 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 09:54:24.689 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: . Invalidated flow fiber cache.
2024-08-19 09:54:24.689 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 09:54:24.689 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 10:17:36.386 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before successfully committing offsets {flow.session-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}}
2024-08-19 10:17:36.386 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.TimeoutException: Timeout of 60000ms expired before successfully committing offsets {flow.start-0=OffsetAndMetadata{offset=0, leaderEpoch=null, metadata=''}}
2024-08-19 10:17:36.390 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 10:17:36.390 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 10:17:36.491 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 10:17:36.491 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 10:17:36.492 [kafka-coordinator-heartbeat-thread | FlowEventConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5-eventConsumer, groupId=FlowEventConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 10:17:36.502 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions revoked: 0.
2024-08-19 10:17:36.523 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions revoked: 0.
2024-08-19 10:17:36.523 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions revoked: 0.
2024-08-19 10:17:36.531 [kafka-coordinator-heartbeat-thread | FlowMapperConsumer-cooperative] WARN  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator {} - [Consumer clientId=eventConsumer--MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164-eventConsumer, groupId=FlowMapperConsumer-cooperative] consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2024-08-19 10:17:36.531 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions revoked: 0.
2024-08-19 10:17:36.545 [flow-event-mediator-long-running-thread-192b3e14-b334-413a-b46e-bdf5e0492037] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.event--11727760-e7a6-4a4b-ba86-e405a85456f5 {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 10:17:36.545 [flow-event-mediator-long-running-thread-57fe6701-374f-407d-a544-1d65cc831712] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.session--619a6d21-584a-432d-8f85-9f6315d5a29e {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 10:17:36.545 [flow-event-mediator-long-running-thread-fe03a3c6-6cf4-497f-b5aa-34344612780c] INFO  net.corda.flow.messaging.mediator.FlowMediatorRebalanceListener-MultiSourceSubscription--FlowEventConsumer--flow.start--aeb7718c-4a5a-4c1c-96b9-d5c76a5ce60f {} - Partitions assigned: 0. Invalidated flow fiber cache.
2024-08-19 10:17:36.996 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 10:17:36.996 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 10:17:38.574 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=9c45a5fda6bd5f32, traceId=66c31bc2e5fe02cf9c45a5fda6bd5f32} - {"traceId":"66c31bc2e5fe02cf9c45a5fda6bd5f32","id":"9c45a5fda6bd5f32","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724062658554918,"duration":19053,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"134","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 10:17:56.521 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 10:17:56.531 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 10:17:56.625 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messagebus.kafka.consumer.CordaKafkaConsumerImpl {} - Failed to commitSync offsets.
org.apache.kafka.common.errors.RebalanceInProgressException: Offset commit cannot be completed since the consumer is undergoing a rebalance for auto partition assignment. You can try completing the rebalance by calling poll() and then retry the operation.
2024-08-19 10:17:56.626 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] WARN  net.corda.messaging.mediator.processor.ConsumerProcessor-FlowMapperEventMediator {} - Retrying processing: Failed to commitSync offsets..
2024-08-19 10:17:56.708 [flow-mapper-event-mediator-long-running-thread-65645ca5-29ed-4afe-bbde-c237229fa3ee] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.start--15ded20c-8641-4915-8208-faa00f18c164 {} - Partitions assigned: 0.
2024-08-19 10:17:56.708 [flow-mapper-event-mediator-long-running-thread-500cf616-7c82-4026-8786-fd5af9674388] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.out--decf32c6-f91d-454f-9d68-6cd96af15935 {} - Partitions assigned: .
2024-08-19 10:17:56.708 [flow-mapper-event-mediator-long-running-thread-de9214fd-9ede-48c8-9a29-0c37b0a6cc59] INFO  net.corda.messaging.subscription.consumer.listener.LoggingConsumerRebalanceListener-MultiSourceSubscription--FlowMapperConsumer--flow.mapper.session.in--f8dc428f-01da-43fd-8371-1dac5331066d {} - Partitions assigned: .
2024-08-19 10:18:00.800 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=4bdde957980170af, traceId=66c31bd8ad4c61f44bdde957980170af} - {"traceId":"66c31bd8ad4c61f44bdde957980170af","id":"4bdde957980170af","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724062680775278,"duration":24207,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"20","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 10:18:00.813 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 0 ms
2024-08-19 10:33:03.875 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=f10159df7da2c3f5, traceId=66c31f5f57dcc66af10159df7da2c3f5} - {"traceId":"66c31f5f57dcc66af10159df7da2c3f5","id":"f10159df7da2c3f5","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724063583836311,"duration":37300,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"136","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 10:34:12.726 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=cf38b047e3921302, traceId=66c31fa45ec8db13cf38b047e3921302} - {"traceId":"66c31fa45ec8db13cf38b047e3921302","id":"cf38b047e3921302","name":"kafka producer - send record to topic scheduled.task.flow.processor","timestamp":1724063652653464,"duration":70933,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"139","send.partition":"0","send.topic":"scheduled.task.flow.processor"}}
2024-08-19 10:35:04.773 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=d4bd068d0635e05d, traceId=66c31fd8eb2932f5d4bd068d0635e05d} - {"traceId":"66c31fd8eb2932f5d4bd068d0635e05d","id":"d4bd068d0635e05d","name":"kafka producer - send record to topic scheduled.task.db.processor","timestamp":1724063704736534,"duration":35946,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"22","send.partition":"0","send.topic":"scheduled.task.db.processor"}}
2024-08-19 10:35:04.788 [durable processing thread deduplication.table.clean.up-scheduled.task.db.processor] INFO  net.corda.processors.db.internal.schedule.DeduplicationTableCleanUpProcessor {} - Cleaning up deduplication table for all vnodes COMPLETED in 0 ms
2024-08-19 10:35:12.851 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=8fe638940fa091a1, traceId=66c31fe07110ea848fe638940fa091a1} - {"traceId":"66c31fe07110ea848fe638940fa091a1","id":"8fe638940fa091a1","name":"kafka producer - send record to topic scheduled.task.flow.status.processor","timestamp":1724063712790291,"duration":59721,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"140","send.partition":"0","send.topic":"scheduled.task.flow.status.processor"}}
2024-08-19 10:36:12.974 [kafka-producer-network-thread | producer--SCHEDULER_WRITER] INFO  net.corda.tracing.brave.BraveTracingService$LogReporter {spanId=42e2b471f09059a0, traceId=66c3201c52e5090242e2b471f09059a0} - {"traceId":"66c3201c52e5090242e2b471f09059a0","id":"42e2b471f09059a0","name":"kafka producer - send record to topic scheduled.task.mapper.processor","timestamp":1724063772955114,"duration":19304,"localEndpoint":{"serviceName":"combined worker","ipv4":"192.168.176.5"},"tags":{"send.offset":"142","send.partition":"0","send.topic":"scheduled.task.mapper.processor"}}
2024-08-19 10:36:33.639 [shutdown] INFO  net.corda.applications.workers.combined.CombinedWorker {} - Combined worker stopping.
2024-08-19 10:36:33.644 [lifecycle-coordinator-68] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.crypto.CryptoProcessor from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.644 [shutdown] INFO  net.corda.processors.uniqueness.internal.UniquenessProcessorImpl {} - Uniqueness processor stopping.
2024-08-19 10:36:33.645 [lifecycle-coordinator-67] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.uniqueness.internal.UniquenessProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.645 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.configuration.read.ConfigurationReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.645 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.virtualnode.read.VirtualNodeInfoReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.645 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.db.connection.manager.DbConnectionManager from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.646 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.token.cache.internal.TokenCacheProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.646 [lifecycle-coordinator-67] INFO  net.corda.uniqueness.checker.impl.BatchedUniquenessCheckerLifecycleImpl {} - Uniqueness checker stopping
2024-08-19 10:36:33.646 [shutdown] INFO  net.corda.processors.token.cache.internal.TokenCacheProcessorImpl {} - Token cache processor stopping.
2024-08-19 10:36:33.648 [shutdown] INFO  net.corda.processors.persistence.internal.PersistenceProcessorImpl {} - Persistence processor stopping.
2024-08-19 10:36:33.649 [lifecycle-coordinator-72] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.uniqueness.checker.UniquenessCheckerLifecycle from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.650 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.membership.PersistentMemberInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.650 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.uniqueness.backingstore.BackingStoreLifecycle received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.650 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.651 [lifecycle-coordinator-73] INFO  net.corda.processors.token.cache.internal.TokenCacheProcessorImpl {} - Token cache processor is DOWN
2024-08-19 10:36:33.651 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.member.MemberProcessor received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.650 [shutdown] INFO  net.corda.processors.db.internal.DBProcessorImpl {} - DB processor stopping.
2024-08-19 10:36:33.652 [lifecycle-coordinator-73] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.token.cache.internal.TokenCacheProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.652 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.virtualnode.read.VirtualNodeInfoReadService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.651 [lifecycle-coordinator-74] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.persistence.internal.PersistenceProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.651 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.persistence.service.MembershipPersistenceService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.653 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.storage.writer.PermissionStorageWriterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.653 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.HsmRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.658 [shutdown] INFO  net.corda.processors.flow.internal.FlowProcessorImpl {} - Flow processor stopping.
2024-08-19 10:36:33.655 [lifecycle-coordinator-76] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.uniqueness.backingstore.BackingStoreLifecycle,coordinators=net.corda.db.connection.manager.DbConnectionManager), status=DOWN)
2024-08-19 10:36:33.659 [lifecycle-coordinator-78] INFO  net.corda.processors.member.internal.lifecycle.MemberProcessorLifecycleHandler {} - Member processor is DOWN
2024-08-19 10:36:33.662 [lifecycle-coordinator-86] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.flow.internal.FlowProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.664 [lifecycle-coordinator-76] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store is DOWN
2024-08-19 10:36:33.664 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MemberSynchronisationServiceImpl received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.653 [lifecycle-coordinator-77] INFO  net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl {} - Gateway processor is DOWN
2024-08-19 10:36:33.659 [lifecycle-coordinator-79] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.DBProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.668 [lifecycle-coordinator-81] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.utxo.token.cache.services.TokenCacheComponent from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.668 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.DBProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.669 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.storage.reader.PermissionStorageReaderService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.668 [lifecycle-coordinator-76] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.671 [lifecycle-coordinator-77] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.configuration.write.ConfigWriteService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.671 [lifecycle-coordinator-77] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.DBProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.write.ConfigWriteService changing to state DOWN
2024-08-19 10:36:33.665 [shutdown] INFO  net.corda.processors.flow.mapper.internal.FlowMapperProcessorImpl {} - Flow mapper processor stopping.
2024-08-19 10:36:33.664 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.persistence.client.MembershipPersistenceClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.655 [lifecycle-coordinator-75] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.cpiinfo.read.CpiInfoReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.679 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.677 [lifecycle-coordinator-82] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.668 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.uniqueness.backingstore.BackingStoreLifecycle from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.680 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.uniqueness.checker.UniquenessCheckerLifecycle received RegistrationStatusChangeEvent DOWN due to net.corda.uniqueness.backingstore.BackingStoreLifecycle changing to state DOWN
2024-08-19 10:36:33.672 [lifecycle-coordinator-88] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.service.FlowService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.680 [lifecycle-coordinator-88] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.flow.internal.FlowProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.flow.service.FlowService changing to state DOWN
2024-08-19 10:36:33.670 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.configuration.write.ConfigWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.681 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.681 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.670 [lifecycle-coordinator-78] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.persistence.service.MembershipPersistenceService from status UP to DOWN. Reason: Dependencies are down.
2024-08-19 10:36:33.670 [lifecycle-coordinator-87] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.member.MemberProcessor from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.659 [lifecycle-coordinator-80] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.membership.PersistentMemberInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.683 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.persistence.client.MembershipPersistenceClient from status UP to DOWN. Reason: Dependency component is down.
2024-08-19 10:36:33.683 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.rest.internal.RestProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.membership.persistence.client.MembershipPersistenceClient changing to state DOWN
2024-08-19 10:36:33.683 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.staticnetwork.StaticMemberRegistrationService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.persistence.client.MembershipPersistenceClient changing to state DOWN
2024-08-19 10:36:33.684 [lifecycle-coordinator-78] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.utxo.token.cache.services.TokenCacheSubscriptionHandler from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.685 [lifecycle-coordinator-78] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.ledger.utxo.token.cache.services.TokenCacheComponent received RegistrationStatusChangeEvent DOWN due to net.corda.ledger.utxo.token.cache.services.TokenCacheSubscriptionHandler changing to state DOWN
2024-08-19 10:36:33.683 [lifecycle-coordinator-87] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.service.FlowExecutor from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.698 [lifecycle-coordinator-87] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.service.FlowService received RegistrationStatusChangeEvent DOWN due to net.corda.flow.service.FlowExecutor changing to state DOWN
2024-08-19 10:36:33.700 [lifecycle-coordinator-80] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.membership.PersistentMemberInfo> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.membership.PersistentMemberInfo> changing to state DOWN
2024-08-19 10:36:33.682 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.ExpirationProcessor received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.682 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.certificate.publisher.MembersClientCertificatePublisher received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.682 [lifecycle-coordinator-86] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-19 10:36:33.681 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.scheduler.impl.SchedulerProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.680 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.HsmRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.675 [lifecycle-coordinator-76] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.permissions.storage.reader.PermissionStorageReaderService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.679 [lifecycle-coordinator-82] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.ledger.persistence.LedgerPersistenceService received RegistrationStatusChangeEvent DOWN due to net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent changing to state DOWN
2024-08-19 10:36:33.703 [lifecycle-coordinator-82] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.ledger.verification.LedgerVerificationComponent received RegistrationStatusChangeEvent DOWN due to net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent changing to state DOWN
2024-08-19 10:36:33.703 [lifecycle-coordinator-82] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.entityprocessor.FlowPersistenceService received RegistrationStatusChangeEvent DOWN due to net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent changing to state DOWN
2024-08-19 10:36:33.678 [lifecycle-coordinator-85] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.cpk.read.CpkReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.704 [lifecycle-coordinator-85] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent received RegistrationStatusChangeEvent DOWN due to net.corda.cpk.read.CpkReadService changing to state DOWN
2024-08-19 10:36:33.679 [lifecycle-coordinator-75] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-19 10:36:33.704 [lifecycle-coordinator-75] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.rest.v1.FlowClassRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-19 10:36:33.704 [lifecycle-coordinator-102] INFO  net.corda.processors.scheduler.impl.SchedulerProcessorImpl {} - Scheduler processor is DOWN
2024-08-19 10:36:33.704 [lifecycle-coordinator-82] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.verification.internal.VerificationProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.sandboxgroupcontext.service.SandboxGroupContextComponent changing to state DOWN
2024-08-19 10:36:33.703 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.grouppolicy.GroupPolicyProvider from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.705 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.RegistrationProxy received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.706 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.703 [lifecycle-coordinator-101] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.read.GroupParametersReaderService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.703 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.validation.cache.PermissionValidationCacheService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.707 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.group.policy.validation.MembershipGroupPolicyValidator received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.707 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.persistence.client.MembershipQueryClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.709 [lifecycle-coordinator-108] INFO  message-tracker-group-p2p.out.markers-subscription-tile-1 {} - The status of net.corda.membership.grouppolicy.GroupPolicyProvider changed from UP to DOWN, stopping subscription.
2024-08-19 10:36:33.710 [lifecycle-coordinator-111] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.group.policy.validation.MembershipGroupPolicyValidator from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.710 [lifecycle-coordinator-111] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.chunking.read.ChunkReadService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.group.policy.validation.MembershipGroupPolicyValidator changing to state DOWN
2024-08-19 10:36:33.711 [lifecycle-coordinator-111] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.chunking.read.ChunkReadService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.681 [shutdown] INFO  net.corda.processors.verification.internal.VerificationProcessorImpl {} - Verification processor stopping.
2024-08-19 10:36:33.681 [lifecycle-coordinator-93] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.flow.mapper.internal.FlowMapperProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.681 [lifecycle-coordinator-84] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.entityprocessor.FlowPersistenceService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.682 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.read.MembershipGroupReaderProvider from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.713 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.member.DynamicMemberRegistrationService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.683 [lifecycle-coordinator-97] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.maintenance.FlowMaintenance from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.713 [lifecycle-coordinator-93] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-19 10:36:33.714 [lifecycle-coordinator-113] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.p2p.filter.FlowP2PFilterService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.714 [lifecycle-coordinator-113] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.flow.mapper.internal.FlowMapperProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.flow.p2p.filter.FlowP2PFilterService changing to state DOWN
2024-08-19 10:36:33.714 [lifecycle-coordinator-114] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.client.hsm.HSMRegistrationClient from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.685 [lifecycle-coordinator-95] INFO  net.corda.processors.rest.internal.RestProcessorImpl {} - REST processor is DOWN
2024-08-19 10:36:33.684 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.client.MGMResourceClient received RegistrationStatusChangeEvent DOWN due to net.corda.membership.persistence.client.MembershipPersistenceClient changing to state DOWN
2024-08-19 10:36:33.683 [lifecycle-coordinator-92] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.ledger.persistence.LedgerPersistenceService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.714 [lifecycle-coordinator-105] INFO  net.corda.membership.impl.registration.RegistrationProxyImpl {} - Registration proxy stopping.
2024-08-19 10:36:33.715 [lifecycle-coordinator-115] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.716 [lifecycle-coordinator-115] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl received RegistrationStatusChangeEvent DOWN due to net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService changing to state DOWN
2024-08-19 10:36:33.717 [lifecycle-coordinator-105] INFO  net.corda.membership.service.impl.MemberOpsServiceImpl {} - Stopping...
2024-08-19 10:36:33.718 [lifecycle-coordinator-117] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.client.CryptoOpsClient from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.718 [lifecycle-coordinator-117] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.KeysRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-19 10:36:33.714 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator InMemorySessionReplayer-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.697 [lifecycle-coordinator-99] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.staticnetwork.StaticMemberRegistrationService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.700 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.grouppolicy.GroupPolicyProvider received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.723 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.723 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.707 [lifecycle-coordinator-110] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.RegistrationProxy from status UP to DOWN. Reason: Dependencies of RegistrationProxy are down.
2024-08-19 10:36:33.706 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.724 [lifecycle-coordinator-101] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.GroupParametersReaderService changing to state DOWN
2024-08-19 10:36:33.724 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.synchronisation.SynchronisationProxy received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.724 [lifecycle-coordinator-101] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - Received event StopEvent(errored=false).
2024-08-19 10:36:33.725 [lifecycle-coordinator-101] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - Handling stop event.
2024-08-19 10:36:33.725 [lifecycle-coordinator-101] INFO  net.corda.membership.impl.read.cache.MemberDataCache$Impl {} - Clearing member data cache.
2024-08-19 10:36:33.705 [lifecycle-coordinator-102] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.rest.v1.FlowClassRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.703 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.virtualnode.write.db.VirtualNodeWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.726 [lifecycle-coordinator-126] INFO  net.corda.membership.impl.synchronisation.SynchronisationProxyImpl {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.membership.synchronisation.SynchronisationProxy,coordinators=net.corda.configuration.read.ConfigurationReadService, net.corda.membership.grouppolicy.GroupPolicyProvider, net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl, net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MemberSynchronisationServiceImpl), status=DOWN)
2024-08-19 10:36:33.726 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.client.hsm.HSMRegistrationClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.727 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.groupparams.writer.service.GroupParametersWriterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.705 [lifecycle-coordinator-104] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.certificate.publisher.MembersClientCertificatePublisher from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.725 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator inbound_message_processor_group-link.in-subscription-tile-13 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.724 [lifecycle-coordinator-124] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.706 [lifecycle-coordinator-107] INFO  net.corda.processors.verification.internal.VerificationProcessorImpl {} - Verification processor is DOWN
2024-08-19 10:36:33.727 [lifecycle-coordinator-124] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> changing to state DOWN
2024-08-19 10:36:33.706 [lifecycle-coordinator-106] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.scheduler.impl.SchedulerProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.728 [lifecycle-coordinator-102] INFO  net.corda.membership.groupparams.writer.service.impl.GroupParametersWriterServiceImpl {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.membership.groupparams.writer.service.GroupParametersWriterService,coordinators=net.corda.configuration.read.ConfigurationReadService), status=DOWN).
2024-08-19 10:36:33.728 [lifecycle-coordinator-102] INFO  net.corda.membership.groupparams.writer.service.impl.GroupParametersWriterServiceImpl {} - Handling registration changed event.
2024-08-19 10:36:33.723 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.MemberLookupRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.707 [lifecycle-coordinator-109] INFO  net.corda.permissions.validation.cache.PermissionValidationCacheService {} - Registration status change received: DOWN.
2024-08-19 10:36:33.728 [lifecycle-coordinator-109] INFO  net.corda.permissions.validation.cache.PermissionValidationCacheService {} - Performing down transition
2024-08-19 10:36:33.723 [lifecycle-coordinator-99] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.723 [lifecycle-coordinator-75] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.cpiupload.endpoints.v1.CpiUploadRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-19 10:36:33.713 [lifecycle-coordinator-111] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.session.mapper.service.FlowMapperService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.730 [lifecycle-coordinator-124] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.cpiupload.endpoints.v1.CpiUploadRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.722 [lifecycle-coordinator-122] INFO  InMemorySessionReplayer-1 {} - Stopping resources
2024-08-19 10:36:33.722 [lifecycle-coordinator-119] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.service.MemberOpsService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.721 [lifecycle-coordinator-105] INFO  net.corda.membership.impl.registration.dynamic.RegistrationManagementServiceImpl {} - Stopping component.
2024-08-19 10:36:33.732 [lifecycle-coordinator-122] INFO  InMemorySessionReplayer-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-19 10:36:33.720 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.733 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator message-tracker-group-p2p.out.markers-subscription-tile-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.733 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.733 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator inbound_message_processor_group-link.in-subscription-tile-13 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.713 [shutdown] INFO  net.corda.processors.rest.internal.RestProcessorImpl {} - REST processor stopping.
2024-08-19 10:36:33.716 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.certificate.client.CertificatesClient received RegistrationStatusChangeEvent DOWN due to net.corda.membership.persistence.client.MembershipPersistenceClient changing to state DOWN
2024-08-19 10:36:33.734 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.RegistrationManagementService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.persistence.client.MembershipPersistenceClient changing to state DOWN
2024-08-19 10:36:33.717 [lifecycle-coordinator-115] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.service.MemberOpsService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService changing to state DOWN
2024-08-19 10:36:33.720 [lifecycle-coordinator-120] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.p2p.MembershipP2PReadService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.720 [lifecycle-coordinator-117] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator DynamicKeyStore-1 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-19 10:36:33.734 [lifecycle-coordinator-122] INFO  CommonComponents-2 {} - Stopping resources
2024-08-19 10:36:33.733 [lifecycle-coordinator-99] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator InMemorySessionReplayer-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.736 [lifecycle-coordinator-99] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to InMemorySessionReplayer-1 changing to state DOWN
2024-08-19 10:36:33.732 [lifecycle-coordinator-105] INFO  net.corda.membership.impl.synchronisation.SynchronisationProxyImpl {} - Synchronisation proxy stopping.
2024-08-19 10:36:33.732 [lifecycle-coordinator-124] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.RegistrationManagementService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.722 [lifecycle-coordinator-118] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.KeysRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.731 [lifecycle-coordinator-119] INFO  net.corda.membership.service.impl.MemberOpsServiceImpl {} - Received event StopEvent(errored=false)
2024-08-19 10:36:33.743 [lifecycle-coordinator-105] INFO  net.corda.membership.groupparams.writer.service.impl.GroupParametersWriterServiceImpl {} - GroupParametersWriterService stopped.
2024-08-19 10:36:33.722 [lifecycle-coordinator-123] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.synchronisation.SynchronisationService-net.corda.membership.impl.synchronisation.MgmSynchronisationServiceImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.744 [lifecycle-coordinator-105] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-19 10:36:33.729 [lifecycle-coordinator-75] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.virtualnode.endpoints.v1.VirtualNodeRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpiinfo.read.CpiInfoReadService changing to state DOWN
2024-08-19 10:36:33.727 [lifecycle-coordinator-104] INFO  inbound_message_processor_group-link.in-subscription-tile-13 {} - The status of net.corda.membership.grouppolicy.GroupPolicyProvider changed from UP to DOWN, stopping subscription.
2024-08-19 10:36:33.745 [lifecycle-coordinator-65] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.rest.FlowRestResourceService received RegistrationStatusChangeEvent DOWN due to net.corda.virtualnode.read.VirtualNodeInfoReadService changing to state DOWN
2024-08-19 10:36:33.727 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator InMemorySessionReplayer-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.725 [lifecycle-coordinator-125] INFO  SessionManagerImpl-1 {} - Stopping resources
2024-08-19 10:36:33.727 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.mgm.MGMRegistrationService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.726 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.704 [lifecycle-coordinator-103] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.persistence.client.MembershipQueryClient from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.747 [lifecycle-coordinator-131] INFO  InMemorySessionReplayer-1 {} - Stopping resources
2024-08-19 10:36:33.748 [lifecycle-coordinator-107] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.registration.MemberRegistrationService-net.corda.membership.impl.registration.dynamic.mgm.MGMRegistrationService from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.746 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionHealthManager-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.748 [lifecycle-coordinator-91] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.grouppolicy.GroupPolicyProvider changing to state DOWN
2024-08-19 10:36:33.744 [lifecycle-coordinator-129] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.certificate.client.CertificatesClient from status UP to DOWN. Reason: Configuration read service went down
2024-08-19 10:36:33.748 [lifecycle-coordinator-129] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.NetworkRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.certificate.client.CertificatesClient changing to state DOWN
2024-08-19 10:36:33.748 [lifecycle-coordinator-129] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.CertificatesRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.certificate.client.CertificatesClient changing to state DOWN
2024-08-19 10:36:33.751 [lifecycle-coordinator-129] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.CertificateRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.certificate.client.CertificatesClient changing to state DOWN
2024-08-19 10:36:33.742 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.crypto.hes.StableKeyPairDecryptor from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.741 [lifecycle-coordinator-124] INFO  net.corda.membership.impl.registration.dynamic.RegistrationManagementServiceImpl {} - Received event StopEvent(errored=false)
2024-08-19 10:36:33.735 [shutdown] INFO  net.corda.processors.p2p.linkmanager.internal.LinkManagerProcessorImpl {} - Link manager processor stopping.
2024-08-19 10:36:33.715 [lifecycle-coordinator-116] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.rest.internal.RestProcessorImpl from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.752 [lifecycle-coordinator-94] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionHealthManager-1 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.read.MembershipGroupReaderProvider changing to state DOWN
2024-08-19 10:36:33.752 [lifecycle-coordinator-117] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.KeyRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-19 10:36:33.752 [lifecycle-coordinator-115] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.session.mapper.service.FlowMapperService received RegistrationStatusChangeEvent DOWN due to net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService changing to state DOWN
2024-08-19 10:36:33.752 [lifecycle-coordinator-123] INFO  DynamicKeyStore-1 {} - Stopping resources
2024-08-19 10:36:33.754 [lifecycle-coordinator-123] INFO  DynamicKeyStore-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-19 10:36:33.752 [lifecycle-coordinator-89] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.p2p.MembershipP2PReadService received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.hes.StableKeyPairDecryptor changing to state DOWN
2024-08-19 10:36:33.752 [lifecycle-coordinator-129] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.CertificateRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.752 [lifecycle-coordinator-133] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.CertificatesRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.748 [lifecycle-coordinator-107] INFO  SessionHealthManager-1 {} - Stopping resources
2024-08-19 10:36:33.745 [lifecycle-coordinator-99] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.verification.internal.VerificationProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.747 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.certificate.service.CertificatesService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.758 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpiinfo.write.CpiInfoWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.747 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.config.Configuration> received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.758 [lifecycle-coordinator-71] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.cpk.write.CpkWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.db.connection.manager.DbConnectionManager changing to state DOWN
2024-08-19 10:36:33.747 [lifecycle-coordinator-132] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.MemberLookupRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.748 [lifecycle-coordinator-134] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.751 [lifecycle-coordinator-131] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.NetworkRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.761 [lifecycle-coordinator-131] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.components.rest.RestGateway from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.755 [lifecycle-coordinator-110] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator DynamicKeyStore-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.762 [lifecycle-coordinator-110] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-1 received RegistrationStatusChangeEvent DOWN due to DynamicKeyStore-1 changing to state DOWN
2024-08-19 10:36:33.754 [shutdown] INFO  net.corda.processors.p2p.gateway.internal.GatewayProcessorImpl {} - Gateway processor stopping.
2024-08-19 10:36:33.763 [lifecycle-coordinator-137] INFO  net.corda.membership.impl.read.reader.GroupParametersReaderServiceImpl {} - GroupParametersReaderService stopped.
2024-08-19 10:36:33.764 [shutdown] INFO  net.corda.processors.scheduler.impl.SchedulerProcessorImpl {} - Scheduler processor stopping.
2024-08-19 10:36:33.755 [lifecycle-coordinator-136] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.p2p.linkmanager.internal.LinkManagerProcessorImpl from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.763 [lifecycle-coordinator-72] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store stopping
2024-08-19 10:36:33.762 [lifecycle-coordinator-105] INFO  net.corda.processors.member.internal.lifecycle.MemberProcessorLifecycleHandler {} - Member processor stopping.
2024-08-19 10:36:33.765 [lifecycle-coordinator-127] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.components.scheduler.TriggerPublisher from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.766 [lifecycle-coordinator-127] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-flow-mapper-state-cleanup received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-19 10:36:33.766 [lifecycle-coordinator-127] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-flow-session-timeout received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-19 10:36:33.766 [lifecycle-coordinator-127] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-flow-status-cleanup received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-19 10:36:33.756 [lifecycle-coordinator-138] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.KeyRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.756 [lifecycle-coordinator-94] INFO  net.corda.membership.impl.read.cache.MembershipGroupReadCache$Impl {} - Clearing membership group read cache.
2024-08-19 10:36:33.761 [lifecycle-coordinator-123] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.client.MemberResourceClient from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.761 [lifecycle-coordinator-132] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.cpi.upload.endpoints.service.CpiUploadService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.761 [lifecycle-coordinator-134] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.rest.FlowRestResourceService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.759 [lifecycle-coordinator-130] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.config.Configuration> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.768 [lifecycle-coordinator-132] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.virtualnode.maintenance.endpoints.v1.VirtualNodeMaintenanceRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.cpi.upload.endpoints.service.CpiUploadService changing to state DOWN
2024-08-19 10:36:33.758 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.client.MemberResourceClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.768 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.processors.p2p.linkmanager.internal.LinkManagerProcessorImpl received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.768 [lifecycle-coordinator-130] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.config.Configuration> received RegistrationStatusChangeEvent DOWN due to net.corda.processors.db.internal.reconcile.db.DbReconcilerReader<java.lang.String, net.corda.data.config.Configuration> changing to state DOWN
2024-08-19 10:36:33.769 [lifecycle-coordinator-119] WARN  net.corda.membership.service.impl.MemberOpsServiceImpl {} - Unexpected event StopEvent(errored=false)!
2024-08-19 10:36:33.767 [lifecycle-coordinator-123] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.rest.v1.MemberRegistrationRestResource-50200 received RegistrationStatusChangeEvent DOWN due to net.corda.membership.client.MemberResourceClient changing to state DOWN
2024-08-19 10:36:33.770 [lifecycle-coordinator-71] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for flow-status-cleanup
2024-08-19 10:36:33.767 [lifecycle-coordinator-138] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.virtualnode.endpoints.v1.VirtualNodeRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.767 [lifecycle-coordinator-98] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-f78613b9-ae92-42db-87ac-99d30440f078 from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.772 [lifecycle-coordinator-98] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-f78613b9-ae92-42db-87ac-99d30440f078 is stopping
2024-08-19 10:36:33.775 [lifecycle-coordinator-160] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.membership.lib.InternalGroupParameters> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.775 [lifecycle-coordinator-108] INFO  message-tracker-group-p2p.out.markers-subscription-tile-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-19 10:36:33.776 [lifecycle-coordinator-163] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-46d0b0de-cd29-426c-9149-ac4463bae133 from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.777 [lifecycle-coordinator-163] INFO  net.corda.libs.statemanager.impl.lifecycle.CheckConnectionEventHandler {} - StateManager-46d0b0de-cd29-426c-9149-ac4463bae133 is stopping
2024-08-19 10:36:33.778 [lifecycle-coordinator-168] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-flow-mapper-state-cleanup from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.779 [lifecycle-coordinator-168] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.config.Configuration> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.779 [lifecycle-coordinator-170] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.libs.virtualnode.maintenance.endpoints.v1.VirtualNodeMaintenanceRestResource from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.767 [lifecycle-coordinator-127] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-ledger-repair received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-19 10:36:33.780 [lifecycle-coordinator-127] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator scheduler-deduplication-table-clean-up-task received RegistrationStatusChangeEvent DOWN due to net.corda.components.scheduler.TriggerPublisher changing to state DOWN
2024-08-19 10:36:33.766 [lifecycle-coordinator-122] INFO  CommonComponents-2 {} - Unregistered for Config updates.
2024-08-19 10:36:33.781 [lifecycle-coordinator-122] INFO  CommonComponents-2 {} - State updated from Started to StoppedDueToChildStopped
2024-08-19 10:36:33.781 [lifecycle-coordinator-170] INFO  CommonComponents-2 {} - Stopping resources
2024-08-19 10:36:33.765 [lifecycle-coordinator-144] INFO  CommonComponents-1 {} - Stopping resources
2024-08-19 10:36:33.782 [lifecycle-coordinator-144] INFO  CommonComponents-1 {} - State updated from Started to StoppedDueToChildStopped
2024-08-19 10:36:33.765 [lifecycle-coordinator-86] INFO  net.corda.uniqueness.backingstore.impl.JPABackingStoreLifecycleImpl {} - Backing store received event StopEvent(errored=false)
2024-08-19 10:36:33.782 [lifecycle-coordinator-122] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator CommonComponents-1 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.764 [lifecycle-coordinator-67] INFO  net.corda.processors.uniqueness.internal.UniquenessProcessorImpl {} - Uniqueness processor received event StopEvent(errored=false).
2024-08-19 10:36:33.753 [lifecycle-coordinator-117] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator CommonComponents-2 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-19 10:36:33.782 [lifecycle-coordinator-122] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator OutboundMessageHandler-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-1 changing to state DOWN
2024-08-19 10:36:33.765 [lifecycle-coordinator-159] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.data.p2p.mtls.MgmAllowedCertificateSubject, net.corda.data.p2p.mtls.MgmAllowedCertificateSubject> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.782 [lifecycle-coordinator-170] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator CommonComponents-2 from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.766 [lifecycle-coordinator-100] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<java.lang.String, net.corda.data.membership.PersistentMemberInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.766 [lifecycle-coordinator-149] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.libs.packaging.core.CpiIdentifier, net.corda.libs.packaging.core.CpiMetadata> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.781 [lifecycle-coordinator-169] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-deduplication-table-clean-up-task from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.781 [lifecycle-coordinator-168] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-ledger-repair from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.767 [lifecycle-coordinator-105] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-flow-session-timeout from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.779 [lifecycle-coordinator-160] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.virtualnode.write.db.VirtualNodeWriteService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.778 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.rest.KeyRotationRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.785 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.membership.locally.hosted.identities.LocallyHostedIdentitiesService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.785 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.management.cache.PermissionManagementCacheService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.786 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.permissions.management.PermissionManagementService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.786 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.configuration.endpoints.v1.ConfigRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.786 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.securitymanager.SecurityConfigHandler received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.787 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.flow.p2p.filter.FlowP2PFilterService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.787 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.virtualnode.maintenance.endpoints.v1.VirtualNodeMaintenanceRestResource received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.788 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.virtualnode.write.db.VirtualNodeInfoWriteService received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.788 [lifecycle-coordinator-70] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.crypto.client.CryptoOpsClient received RegistrationStatusChangeEvent DOWN due to net.corda.configuration.read.ConfigurationReadService changing to state DOWN
2024-08-19 10:36:33.777 [lifecycle-coordinator-104] INFO  inbound_message_processor_group-link.in-subscription-tile-13 {} - State updated from Started to StoppedDueToChildStopped
2024-08-19 10:36:33.777 [lifecycle-coordinator-165] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator scheduler-flow-status-cleanup from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.776 [lifecycle-coordinator-146] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.permissions.management.cache.PermissionManagementCacheService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.775 [lifecycle-coordinator-158] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator Gateway-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.771 [lifecycle-coordinator-71] INFO  net.corda.processors.scheduler.impl.Schedulers {} - Stopping scheduler for deduplication-table-clean-up-task
2024-08-19 10:36:33.767 [lifecycle-coordinator-94] INFO  net.corda.membership.impl.read.cache.MemberListCache$Impl {} - Clearing member list cache.
2024-08-19 10:36:33.767 [lifecycle-coordinator-118] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator LinkManager-1 from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.770 [lifecycle-coordinator-131] INFO  net.corda.components.rest.internal.RestGatewayEventHandler {} - Stop event received, stopping dependencies.
2024-08-19 10:36:33.770 [lifecycle-coordinator-107] INFO  SessionHealthManager-1 {} - Unregistered for Config updates.
2024-08-19 10:36:33.769 [lifecycle-coordinator-125] INFO  SessionManagerImpl-1 {} - Unregistered for Config updates.
2024-08-19 10:36:33.770 [lifecycle-coordinator-147] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.reconciliation.impl.ReconcilerImpl<net.corda.virtualnode.HoldingIdentity, net.corda.virtualnode.VirtualNodeInfo> from status UP to DOWN. Reason: Status has changed to DOWN
2024-08-19 10:36:33.771 [lifecycle-coordinator-141] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.flow.rest.FlowStatusLookupService from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.771 [lifecycle-coordinator-135] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator net.corda.membership.rest.v1.MemberRegistrationRestResource-50200 from status UP to DOWN. Reason: Dependencies are DOWN
2024-08-19 10:36:33.772 [lifecycle-coordinator-152] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-95f3b18a-3209-4bc4-ae74-4401a8ff4632 from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.777 [lifecycle-coordinator-167] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-f8007937-8959-4b96-8c77-541a143bfa8f from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.790 [lifecycle-coordinator-67] INFO  net.corda.processors.db.internal.reconcile.db.MemberInfoReconciler {} - Received event RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.processors.db.internal.reconcile.db.MemberInfoReconciler$MemberInfoReconcilerReadWriter,coordinators=net.corda.configuration.read.ConfigurationReadService), status=DOWN).
2024-08-19 10:36:33.788 [lifecycle-coordinator-149] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator net.corda.libs.permissions.endpoints.v1.user.UserEndpoint received RegistrationStatusChangeEvent DOWN due to net.corda.permissions.management.PermissionManagementService changing to state DOWN
2024-08-19 10:36:33.783 [lifecycle-coordinator-170] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator LinkManager-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-2 changing to state DOWN
2024-08-19 10:36:33.783 [lifecycle-coordinator-144] INFO  OutboundMessageHandler-1 {} - Stopping resources
2024-08-19 10:36:33.783 [lifecycle-coordinator-122] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator Gateway-1 received RegistrationStatusChangeEvent DOWN due to CommonComponents-1 changing to state DOWN
2024-08-19 10:36:33.782 [lifecycle-coordinator-117] INFO  net.corda.lifecycle.impl.Registration {} - Coordinator SessionManagerImpl-1 received RegistrationStatusChangeEvent DOWN due to net.corda.crypto.client.CryptoOpsClient changing to state DOWN
2024-08-19 10:36:33.763 [lifecycle-coordinator-140] INFO  net.corda.lifecycle.impl.LifecycleProcessor {} - Updating coordinator StateManager-e7395e47-df02-442f-8de3-67fd416798e5 from status UP to DOWN. Reason: Component has been stopped
2024-08-19 10:36:33.786 [lifecycle-coordinator-105] INFO  net.corda.crypto.rest.impl.KeyRotationRestResourceImpl {} - Handling KeyRotationRestResource event, RegistrationStatusChangeEvent(registration=Registration(registeringCoordinator=net.corda.crypto.rest.KeyRotationRestResource,coordinators=net.corda.configuration.read.ConfigurationReadService), status=DOWN).
